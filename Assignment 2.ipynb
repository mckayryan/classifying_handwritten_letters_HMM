{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 Assignment 2\n",
    "\n",
    "## *Tasks TODO*\n",
    "- parameter initialization\n",
    "- baseline (GMM model)\n",
    "- mean negative log probability\n",
    "- sample predictions.txt generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hmmlearn\n",
    "import sklearn\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it's version 0.2.1 (install from github, not pip)\n",
    "# pip install git+https://github.com/hmmlearn/hmmlearn.git\n",
    "hmmlearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "trainData = sio.loadmat('./trajectories_train.mat')\n",
    "testData = sio.loadmat('./trajectories_xtest.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the data\n",
    "xtrain = trainData['xtrain'].reshape((-1, ))\n",
    "ytrain = trainData['ytrain'].reshape((-1, ))\n",
    "kf = StratifiedKFold(n_splits = 3, random_state=rng)\n",
    "xtest = testData['xtest'].reshape((-1, ))\n",
    "key = trainData['key']\n",
    "key = [item[0] for item in key.reshape((-1, ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429,)\n",
      "(1429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "# print([sum(yval == i) for i in np.unique(ytrain)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = xtrain[idx]\n",
    "y = ytrain[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_char(data, label):\n",
    "    start_x = 0\n",
    "    start_y = 0\n",
    "    plt.plot(start_x, start_y, 'ro')\n",
    "    for vel_h, vel_v, alpha in zip(data[0,], data[1, ], 1/(1 + np.exp(-data[2, ]/np.sum(data[1, ])))):\n",
    "        start_x = start_x + vel_h\n",
    "        start_y = start_y + vel_v\n",
    "        plt.plot(start_x, start_y,'bo', alpha = alpha)\n",
    "    plt.title('Character ' + key[label-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8d85162d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_char(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([seq.T for seq in xtrain])\n",
    "xtest = np.asarray([seq.T for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_max = np.max(np.vstack(xtrain), axis=0)\n",
    "train_min = np.min(np.vstack(xtrain), axis=0)\n",
    "def rescale(seq):\n",
    "    return (seq - train_min) / (train_max - train_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([rescale(seq) for seq in xtrain])\n",
    "xtest = np.asarray([rescale(seq) for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths_train = list(map(lambda x: x.shape[0], xtrain))\n",
    "lengths_test = list(map(lambda x: x.shape[0], xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder().fit(ytrain)\n",
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(hmm, sequence):\n",
    "\n",
    "    logprob_frame = hmm._compute_log_likelihood(sequence)\n",
    "    logprob_sequence, _ =  hmm._do_forward_pass(logprob_frame)\n",
    "\n",
    "    return logprob_sequence\n",
    "\n",
    "def log_likelihoods(hmm, sequences):\n",
    "\n",
    "    ll = lambda seq: log_likelihood(hmm, seq)\n",
    "\n",
    "    return np.fromiter(map(ll, sequences), dtype='float64')\n",
    "\n",
    "def log_likelihoods_cond(cond_hmms, sequences):\n",
    "\n",
    "    ll = lambda hmm: log_likelihoods(hmm, sequences)\n",
    "\n",
    "    return np.vstack(map(ll, cond_hmms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure to keep the init_params commented otherwise it doesn't work properly for some reason\n",
    "class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hmm=GaussianHMM()):\n",
    "        self.hmm = hmm\n",
    "        self.class_cond_hmms_ = []\n",
    "\n",
    "    def fit(self, sequences, labels, k):        \n",
    "        class_counts = np.bincount(labels).astype(np.float)\n",
    "        self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "        \n",
    "        for c in range(np.max(labels)+1):\n",
    "            sequences_c = sequences[labels == c]\n",
    "            X_c = np.vstack(sequences_c)\n",
    "            lengths_c = list(map(len, sequences_c))\n",
    "            class_cond_hmm = clone(self.hmm, safe=True)\n",
    "            n_states_k = k[c]\n",
    "            pi0 = np.eye(1, n_states_k)[0]\n",
    "            trans0 = np.diag(np.ones(n_states_k)) + np.diag(np.ones(n_states_k-1), 1)\n",
    "            trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "            class_cond_hmm.n_components = n_states_k\n",
    "            class_cond_hmm.startprob_ = pi0\n",
    "            class_cond_hmm.transmat_  = trans0\n",
    "            class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "            self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        # 20 x N matrix\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "        return np.argmax(log_post_unnorm, axis=0)\n",
    "    \n",
    "    def predict_proba(self, sequences):\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "        \n",
    "        prob_post_norm = np.empty_like(log_post_unnorm)\n",
    "        \n",
    "        for i in range(log_post_unnorm.shape[1]):\n",
    "            c = np.max(log_post_unnorm[:,i])\n",
    "            prob_post_unnorm = np.exp(log_post_unnorm[:,i].astype(np.float64) - c)\n",
    "            prob_post_norm[:,i] = prob_post_unnorm / np.sum(prob_post_unnorm)\n",
    "            \n",
    "        return prob_post_norm\n",
    "    \n",
    "    def generateSample(self, mClass, length):\n",
    "        sel_hmm = self.class_cond_hmms_[mClass]\n",
    "        x, _ = sel_hmm.sample(length)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian HMM (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT of warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=25, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = GaussianHMM(n_components=25, n_iter=10, random_state=seed)\n",
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(25, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.93360995850622408)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96092925026399156)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs = hmm_classifier.predict_proba(xtrain[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "g\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(np.round(probs[:,idx], 4))\n",
    "print(key[np.argmax(probs[:,idx]) + 1])\n",
    "print(key[ytrain[train_index][idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g   h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  26   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   \n",
       "c   0   0  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  10   0   1   4   0   0   0   0   0   0   0   4   0   \n",
       "l   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   2   0   \n",
       "m   0   0   0   0   0   0   0   0  18   3   0   0   0   0   0   0   0   2   0   \n",
       "n   0   0   0   0   0   0   0   0   4  16   0   0   0   0   0   0   0   1   0   \n",
       "o   0   0   0   0   0   0   0   0   0   0  22   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0   0   0   0   0   0  24   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0   0   0   0   1   0   0  18   0   0   0   0   0   0   \n",
       "r   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22   0   0   0   0   \n",
       "u   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   4   0   \n",
       "v   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  30   0   0   \n",
       "w   0   0   0   0   0   0   0   0   2   1   0   0   0   0   0   1   0  16   0   \n",
       "y   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   \n",
       "z   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  31  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[test_index], y_val_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g   h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  55   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   \n",
       "c   0   0  44   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  47   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  64   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  50   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  24   0   1   7   0   0   0   0   0   0   0   6   0   \n",
       "l   0   0   0   0   0   0   3  48   0   0   0   0   0   0   0   0   0   1   0   \n",
       "m   0   0   0   0   0   0   2   0  37   2   0   0   0   0   0   0   0   3   0   \n",
       "n   0   0   0   0   0   0   0   0   3  35   0   0   0   0   0   0   0   3   0   \n",
       "o   0   0   0   0   0   0   0   0   0   0  44   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0   0   0   0   0   0  46   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   \n",
       "r   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0   0   0   0   0   0   0   0   0  43   0   0   0   0   \n",
       "u   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  39   0   3   0   \n",
       "v   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60   0   0   \n",
       "w   0   0   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0  36   0   \n",
       "y   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45   \n",
       "z   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  62  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[train_index], y_train_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations of validations confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with m, u, w\n",
    "* n gets mixed up with m, w\n",
    "* u gets mixed up with w\n",
    "\n",
    "### Observations of training confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with u, w\n",
    "* n gets mixed up with n, w, m\n",
    "* p gets mixed up with n\n",
    "* u gets mixed up with a, w\n",
    "* w gets mixed up with a, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random sample from the gmm for a certain class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc2de99ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myClass = [20]\n",
    "x = hmm_classifier.generateSample(label_enc.transform(myClass)[0], 200)\n",
    "x = x * (train_max - train_min) + train_min\n",
    "plot_char(x.T, myClass[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 5, 0.7998600419874038)\n",
      "('Accuracy', 6, 0.8621413575927221)\n",
      "('Accuracy', 7, 0.8530440867739678)\n",
      "('Accuracy', 8, 0.8761371588523443)\n",
      "('Accuracy', 9, 0.8803358992302309)\n",
      "('Accuracy', 10, 0.8999300209937019)\n",
      "('Accuracy', 11, 0.900629811056683)\n",
      "('Accuracy', 12, 0.9062281315605318)\n",
      "('Accuracy', 13, 0.9097270818754374)\n",
      "('Accuracy', 14, 0.9111266620013996)\n",
      "('Accuracy', 15, 0.9188243526941917)\n",
      "('Accuracy', 16, 0.9118264520643807)\n",
      "('Accuracy', 17, 0.9132260321903429)\n",
      "('Accuracy', 18, 0.9111266620013996)\n",
      "('Accuracy', 19, 0.9104268719384184)\n",
      "('Accuracy', 20, 0.9146256123163051)\n",
      "('Accuracy', 21, 0.9125262421273618)\n",
      "('Accuracy', 22, 0.9181245626312107)\n",
      "('Accuracy', 23, 0.9230230930720784)\n",
      "('Accuracy', 24, 0.9258222533240028)\n",
      "('Accuracy', 25, 0.9258222533240028)\n",
      "('Accuracy', 26, 0.9153254023792862)\n",
      "('Accuracy', 27, 0.9230230930720784)\n",
      "('Accuracy', 28, 0.9286214135759272)\n",
      "('Accuracy', 29, 0.9209237228831351)\n",
      "('Accuracy', 30, 0.9258222533240028)\n"
     ]
    }
   ],
   "source": [
    "cv1_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "#                       init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    correct = 0.0\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "#         hmm.startprob_ = pi0\n",
    "#         hmm.transmat_  = trans0\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]), np.tile(k, 20))\n",
    "        y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))\n",
    "        correct += np.sum(y_val_pred == ytrain[test_index])\n",
    "    accuracy = correct/xtrain.shape[0]\n",
    "    cv1_results[k] = accuracy\n",
    "    print('Accuracy', k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k,\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    class_cond_accuracies = {}\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]), np.tile(k, 20))\n",
    "        for label in label_enc.classes_:\n",
    "            class_cond_xtest = xtrain[test_index][ytrain[test_index] == label]\n",
    "            y_class_cond_pred = label_enc.inverse_transform(hmm_classifier.predict(class_cond_xtest))\n",
    "            class_cond_accuracy = (y_class_cond_pred == label).mean()\n",
    "            if (not class_cond_accuracies.has_key(label)):\n",
    "                class_cond_accuracies[label] = []\n",
    "            class_cond_accuracies[label] = class_cond_accuracies[label] + [class_cond_accuracy]\n",
    "\n",
    "    k_states_results = {}\n",
    "    for label in label_enc.classes_:\n",
    "        k_states_results[label] = np.mean(class_cond_accuracies[label])\n",
    "    cv2_results[k] = k_states_results\n",
    "    print('Average for k = ', k, np.mean(cv2_results[k].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.7977</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.4849</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.4683</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.7746</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8605</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.6278</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.6302</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a       b       c       d       e       g       h       l       m  \\\n",
       "5   0.9519  0.9524  0.9091  0.2240  0.9896  0.9733  0.1930  0.7977  0.5507   \n",
       "6   0.9638  0.9167  0.9545  1.0000  0.9896  1.0000  0.4386  0.8234  0.7161   \n",
       "7   0.9757  0.9048  0.9848  0.9855  0.9896  1.0000  0.3158  0.7972  0.5527   \n",
       "8   0.9877  0.9524  0.9848  1.0000  0.9896  1.0000  0.2281  0.8613  0.5672   \n",
       "9   0.9757  0.9643  1.0000  1.0000  0.9896  1.0000  0.2456  0.8979  0.6555   \n",
       "10  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.4561  0.9103  0.6403   \n",
       "11  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4737  0.8599  0.6416   \n",
       "12  1.0000  0.9405  1.0000  1.0000  0.9896  1.0000  0.4912  0.8727  0.6713   \n",
       "13  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.3860  0.8865  0.6713   \n",
       "14  0.9877  0.9405  1.0000  1.0000  0.9896  1.0000  0.4386  0.8481  0.6858   \n",
       "15  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.5263  0.8984  0.6548   \n",
       "16  1.0000  0.9405  1.0000  1.0000  0.9896  1.0000  0.5088  0.8471  0.6555   \n",
       "17  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.5088  0.8727  0.6410   \n",
       "18  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.3684  0.8471  0.6561   \n",
       "19  0.9877  0.9643  0.9848  1.0000  0.9896  1.0000  0.3684  0.8723  0.6700   \n",
       "20  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.4035  0.8732  0.6133   \n",
       "21  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.3860  0.9107  0.6561   \n",
       "22  0.9877  0.9762  1.0000  1.0000  0.9896  1.0000  0.4386  0.8979  0.6397   \n",
       "23  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4561  0.9107  0.6555   \n",
       "24  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4561  0.8979  0.6568   \n",
       "25  0.9877  0.9405  1.0000  1.0000  0.9896  1.0000  0.4561  0.8856  0.7003   \n",
       "26  0.9877  0.9286  1.0000  1.0000  0.9896  1.0000  0.4386  0.8727  0.6423   \n",
       "27  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4386  0.9112  0.6864   \n",
       "28  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.5439  0.9236  0.6258   \n",
       "29  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.3860  0.8979  0.6555   \n",
       "30  0.9877  0.9286  1.0000  1.0000  0.9896  1.0000  0.4737  0.9107  0.7161   \n",
       "\n",
       "         n       o       p       q       r       s       u       v       w  \\\n",
       "5   0.4349  0.9848  0.8720  0.8246  0.7044  1.0000  0.4848  0.9889  0.7254   \n",
       "6   0.4849  0.9545  0.9281  0.8947  0.7404  1.0000  0.4394  0.9889  0.6719   \n",
       "7   0.4683  0.9697  0.9281  0.9474  0.7746  0.9848  0.2973  0.9889  0.8614   \n",
       "8   0.5167  0.9697  0.9275  0.9649  0.8096  1.0000  0.5635  1.0000  0.8789   \n",
       "9   0.5016  0.9848  0.9143  0.9298  0.8263  0.9848  0.5332  1.0000  0.8956   \n",
       "10  0.5643  0.9848  0.9710  0.9474  0.8605  1.0000  0.6263  1.0000  0.8439   \n",
       "11  0.5635  0.9848  0.9432  0.9649  0.9307  0.9690  0.6732  1.0000  0.8623   \n",
       "12  0.5976  0.9848  0.9432  0.9474  0.8965  0.9848  0.6861  1.0000  0.8789   \n",
       "13  0.6786  0.9848  0.9432  0.9474  0.9307  1.0000  0.7338  1.0000  0.8614   \n",
       "14  0.6452  1.0000  0.9287  0.9474  0.9298  0.9683  0.7965  1.0000  0.8965   \n",
       "15  0.6286  1.0000  0.9565  0.9474  0.9649  0.9841  0.8124  0.9889  0.8798   \n",
       "16  0.6421  0.9848  0.9710  0.9474  0.9649  0.9841  0.7489  0.9889  0.8456   \n",
       "17  0.6929  0.9848  0.9710  0.9474  0.9474  0.9841  0.7338  0.9889  0.8439   \n",
       "18  0.6444  0.9848  0.9855  0.9474  0.9482  0.9841  0.7799  1.0000  0.8974   \n",
       "19  0.6278  1.0000  1.0000  0.9649  0.9474  0.9841  0.7345  0.9889  0.8807   \n",
       "20  0.6921  1.0000  0.9855  0.9649  0.9649  0.9841  0.8139  0.9889  0.8465   \n",
       "21  0.5952  1.0000  0.9710  0.9474  0.9649  1.0000  0.7626  1.0000  0.8623   \n",
       "22  0.5794  1.0000  1.0000  0.9649  0.9649  0.9841  0.8579  0.9889  0.8640   \n",
       "23  0.6778  1.0000  1.0000  0.9649  0.9474  0.9841  0.8276  1.0000  0.8982   \n",
       "24  0.7270  1.0000  0.9855  0.9825  0.9649  0.9841  0.8427  1.0000  0.8982   \n",
       "25  0.7103  1.0000  1.0000  0.9825  0.9649  0.9841  0.8283  1.0000  0.8982   \n",
       "26  0.6302  1.0000  0.9710  0.9825  0.9307  0.9841  0.8117  1.0000  0.9316   \n",
       "27  0.5976  1.0000  1.0000  0.9825  0.9482  0.9841  0.8593  1.0000  0.9149   \n",
       "28  0.6944  1.0000  0.9855  1.0000  0.9825  0.9841  0.7980  1.0000  0.9149   \n",
       "29  0.6468  1.0000  1.0000  0.9649  0.9482  0.9841  0.8593  1.0000  0.9316   \n",
       "30  0.6294  1.0000  1.0000  0.9825  0.9825  0.9841  0.8283  1.0000  0.9149   \n",
       "\n",
       "         y    z  \n",
       "5   1.0000  1.0  \n",
       "6   0.9855  1.0  \n",
       "7   0.9855  1.0  \n",
       "8   0.9855  1.0  \n",
       "9   0.9710  1.0  \n",
       "10  0.9710  1.0  \n",
       "11  0.9710  1.0  \n",
       "12  1.0000  1.0  \n",
       "13  1.0000  1.0  \n",
       "14  1.0000  1.0  \n",
       "15  1.0000  1.0  \n",
       "16  1.0000  1.0  \n",
       "17  1.0000  1.0  \n",
       "18  1.0000  1.0  \n",
       "19  1.0000  1.0  \n",
       "20  1.0000  1.0  \n",
       "21  1.0000  1.0  \n",
       "22  1.0000  1.0  \n",
       "23  1.0000  1.0  \n",
       "24  1.0000  1.0  \n",
       "25  1.0000  1.0  \n",
       "26  1.0000  1.0  \n",
       "27  1.0000  1.0  \n",
       "28  1.0000  1.0  \n",
       "29  1.0000  1.0  \n",
       "30  1.0000  1.0  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pandas.DataFrame(cv2_results).T\n",
    "result.columns = key\n",
    "result.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 22,  9,  6,  5,  6, 28, 28,  6, 24, 14, 19, 28, 28,  5, 27,  8,\n",
       "       26,  5,  5])"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highest n_states for each character\n",
    "np.asarray(range(5, 31))[np.argmax(np.asarray(result), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tested states\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 30, 20, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.939xx\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 20, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.93983402489626555\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.94190871369294604\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 15, 28, 26, 28, 28] 0.91701244813278004\n",
    "# [28, 28, 28, 28, 28, 28, 28, 10, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.91xx\n",
    "# [28, 28, 28, 28, 28, 28, 28, 21, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.94190871369294604\n",
    "# [28, 28, 28, 28, 28, 28, 15, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.92323651452282163\n",
    "\n",
    "# Winner\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining the classifier using the \"Optimized\" number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=25, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.array([28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.94190871369294604)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96620908130939809)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture HMM (meh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    filtered = np.empty_like(data)\n",
    "    \n",
    "    for i in range(filtered.shape[0]):\n",
    "        ll = np.zeros(data[i].shape)\n",
    "        \n",
    "        for j in range(3):\n",
    "            ll[:,j] = lfilter(b, a, data[i][:,j])\n",
    "        \n",
    "        filtered[i] = ll\n",
    "    return filtered\n",
    "\n",
    "# Filter requirements.\n",
    "order = 4\n",
    "fs = 200.0       # sample rate, Hz\n",
    "cutoff = 2  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_states = 10\n",
    "\n",
    "# initial guess for EM\n",
    "# pi0 = np.eye(1, n_states)[0] # start probability\n",
    "# pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "# trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "# trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "# trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=n_states, \n",
    "#                   init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "# hmm.startprob_ = pi0\n",
    "# hmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT of warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(15, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.96887966804979253)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96409714889123543)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cross validation on number of states, cutoff frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "order = 4\n",
    "fs = 200.0  \n",
    "\n",
    "hmm = GaussianHMM(n_components=n_states,\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: k = 10; cut_freq = 2 ---> 0.941175230565\n",
      "Validation Accuracy: k = 10; cut_freq = 3 ---> 0.974032995778\n",
      "Validation Accuracy: k = 10; cut_freq = 4 ---> 0.951644298248\n",
      "Validation Accuracy: k = 10; cut_freq = 5 ---> 0.951651732219\n",
      "Validation Accuracy: k = 10; cut_freq = 6 ---> 0.943244786528\n",
      "Validation Accuracy: k = 10; cut_freq = 7 ---> 0.929225864831\n",
      "Validation Accuracy: k = 10; cut_freq = 8 ---> 0.915280264919\n",
      "Validation Accuracy: k = 10; cut_freq = 9 ---> 0.906148170785\n",
      "Validation Accuracy: k = 10; cut_freq = 10 ---> 0.906148170785\n",
      "Validation Accuracy: k = 11; cut_freq = 2 ---> 0.947467751185\n",
      "Validation Accuracy: k = 11; cut_freq = 3 ---> 0.965722956995\n",
      "Validation Accuracy: k = 11; cut_freq = 4 ---> 0.956534975435\n",
      "Validation Accuracy: k = 11; cut_freq = 5 ---> 0.954533608424\n",
      "Validation Accuracy: k = 11; cut_freq = 6 ---> 0.947453901172\n",
      "Validation Accuracy: k = 11; cut_freq = 7 ---> 0.934897577887\n",
      "Validation Accuracy: k = 11; cut_freq = 8 ---> 0.925800352473\n",
      "Validation Accuracy: k = 11; cut_freq = 9 ---> 0.908948008025\n",
      "Validation Accuracy: k = 11; cut_freq = 10 ---> 0.914540248533\n",
      "Validation Accuracy: k = 12; cut_freq = 2 ---> 0.950240153677\n",
      "Validation Accuracy: k = 12; cut_freq = 3 ---> 0.965691937901\n",
      "Validation Accuracy: k = 12; cut_freq = 4 ---> 0.951664299024\n",
      "Validation Accuracy: k = 12; cut_freq = 5 ---> 0.959375832158\n",
      "Validation Accuracy: k = 12; cut_freq = 6 ---> 0.95101733992\n",
      "Validation Accuracy: k = 12; cut_freq = 7 ---> 0.93974108483\n",
      "Validation Accuracy: k = 12; cut_freq = 8 ---> 0.916679541935\n",
      "Validation Accuracy: k = 12; cut_freq = 9 ---> 0.908313615727\n",
      "Validation Accuracy: k = 12; cut_freq = 10 ---> 0.900598232968\n",
      "Validation Accuracy: k = 13; cut_freq = 2 ---> 0.950207851374\n",
      "Validation Accuracy: k = 13; cut_freq = 3 ---> 0.964266509345\n",
      "Validation Accuracy: k = 13; cut_freq = 4 ---> 0.953093311925\n",
      "Validation Accuracy: k = 13; cut_freq = 5 ---> 0.958015008207\n",
      "Validation Accuracy: k = 13; cut_freq = 6 ---> 0.946819508873\n",
      "Validation Accuracy: k = 13; cut_freq = 7 ---> 0.946053340948\n",
      "Validation Accuracy: k = 13; cut_freq = 8 ---> 0.925056486462\n",
      "Validation Accuracy: k = 13; cut_freq = 9 ---> 0.913143272656\n",
      "Validation Accuracy: k = 13; cut_freq = 10 ---> 0.909690590828\n",
      "Validation Accuracy: k = 14; cut_freq = 2 ---> 0.952339710805\n",
      "Validation Accuracy: k = 14; cut_freq = 3 ---> 0.963542644111\n",
      "Validation Accuracy: k = 14; cut_freq = 4 ---> 0.96007611227\n",
      "Validation Accuracy: k = 14; cut_freq = 5 ---> 0.95376615729\n",
      "Validation Accuracy: k = 14; cut_freq = 6 ---> 0.934873992765\n",
      "Validation Accuracy: k = 14; cut_freq = 7 ---> 0.936988417835\n",
      "Validation Accuracy: k = 14; cut_freq = 8 ---> 0.929233298803\n",
      "Validation Accuracy: k = 14; cut_freq = 9 ---> 0.914592286334\n",
      "Validation Accuracy: k = 14; cut_freq = 10 ---> 0.906136887189\n",
      "Validation Accuracy: k = 15; cut_freq = 2 ---> 0.958613513857\n",
      "Validation Accuracy: k = 15; cut_freq = 3 ---> 0.962877232718\n",
      "Validation Accuracy: k = 15; cut_freq = 4 ---> 0.961498974408\n",
      "Validation Accuracy: k = 15; cut_freq = 5 ---> 0.958665551657\n",
      "Validation Accuracy: k = 15; cut_freq = 6 ---> 0.948134180507\n",
      "Validation Accuracy: k = 15; cut_freq = 7 ---> 0.939724933678\n",
      "Validation Accuracy: k = 15; cut_freq = 8 ---> 0.923649775474\n",
      "Validation Accuracy: k = 15; cut_freq = 9 ---> 0.915982846169\n",
      "Validation Accuracy: k = 15; cut_freq = 10 ---> 0.908246444705\n",
      "Validation Accuracy: k = 16; cut_freq = 2 ---> 0.952340994013\n",
      "Validation Accuracy: k = 16; cut_freq = 3 ---> 0.96779021182\n",
      "Validation Accuracy: k = 16; cut_freq = 4 ---> 0.959440436763\n",
      "Validation Accuracy: k = 16; cut_freq = 5 ---> 0.959365831769\n",
      "Validation Accuracy: k = 16; cut_freq = 6 ---> 0.950268606355\n",
      "Validation Accuracy: k = 16; cut_freq = 7 ---> 0.934887577499\n",
      "Validation Accuracy: k = 16; cut_freq = 8 ---> 0.924373640709\n",
      "Validation Accuracy: k = 16; cut_freq = 9 ---> 0.911061149887\n",
      "Validation Accuracy: k = 16; cut_freq = 10 ---> 0.9061704727\n",
      "Validation Accuracy: k = 17; cut_freq = 2 ---> 0.957263973504\n",
      "Validation Accuracy: k = 17; cut_freq = 3 ---> 0.967066346585\n",
      "Validation Accuracy: k = 17; cut_freq = 4 ---> 0.962868515538\n",
      "Validation Accuracy: k = 17; cut_freq = 5 ---> 0.963576229621\n",
      "Validation Accuracy: k = 17; cut_freq = 6 ---> 0.950961452495\n",
      "Validation Accuracy: k = 17; cut_freq = 7 ---> 0.938438714722\n",
      "Validation Accuracy: k = 17; cut_freq = 8 ---> 0.92018682798\n",
      "Validation Accuracy: k = 17; cut_freq = 9 ---> 0.917375972422\n",
      "Validation Accuracy: k = 17; cut_freq = 10 ---> 0.918098554449\n",
      "Validation Accuracy: k = 18; cut_freq = 2 ---> 0.962813911321\n",
      "Validation Accuracy: k = 18; cut_freq = 3 ---> 0.966383500833\n",
      "Validation Accuracy: k = 18; cut_freq = 4 ---> 0.962859798358\n",
      "Validation Accuracy: k = 18; cut_freq = 5 ---> 0.961472822869\n",
      "Validation Accuracy: k = 18; cut_freq = 6 ---> 0.951650449011\n",
      "Validation Accuracy: k = 18; cut_freq = 7 ---> 0.934917313385\n",
      "Validation Accuracy: k = 18; cut_freq = 8 ---> 0.913864571474\n",
      "Validation Accuracy: k = 18; cut_freq = 9 ---> 0.916732862944\n",
      "Validation Accuracy: k = 18; cut_freq = 10 ---> 0.90629096473\n",
      "Validation Accuracy: k = 19; cut_freq = 2 ---> 0.957915800162\n",
      "Validation Accuracy: k = 19; cut_freq = 3 ---> 0.96713095119\n",
      "Validation Accuracy: k = 19; cut_freq = 4 ---> 0.969141035382\n",
      "Validation Accuracy: k = 19; cut_freq = 5 ---> 0.962865949121\n",
      "Validation Accuracy: k = 19; cut_freq = 6 ---> 0.949641648027\n",
      "Validation Accuracy: k = 19; cut_freq = 7 ---> 0.942009587442\n",
      "Validation Accuracy: k = 19; cut_freq = 8 ---> 0.927185779475\n",
      "Validation Accuracy: k = 19; cut_freq = 9 ---> 0.923761550325\n",
      "Validation Accuracy: k = 19; cut_freq = 10 ---> 0.914577418391\n",
      "Validation Accuracy: k = 20; cut_freq = 2 ---> 0.96213849954\n",
      "Validation Accuracy: k = 20; cut_freq = 3 ---> 0.968483057961\n",
      "Validation Accuracy: k = 20; cut_freq = 4 ---> 0.958675552045\n",
      "Validation Accuracy: k = 20; cut_freq = 5 ---> 0.964226773071\n",
      "Validation Accuracy: k = 20; cut_freq = 6 ---> 0.943334259464\n",
      "Validation Accuracy: k = 20; cut_freq = 7 ---> 0.935681180173\n",
      "Validation Accuracy: k = 20; cut_freq = 8 ---> 0.927872474853\n",
      "Validation Accuracy: k = 20; cut_freq = 9 ---> 0.922235630516\n",
      "Validation Accuracy: k = 20; cut_freq = 10 ---> 0.920955562322\n",
      "Validation Accuracy: k = 21; cut_freq = 2 ---> 0.959332511537\n",
      "Validation Accuracy: k = 21; cut_freq = 3 ---> 0.969215640375\n",
      "Validation Accuracy: k = 21; cut_freq = 4 ---> 0.953752572555\n",
      "Validation Accuracy: k = 21; cut_freq = 5 ---> 0.96219925452\n",
      "Validation Accuracy: k = 21; cut_freq = 6 ---> 0.946140247467\n",
      "Validation Accuracy: k = 21; cut_freq = 7 ---> 0.948900348433\n",
      "Validation Accuracy: k = 21; cut_freq = 8 ---> 0.92569087876\n",
      "Validation Accuracy: k = 21; cut_freq = 9 ---> 0.932050570402\n",
      "Validation Accuracy: k = 21; cut_freq = 10 ---> 0.925059052878\n",
      "Validation Accuracy: k = 22; cut_freq = 2 ---> 0.95935609666\n",
      "Validation Accuracy: k = 22; cut_freq = 3 ---> 0.966389651596\n",
      "Validation Accuracy: k = 22; cut_freq = 4 ---> 0.956552409795\n",
      "Validation Accuracy: k = 22; cut_freq = 5 ---> 0.96635119853\n",
      "Validation Accuracy: k = 22; cut_freq = 6 ---> 0.951653015427\n",
      "Validation Accuracy: k = 22; cut_freq = 7 ---> 0.941146512609\n",
      "Validation Accuracy: k = 22; cut_freq = 8 ---> 0.929210996888\n",
      "Validation Accuracy: k = 22; cut_freq = 9 ---> 0.930658727358\n",
      "Validation Accuracy: k = 22; cut_freq = 10 ---> 0.939046955481\n",
      "Validation Accuracy: k = 23; cut_freq = 2 ---> 0.958648382576\n",
      "Validation Accuracy: k = 23; cut_freq = 3 ---> 0.968506643083\n",
      "Validation Accuracy: k = 23; cut_freq = 4 ---> 0.963558795262\n",
      "Validation Accuracy: k = 23; cut_freq = 5 ---> 0.963608531924\n",
      "Validation Accuracy: k = 23; cut_freq = 6 ---> 0.957260123878\n",
      "Validation Accuracy: k = 23; cut_freq = 7 ---> 0.946749771435\n",
      "Validation Accuracy: k = 23; cut_freq = 8 ---> 0.932065438345\n",
      "Validation Accuracy: k = 23; cut_freq = 9 ---> 0.933520602786\n",
      "Validation Accuracy: k = 23; cut_freq = 10 ---> 0.939131560862\n",
      "Validation Accuracy: k = 24; cut_freq = 2 ---> 0.960056376772\n",
      "Validation Accuracy: k = 24; cut_freq = 3 ---> 0.970556463549\n",
      "Validation Accuracy: k = 24; cut_freq = 4 ---> 0.965650918418\n",
      "Validation Accuracy: k = 24; cut_freq = 5 ---> 0.966398368776\n",
      "Validation Accuracy: k = 24; cut_freq = 6 ---> 0.953751289347\n",
      "Validation Accuracy: k = 24; cut_freq = 7 ---> 0.943978652151\n",
      "Validation Accuracy: k = 24; cut_freq = 8 ---> 0.936264552601\n",
      "Validation Accuracy: k = 24; cut_freq = 9 ---> 0.92081891914\n",
      "Validation Accuracy: k = 24; cut_freq = 10 ---> 0.939096692143\n",
      "Validation Accuracy: k = 25; cut_freq = 2 ---> 0.962847496832\n",
      "Validation Accuracy: k = 25; cut_freq = 3 ---> 0.967089931708\n",
      "Validation Accuracy: k = 25; cut_freq = 4 ---> 0.962175669397\n",
      "Validation Accuracy: k = 25; cut_freq = 5 ---> 0.963598531536\n",
      "Validation Accuracy: k = 25; cut_freq = 6 ---> 0.950977603646\n",
      "Validation Accuracy: k = 25; cut_freq = 7 ---> 0.939176164691\n"
     ]
    }
   ],
   "source": [
    "cv3_results = {}\n",
    "for k in range(10, 31):\n",
    "    for cutoff in [2, 3, 4, 5, 6, 7, 8, 9, 10]:  # desired cutoff frequency of the filter, Hz\n",
    "        xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)\n",
    "        val_acc = 0.0\n",
    "        tra_acc = 0.0\n",
    "        for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "            hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "            hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                       label_enc.transform(ytrain[train_index]),\n",
    "                       np.tile(k, 20))\n",
    "\n",
    "            y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))\n",
    "            val_acc += (y_val_pred == ytrain[test_index]).mean()\n",
    "            \n",
    "            y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))\n",
    "            \n",
    "            tra_acc += (y_train_pred == ytrain[train_index]).mean()\n",
    "            \n",
    "        val_acc /= kf.get_n_splits()\n",
    "        print('Validation Accuracy: k = ' + str(k) + '; cut_freq = ' + str(cutoff) + ' ---> ' + str(val_acc))\n",
    "        \n",
    "        cv3_results[(k, cutoff)] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gaussian Mixture HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Note**:\n",
    "I was getting some results (70%) with these parameters when I was on version 0.2.0 but after updating to the latest\n",
    "version (0.2.1), GMMHMM hasn't been great and it's taking too long to run. There are some open issues on their Github which seem to suggest GMMHMM is a bit buggy atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0. ],\n",
       "       [ 0. ,  0.5,  0.5],\n",
       "       [ 0. ,  0. ,  1. ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_states = 3\n",
    "n_mix = 10\n",
    "# initial guess for EM\n",
    "pi0 = np.eye(1, n_states)[0] # start probability\n",
    "pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmmhmm = GMMHMM(n_components=n_states, \n",
    "                n_mix=n_mix,\n",
    "                covariance_type='diag',\n",
    "                init_params='mc',\n",
    "                n_iter=3,\n",
    "                random_state=rng)\n",
    "gmmhmm.startprob_ = pi0\n",
    "gmmhmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=None,\n",
       "    covars_weight=None, init_params='mc', means_prior=0.0,\n",
       "    means_weight=0.0, min_covar=0.001, n_components=3, n_iter=3, n_mix=10,\n",
       "    params='stmcw',\n",
       "    random_state=<mtrand.RandomState object at 0x000000000A48A3A8>,\n",
       "    startprob_prior=1.0, tol=0.01, transmat_prior=1.0, verbose=False,\n",
       "    weights_prior=1.0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(gmmhmm)\n",
    "hmm_classifier.fit(xtrain, label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20L, 429L)\n",
      "(20L,)\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.38694638694638694)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', (y_val_pred == yval).mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian Mixture Classifier (Zero Padded Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding sequances with zero so they all have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_seq(seq):\n",
    "    seq_len = seq.shape[0]\n",
    "    x = np.pad(seq[:, 0], (0, max_length - seq_len%max_length), 'constant')\n",
    "    y = np.pad(seq[:, 1], (0, max_length - seq_len%max_length), 'constant')\n",
    "    z = np.pad(seq[:, 2], (0, max_length - seq_len%max_length), 'constant')\n",
    "    return np.stack((x, y, z)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_zp = np.asarray([pad_seq(seq) for seq in xtrain])\n",
    "xtest_zp = np.asarray([pad_seq(seq) for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 250, 3)\n",
      "(1429, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_zp.shape)\n",
    "print(xtest_zp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GaussianMixtureClassifier():\n",
    "    '''\n",
    "    GaussianMixtureClassifier is classifier where a seperate GMM is trained on\n",
    "    different classes and it has a similar API to ski-learn classifiers\n",
    "    Parameters\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        K = int(np.max(y)+1)\n",
    "        self.models = []\n",
    "        for k in range(K):\n",
    "            model = GaussianMixture(**self.kwargs)\n",
    "            model.fit(X[y==k])\n",
    "            self.models.append(model)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        loglikelihood = [ model.score_samples(X) for model in self.models ]\n",
    "        return np.vstack(loglikelihood).argmax(axis=0)\n",
    "    \n",
    "    def score(self, X):\n",
    "        return self.predict(X)\n",
    "\n",
    "    def score_samples(self, X):\n",
    "        loglikelihood = [ model.score_samples(X) for model in self.models ]\n",
    "        return np.vstack(loglikelihood).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshaping the data into a two dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_zp = xtrain_zp.reshape(xtrain_zp.shape[0], xtrain_zp.shape[1]* xtrain_zp.shape[2])\n",
    "ytrain_zp = ytrain - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 750)\n",
      "set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_zp.shape)\n",
    "print(set(ytrain_zp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Diagonal Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.96680497925311204)\n",
      "('Accuracy: ', 0.97268907563025209)\n",
      "('Accuracy: ', 0.97027600849256901)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "    gmm_classifier = GaussianMixtureClassifier(n_components=10, covariance_type='diag', verbose=False, max_iter=1000)\n",
    "\n",
    "    gmm_classifier.fit(xtrain_zp[train_index], ytrain[train_index]-1)\n",
    "    accuracy = (gmm_classifier.predict(xtrain_zp[test_index]) == (ytrain[test_index] - 1)).mean()\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 1.0)\n",
      "('Accuracy: ', 0.99159663865546221)\n",
      "('Accuracy: ', 0.99150743099787686)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "    gmm_classifier = GaussianMixtureClassifier(n_components=10, covariance_type='full', verbose=False, max_iter=1000)\n",
    "    gmm_classifier.fit(xtrain_zp[train_index], ytrain[train_index]-1)\n",
    "    accuracy = (gmm_classifier.predict(xtrain_zp[test_index]) == (ytrain[test_index] - 1)).mean()\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-pass Filtering of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    filtered = np.empty_like(data)\n",
    "    \n",
    "    for i in range(filtered.shape[0]):\n",
    "        ll = np.zeros(data[i].shape)\n",
    "        \n",
    "        for j in range(3):\n",
    "            ll[:,j] = lfilter(b, a, data[i][:,j])\n",
    "        \n",
    "        filtered[i] = ll\n",
    "    return filtered\n",
    "\n",
    "# Filter requirements.\n",
    "order = 4\n",
    "fs = 200.0       # sample rate, Hz\n",
    "cutoff = 2  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=1, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = GaussianHMM(n_iter=10, random_state=seed)\n",
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(15, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.96887966804979253)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96409714889123543)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation on number of states, cutoff frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "order = 4\n",
    "fs = 200.0  \n",
    "\n",
    "hmm = GaussianHMM(n_iter=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: k = 10; cut_freq = 2 ---> 0.941175230565\n",
      "Validation Accuracy: k = 10; cut_freq = 3 ---> 0.974032995778\n"
     ]
    }
   ],
   "source": [
    "cv3_results = {}\n",
    "for k in range(10, 31):\n",
    "    for cutoff in [2, 3, 4, 5, 6, 7, 8, 9, 10]:  # desired cutoff frequency of the filter, Hz\n",
    "        xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)\n",
    "        val_acc = 0.0\n",
    "        tra_acc = 0.0\n",
    "        for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "            hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "            hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                       label_enc.transform(ytrain[train_index]),\n",
    "                       np.tile(k, 20))\n",
    "\n",
    "            y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))\n",
    "            val_acc += (y_val_pred == ytrain[test_index]).mean()\n",
    "            \n",
    "            y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))\n",
    "            \n",
    "            tra_acc += (y_train_pred == ytrain[train_index]).mean()\n",
    "            \n",
    "        val_acc /= kf.get_n_splits()\n",
    "        print('Validation Accuracy: k = ' + str(k) + '; cut_freq = ' + str(cutoff) + ' ---> ' + str(val_acc))\n",
    "        \n",
    "        cv3_results[(k, cutoff)] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix Material\n",
    "* scaling and guassian filter (although guassian filter didn't work) https://www.researchgate.net/publication/4090432_Principal_Component_Analysis_for_Online_Handwritten_Character_Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
