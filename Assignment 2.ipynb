{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 Assignment 2\n",
    "\n",
    "## *Tasks TODO*\n",
    "- parameter initialization\n",
    "- baseline (GMM model)\n",
    "- mean negative log probability\n",
    "- sample predictions.txt generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from scipy.misc import logsumexp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hmmlearn\n",
    "import sklearn\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it's version 0.2.1 (install from github, not pip)\n",
    "# pip install git+https://github.com/hmmlearn/hmmlearn.git\n",
    "hmmlearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "trainData = sio.loadmat('./trajectories_train.mat')\n",
    "testData = sio.loadmat('./trajectories_xtest.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the data\n",
    "xtrain = trainData['xtrain'].reshape((-1, ))\n",
    "ytrain = trainData['ytrain'].reshape((-1, ))\n",
    "kf = StratifiedKFold(n_splits = 3, random_state=rng)\n",
    "xtest = testData['xtest'].reshape((-1, ))\n",
    "key = trainData['key']\n",
    "key = [item[0] for item in key.reshape((-1, ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429,)\n",
      "(1429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "# print([sum(yval == i) for i in np.unique(ytrain)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = xtrain[idx]\n",
    "y = ytrain[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_char(data, label):\n",
    "    start_x = 0\n",
    "    start_y = 0\n",
    "    plt.plot(start_x, start_y, 'ro')\n",
    "    for vel_h, vel_v, alpha in zip(data[0,], data[1, ], 1/(1 + np.exp(-data[2, ]/np.sum(data[2, ])))):\n",
    "        start_x = start_x + vel_h\n",
    "        start_y = start_y + vel_v\n",
    "        plt.plot(start_x, start_y,'bo', alpha = alpha)\n",
    "    plt.title('Character ' + key[label-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgFfRKRGKOCLiNQIBXwRkRrx/wGWzexlR/gd6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5231235d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_char(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([seq.T for seq in xtrain])\n",
    "xtest = np.asarray([seq.T for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_max = np.max(np.vstack(xtrain), axis=0)\n",
    "train_min = np.min(np.vstack(xtrain), axis=0)\n",
    "def rescale(seq):\n",
    "    return (seq - train_min) / (train_max - train_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([rescale(seq) for seq in xtrain])\n",
    "xtest = np.asarray([rescale(seq) for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths_train = list(map(lambda x: x.shape[0], xtrain))\n",
    "lengths_test = list(map(lambda x: x.shape[0], xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder().fit(ytrain)\n",
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(hmm, sequence):\n",
    "\n",
    "    logprob_frame = hmm._compute_log_likelihood(sequence)\n",
    "    logprob_sequence, _ =  hmm._do_forward_pass(logprob_frame)\n",
    "\n",
    "    return logprob_sequence\n",
    "\n",
    "def log_likelihoods(hmm, sequences):\n",
    "\n",
    "    ll = lambda seq: log_likelihood(hmm, seq)\n",
    "\n",
    "    return np.fromiter(map(ll, sequences), dtype='float64')\n",
    "\n",
    "def log_likelihoods_cond(cond_hmms, sequences):\n",
    "\n",
    "    ll = lambda hmm: log_likelihoods(hmm, sequences)\n",
    "\n",
    "    return np.vstack(map(ll, cond_hmms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure to keep the init_params commented otherwise it doesn't work properly for some reason\n",
    "class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hmm=GaussianHMM()):\n",
    "        self.hmm = hmm\n",
    "        self.class_cond_hmms_ = []\n",
    "\n",
    "    def fit(self, sequences, labels, k):        \n",
    "        class_counts = np.bincount(labels).astype(np.float)\n",
    "        self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "        \n",
    "        for c in range(np.max(labels)+1):\n",
    "            sequences_c = sequences[labels == c]\n",
    "            X_c = np.vstack(sequences_c)\n",
    "            lengths_c = list(map(len, sequences_c))\n",
    "            class_cond_hmm = clone(self.hmm, safe=True)\n",
    "            n_states_k = k[c]\n",
    "            pi0 = np.eye(1, n_states_k)[0]\n",
    "            trans0 = np.diag(np.ones(n_states_k)) + np.diag(np.ones(n_states_k-1), 1)\n",
    "            trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "            class_cond_hmm.n_components = n_states_k\n",
    "            class_cond_hmm.startprob_ = pi0\n",
    "            class_cond_hmm.transmat_  = trans0\n",
    "            class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "            self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        # 20 x N matrix\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "        return np.argmax(log_post_unnorm, axis=0)\n",
    "    \n",
    "    def predict_proba(self, sequences):\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "        \n",
    "        prob_post_norm = np.empty_like(log_post_unnorm)\n",
    "        \n",
    "        for i in range(log_post_unnorm.shape[1]):\n",
    "            prob_post_norm[:,i] = log_post_unnorm[:,i] - logsumexp(log_post_unnorm[:,i].astype(np.float64))\n",
    "            \n",
    "        return prob_post_norm\n",
    "    \n",
    "    def generateSample(self, mClass, length):\n",
    "        sel_hmm = self.class_cond_hmms_[mClass]\n",
    "        x, _ = sel_hmm.sample(length)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian HMM (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT of warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=25, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = GaussianHMM(n_components=25, n_iter=10, random_state=seed)\n",
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.91286307053941906)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.92291446673706445)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -633.39330223  -716.73831282 -1377.33463369 ...,  -750.90688639\n",
      "   -128.17515324 -1401.87587089]\n",
      " [    0.         -2341.95148306  -344.99609696 ...,     0.          -346.90716614\n",
      "   -778.13818157]\n",
      " [ -824.58893235 -1130.92364706 -1396.54341597 ...,  -850.87611871\n",
      "   -603.47427926 -1372.08565754]\n",
      " ..., \n",
      " [ -222.52336559    -7.62166245  -294.64503342 ...,  -189.58760315     0.\n",
      "   -460.92047339]\n",
      " [ -289.35671958  -736.0336879   -332.15004121 ...,  -280.03336727\n",
      "   -341.75228536  -695.49955123]\n",
      " [ -568.16108403 -4283.55734376 -1351.77422705 ...,  -696.20962815\n",
      "  -1051.35831066 -1509.92952098]]\n"
     ]
    }
   ],
   "source": [
    "val_probs = hmm_classifier.predict_proba(xtrain[test_index])\n",
    "print(val_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0592816836187335"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_probs[(ytrain[test_index] - 1), range(len(test_index))].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs = hmm_classifier.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n"
     ]
    }
   ],
   "source": [
    "print(key[np.argmax(probs[:,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f522fb06790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 53\n",
    "x = xtest[index] * (train_max - train_min) + train_min\n",
    "plot_char(x.T, np.argmax(probs[:,index])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1018.722   -199.0742  -808.1758  -678.572   -463.2001  -440.4725\n",
      "  -235.9149  -445.2649  -222.8068  -215.0424  -418.1345  -258.7311\n",
      "  -310.8969  -292.6349 -1360.9975  -490.7667     0.      -236.0413\n",
      "  -279.045   -592.294 ]\n",
      "w\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(np.round(probs[:,idx], 4))\n",
    "print(key[np.argmax(probs[:,idx]) + 1])\n",
    "print(key[ytrain[train_index][idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with 28 states (Cross-Validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=28, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = GaussianHMM(n_components=28, n_iter=10, random_state=seed)\n",
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(28, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.9294605809128631)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96304118268215422)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_probs = hmm_classifier.predict_proba(xtrain[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9986246769641314"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_probs[(ytrain[test_index] - 1), range(len(test_index))].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g  h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  28   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  26   0   0   0   0  0   0   0   0   0   1   0   0   0   0   0   1   0   \n",
       "c   0   0  22   0   0   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  24   0   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  32   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  25  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  8   0   1   5   0   0   0   0   0   0   0   5   0   \n",
       "l   0   0   0   0   0   0  0  27   0   0   0   0   0   0   0   0   0   0   0   \n",
       "m   0   0   0   0   0   0  0   0  17   2   0   0   0   0   0   0   0   4   0   \n",
       "n   0   0   0   0   0   0  0   0   5  14   0   0   0   0   0   0   0   2   0   \n",
       "o   0   0   0   0   0   0  0   0   0   0  22   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0  0   0   0   0   0  24   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0  0   0   0   1   0   0  18   0   0   0   0   0   0   \n",
       "r   0   1   0   0   0   0  0   0   0   0   0   0   0  19   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0  0   0   0   0   0   0   0   0  22   0   0   0   0   \n",
       "u   2   0   0   0   0   0  0   0   1   1   0   0   0   0   0  12   0   6   0   \n",
       "v   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0  30   0   0   \n",
       "w   0   0   0   0   0   0  0   0   1   1   0   0   0   0   0   0   0  18   0   \n",
       "y   0   0   0   0   0   2  0   0   0   0   0   0   0   0   0   0   0   0  21   \n",
       "z   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  31  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[test_index], y_val_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g   h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "c   0   0  44   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  47   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  64   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  50   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  22   0   1   7   0   0   0   1   0   0   0   7   0   \n",
       "l   0   0   0   0   0   0   0  49   0   1   0   0   0   1   0   0   0   1   0   \n",
       "m   0   0   0   0   0   0   0   0  29   8   0   0   0   0   0   0   0   7   0   \n",
       "n   0   0   0   0   0   0   1   0  10  27   0   0   0   0   0   0   0   3   0   \n",
       "o   0   0   0   0   0   0   0   0   0   0  44   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0   0   0   0   2   0  44   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   \n",
       "r   0   1   0   0   0   0   2   0   0   1   0   0   0  34   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0   0   0   0   0   0   0   0   0  43   0   0   0   0   \n",
       "u   3   0   0   0   0   0   0   0   3   0   0   0   0   0   0  28   0   8   0   \n",
       "v   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60   0   0   \n",
       "w   0   0   0   0   0   0   0   0   3   2   0   0   0   0   0   0   0  33   0   \n",
       "y   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45   \n",
       "z   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  62  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[train_index], y_train_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations of validations confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with m, u, w\n",
    "* n gets mixed up with m, w\n",
    "* u gets mixed up with w\n",
    "\n",
    "### Observations of training confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with u, w\n",
    "* n gets mixed up with n, w, m\n",
    "* p gets mixed up with n\n",
    "* u gets mixed up with a, w\n",
    "* w gets mixed up with a, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random sample from the gmm for a certain class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf0IIUqpM+g3oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5231276350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myClass = [20]\n",
    "x = hmm_classifier.generateSample(label_enc.transform(myClass)[0], 200)\n",
    "x = x * (train_max - train_min) + train_min\n",
    "plot_char(x.T, myClass[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv1_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "#                       init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    correct = 0.0\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "#         hmm.startprob_ = pi0\n",
    "#         hmm.transmat_  = trans0\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]), np.tile(k, 20))\n",
    "        y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))\n",
    "        correct += np.sum(y_val_pred == ytrain[test_index])\n",
    "    accuracy = correct/xtrain.shape[0]\n",
    "    cv1_results[k] = accuracy\n",
    "    print('Accuracy', k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k,\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    class_cond_accuracies = {}\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]), np.tile(k, 20))\n",
    "        for label in label_enc.classes_:\n",
    "            class_cond_xtest = xtrain[test_index][ytrain[test_index] == label]\n",
    "            y_class_cond_pred = label_enc.inverse_transform(hmm_classifier.predict(class_cond_xtest))\n",
    "            class_cond_accuracy = (y_class_cond_pred == label).mean()\n",
    "            if (not class_cond_accuracies.has_key(label)):\n",
    "                class_cond_accuracies[label] = []\n",
    "            class_cond_accuracies[label] = class_cond_accuracies[label] + [class_cond_accuracy]\n",
    "\n",
    "    k_states_results = {}\n",
    "    for label in label_enc.classes_:\n",
    "        k_states_results[label] = np.mean(class_cond_accuracies[label])\n",
    "    cv2_results[k] = k_states_results\n",
    "    print('Average for k = ', k, np.mean(cv2_results[k].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.7977</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.4849</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.4683</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.7746</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8605</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.6278</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.6302</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a       b       c       d       e       g       h       l       m  \\\n",
       "5   0.9519  0.9524  0.9091  0.2240  0.9896  0.9733  0.1930  0.7977  0.5507   \n",
       "6   0.9638  0.9167  0.9545  1.0000  0.9896  1.0000  0.4386  0.8234  0.7161   \n",
       "7   0.9757  0.9048  0.9848  0.9855  0.9896  1.0000  0.3158  0.7972  0.5527   \n",
       "8   0.9877  0.9524  0.9848  1.0000  0.9896  1.0000  0.2281  0.8613  0.5672   \n",
       "9   0.9757  0.9643  1.0000  1.0000  0.9896  1.0000  0.2456  0.8979  0.6555   \n",
       "10  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.4561  0.9103  0.6403   \n",
       "11  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4737  0.8599  0.6416   \n",
       "12  1.0000  0.9405  1.0000  1.0000  0.9896  1.0000  0.4912  0.8727  0.6713   \n",
       "13  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.3860  0.8865  0.6713   \n",
       "14  0.9877  0.9405  1.0000  1.0000  0.9896  1.0000  0.4386  0.8481  0.6858   \n",
       "15  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.5263  0.8984  0.6548   \n",
       "16  1.0000  0.9405  1.0000  1.0000  0.9896  1.0000  0.5088  0.8471  0.6555   \n",
       "17  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.5088  0.8727  0.6410   \n",
       "18  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.3684  0.8471  0.6561   \n",
       "19  0.9877  0.9643  0.9848  1.0000  0.9896  1.0000  0.3684  0.8723  0.6700   \n",
       "20  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.4035  0.8732  0.6133   \n",
       "21  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.3860  0.9107  0.6561   \n",
       "22  0.9877  0.9762  1.0000  1.0000  0.9896  1.0000  0.4386  0.8979  0.6397   \n",
       "23  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4561  0.9107  0.6555   \n",
       "24  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4561  0.8979  0.6568   \n",
       "25  0.9877  0.9405  1.0000  1.0000  0.9896  1.0000  0.4561  0.8856  0.7003   \n",
       "26  0.9877  0.9286  1.0000  1.0000  0.9896  1.0000  0.4386  0.8727  0.6423   \n",
       "27  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4386  0.9112  0.6864   \n",
       "28  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.5439  0.9236  0.6258   \n",
       "29  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.3860  0.8979  0.6555   \n",
       "30  0.9877  0.9286  1.0000  1.0000  0.9896  1.0000  0.4737  0.9107  0.7161   \n",
       "\n",
       "         n       o       p       q       r       s       u       v       w  \\\n",
       "5   0.4349  0.9848  0.8720  0.8246  0.7044  1.0000  0.4848  0.9889  0.7254   \n",
       "6   0.4849  0.9545  0.9281  0.8947  0.7404  1.0000  0.4394  0.9889  0.6719   \n",
       "7   0.4683  0.9697  0.9281  0.9474  0.7746  0.9848  0.2973  0.9889  0.8614   \n",
       "8   0.5167  0.9697  0.9275  0.9649  0.8096  1.0000  0.5635  1.0000  0.8789   \n",
       "9   0.5016  0.9848  0.9143  0.9298  0.8263  0.9848  0.5332  1.0000  0.8956   \n",
       "10  0.5643  0.9848  0.9710  0.9474  0.8605  1.0000  0.6263  1.0000  0.8439   \n",
       "11  0.5635  0.9848  0.9432  0.9649  0.9307  0.9690  0.6732  1.0000  0.8623   \n",
       "12  0.5976  0.9848  0.9432  0.9474  0.8965  0.9848  0.6861  1.0000  0.8789   \n",
       "13  0.6786  0.9848  0.9432  0.9474  0.9307  1.0000  0.7338  1.0000  0.8614   \n",
       "14  0.6452  1.0000  0.9287  0.9474  0.9298  0.9683  0.7965  1.0000  0.8965   \n",
       "15  0.6286  1.0000  0.9565  0.9474  0.9649  0.9841  0.8124  0.9889  0.8798   \n",
       "16  0.6421  0.9848  0.9710  0.9474  0.9649  0.9841  0.7489  0.9889  0.8456   \n",
       "17  0.6929  0.9848  0.9710  0.9474  0.9474  0.9841  0.7338  0.9889  0.8439   \n",
       "18  0.6444  0.9848  0.9855  0.9474  0.9482  0.9841  0.7799  1.0000  0.8974   \n",
       "19  0.6278  1.0000  1.0000  0.9649  0.9474  0.9841  0.7345  0.9889  0.8807   \n",
       "20  0.6921  1.0000  0.9855  0.9649  0.9649  0.9841  0.8139  0.9889  0.8465   \n",
       "21  0.5952  1.0000  0.9710  0.9474  0.9649  1.0000  0.7626  1.0000  0.8623   \n",
       "22  0.5794  1.0000  1.0000  0.9649  0.9649  0.9841  0.8579  0.9889  0.8640   \n",
       "23  0.6778  1.0000  1.0000  0.9649  0.9474  0.9841  0.8276  1.0000  0.8982   \n",
       "24  0.7270  1.0000  0.9855  0.9825  0.9649  0.9841  0.8427  1.0000  0.8982   \n",
       "25  0.7103  1.0000  1.0000  0.9825  0.9649  0.9841  0.8283  1.0000  0.8982   \n",
       "26  0.6302  1.0000  0.9710  0.9825  0.9307  0.9841  0.8117  1.0000  0.9316   \n",
       "27  0.5976  1.0000  1.0000  0.9825  0.9482  0.9841  0.8593  1.0000  0.9149   \n",
       "28  0.6944  1.0000  0.9855  1.0000  0.9825  0.9841  0.7980  1.0000  0.9149   \n",
       "29  0.6468  1.0000  1.0000  0.9649  0.9482  0.9841  0.8593  1.0000  0.9316   \n",
       "30  0.6294  1.0000  1.0000  0.9825  0.9825  0.9841  0.8283  1.0000  0.9149   \n",
       "\n",
       "         y    z  \n",
       "5   1.0000  1.0  \n",
       "6   0.9855  1.0  \n",
       "7   0.9855  1.0  \n",
       "8   0.9855  1.0  \n",
       "9   0.9710  1.0  \n",
       "10  0.9710  1.0  \n",
       "11  0.9710  1.0  \n",
       "12  1.0000  1.0  \n",
       "13  1.0000  1.0  \n",
       "14  1.0000  1.0  \n",
       "15  1.0000  1.0  \n",
       "16  1.0000  1.0  \n",
       "17  1.0000  1.0  \n",
       "18  1.0000  1.0  \n",
       "19  1.0000  1.0  \n",
       "20  1.0000  1.0  \n",
       "21  1.0000  1.0  \n",
       "22  1.0000  1.0  \n",
       "23  1.0000  1.0  \n",
       "24  1.0000  1.0  \n",
       "25  1.0000  1.0  \n",
       "26  1.0000  1.0  \n",
       "27  1.0000  1.0  \n",
       "28  1.0000  1.0  \n",
       "29  1.0000  1.0  \n",
       "30  1.0000  1.0  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pandas.DataFrame(cv2_results).T\n",
    "result.columns = key\n",
    "result.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 22,  9,  6,  5,  6, 28, 28,  6, 24, 14, 19, 28, 28,  5, 27,  8,\n",
       "       26,  5,  5])"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highest n_states for each character\n",
    "np.asarray(range(5, 31))[np.argmax(np.asarray(result), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tested states\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 30, 20, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.939xx\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 20, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.93983402489626555\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.94190871369294604\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 15, 28, 26, 28, 28] 0.91701244813278004\n",
    "# [28, 28, 28, 28, 28, 28, 28, 10, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.91xx\n",
    "# [28, 28, 28, 28, 28, 28, 28, 21, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.94190871369294604\n",
    "# [28, 28, 28, 28, 28, 28, 15, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.92323651452282163\n",
    "\n",
    "# Winner\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining the classifier using the \"Optimized\" number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=5, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.array([28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.94190871369294604)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96620908130939809)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -838.53789163  -866.20130473 -1521.60357101 ...,  -948.10347455\n",
      "   -258.81700631 -1161.21450913]\n",
      " [    0.          -448.37640674  -510.48189047 ...,     0.          -434.55122135\n",
      "   -870.09897256]\n",
      " [ -849.2531351  -1055.65883609 -1594.84073063 ...,  -882.82262754\n",
      "   -846.64294652 -1412.24554064]\n",
      " ..., \n",
      " [ -236.32729772     0.          -309.7650569  ...,  -260.02998503     0.\n",
      "   -774.87969189]\n",
      " [ -337.92946153 -1140.67808692  -476.91474729 ...,  -393.33500004\n",
      "   -477.32471429 -1282.19656527]\n",
      " [ -872.44157002 -4453.37660467 -1503.87784827 ..., -1077.59177316\n",
      "  -1308.40051776 -1469.78607336]]\n"
     ]
    }
   ],
   "source": [
    "val_probs = hmm_classifier.predict_proba(xtrain[test_index])\n",
    "print(val_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8341696292056635"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_probs[(ytrain[test_index] - 1), range(len(test_index))].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture HMM (meh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    filtered = np.empty_like(data)\n",
    "    \n",
    "    for i in range(filtered.shape[0]):\n",
    "        ll = np.zeros(data[i].shape)\n",
    "        \n",
    "        for j in range(3):\n",
    "            ll[:,j] = lfilter(b, a, data[i][:,j])\n",
    "        \n",
    "        filtered[i] = ll\n",
    "    return filtered\n",
    "\n",
    "# Filter requirements.\n",
    "order = 4\n",
    "fs = 200.0       # sample rate, Hz\n",
    "cutoff = 2  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_states = 10\n",
    "\n",
    "# initial guess for EM\n",
    "# pi0 = np.eye(1, n_states)[0] # start probability\n",
    "# pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "# trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "# trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "# trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=n_states, \n",
    "#                   init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "# hmm.startprob_ = pi0\n",
    "# hmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT of warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(15, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.96887966804979253)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96409714889123543)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation on number of states, cutoff frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "order = 4\n",
    "fs = 200.0  \n",
    "\n",
    "hmm = GaussianHMM(n_components=n_states,\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: k = 10; cut_freq = 2 ---> 0.941175230565\n",
      "Validation Accuracy: k = 10; cut_freq = 3 ---> 0.974032995778\n",
      "Validation Accuracy: k = 10; cut_freq = 4 ---> 0.951644298248\n",
      "Validation Accuracy: k = 10; cut_freq = 5 ---> 0.951651732219\n",
      "Validation Accuracy: k = 10; cut_freq = 6 ---> 0.943244786528\n",
      "Validation Accuracy: k = 10; cut_freq = 7 ---> 0.929225864831\n",
      "Validation Accuracy: k = 10; cut_freq = 8 ---> 0.915280264919\n",
      "Validation Accuracy: k = 10; cut_freq = 9 ---> 0.906148170785\n",
      "Validation Accuracy: k = 10; cut_freq = 10 ---> 0.906148170785\n",
      "Validation Accuracy: k = 11; cut_freq = 2 ---> 0.947467751185\n",
      "Validation Accuracy: k = 11; cut_freq = 3 ---> 0.965722956995\n",
      "Validation Accuracy: k = 11; cut_freq = 4 ---> 0.956534975435\n",
      "Validation Accuracy: k = 11; cut_freq = 5 ---> 0.954533608424\n",
      "Validation Accuracy: k = 11; cut_freq = 6 ---> 0.947453901172\n",
      "Validation Accuracy: k = 11; cut_freq = 7 ---> 0.934897577887\n",
      "Validation Accuracy: k = 11; cut_freq = 8 ---> 0.925800352473\n",
      "Validation Accuracy: k = 11; cut_freq = 9 ---> 0.908948008025\n",
      "Validation Accuracy: k = 11; cut_freq = 10 ---> 0.914540248533\n",
      "Validation Accuracy: k = 12; cut_freq = 2 ---> 0.950240153677\n",
      "Validation Accuracy: k = 12; cut_freq = 3 ---> 0.965691937901\n",
      "Validation Accuracy: k = 12; cut_freq = 4 ---> 0.951664299024\n",
      "Validation Accuracy: k = 12; cut_freq = 5 ---> 0.959375832158\n",
      "Validation Accuracy: k = 12; cut_freq = 6 ---> 0.95101733992\n",
      "Validation Accuracy: k = 12; cut_freq = 7 ---> 0.93974108483\n",
      "Validation Accuracy: k = 12; cut_freq = 8 ---> 0.916679541935\n",
      "Validation Accuracy: k = 12; cut_freq = 9 ---> 0.908313615727\n",
      "Validation Accuracy: k = 12; cut_freq = 10 ---> 0.900598232968\n",
      "Validation Accuracy: k = 13; cut_freq = 2 ---> 0.950207851374\n",
      "Validation Accuracy: k = 13; cut_freq = 3 ---> 0.964266509345\n",
      "Validation Accuracy: k = 13; cut_freq = 4 ---> 0.953093311925\n",
      "Validation Accuracy: k = 13; cut_freq = 5 ---> 0.958015008207\n",
      "Validation Accuracy: k = 13; cut_freq = 6 ---> 0.946819508873\n",
      "Validation Accuracy: k = 13; cut_freq = 7 ---> 0.946053340948\n",
      "Validation Accuracy: k = 13; cut_freq = 8 ---> 0.925056486462\n",
      "Validation Accuracy: k = 13; cut_freq = 9 ---> 0.913143272656\n",
      "Validation Accuracy: k = 13; cut_freq = 10 ---> 0.909690590828\n",
      "Validation Accuracy: k = 14; cut_freq = 2 ---> 0.952339710805\n",
      "Validation Accuracy: k = 14; cut_freq = 3 ---> 0.963542644111\n",
      "Validation Accuracy: k = 14; cut_freq = 4 ---> 0.96007611227\n",
      "Validation Accuracy: k = 14; cut_freq = 5 ---> 0.95376615729\n",
      "Validation Accuracy: k = 14; cut_freq = 6 ---> 0.934873992765\n",
      "Validation Accuracy: k = 14; cut_freq = 7 ---> 0.936988417835\n",
      "Validation Accuracy: k = 14; cut_freq = 8 ---> 0.929233298803\n",
      "Validation Accuracy: k = 14; cut_freq = 9 ---> 0.914592286334\n",
      "Validation Accuracy: k = 14; cut_freq = 10 ---> 0.906136887189\n",
      "Validation Accuracy: k = 15; cut_freq = 2 ---> 0.958613513857\n",
      "Validation Accuracy: k = 15; cut_freq = 3 ---> 0.962877232718\n",
      "Validation Accuracy: k = 15; cut_freq = 4 ---> 0.961498974408\n",
      "Validation Accuracy: k = 15; cut_freq = 5 ---> 0.958665551657\n",
      "Validation Accuracy: k = 15; cut_freq = 6 ---> 0.948134180507\n",
      "Validation Accuracy: k = 15; cut_freq = 7 ---> 0.939724933678\n",
      "Validation Accuracy: k = 15; cut_freq = 8 ---> 0.923649775474\n",
      "Validation Accuracy: k = 15; cut_freq = 9 ---> 0.915982846169\n",
      "Validation Accuracy: k = 15; cut_freq = 10 ---> 0.908246444705\n",
      "Validation Accuracy: k = 16; cut_freq = 2 ---> 0.952340994013\n",
      "Validation Accuracy: k = 16; cut_freq = 3 ---> 0.96779021182\n",
      "Validation Accuracy: k = 16; cut_freq = 4 ---> 0.959440436763\n",
      "Validation Accuracy: k = 16; cut_freq = 5 ---> 0.959365831769\n",
      "Validation Accuracy: k = 16; cut_freq = 6 ---> 0.950268606355\n",
      "Validation Accuracy: k = 16; cut_freq = 7 ---> 0.934887577499\n",
      "Validation Accuracy: k = 16; cut_freq = 8 ---> 0.924373640709\n",
      "Validation Accuracy: k = 16; cut_freq = 9 ---> 0.911061149887\n",
      "Validation Accuracy: k = 16; cut_freq = 10 ---> 0.9061704727\n",
      "Validation Accuracy: k = 17; cut_freq = 2 ---> 0.957263973504\n",
      "Validation Accuracy: k = 17; cut_freq = 3 ---> 0.967066346585\n",
      "Validation Accuracy: k = 17; cut_freq = 4 ---> 0.962868515538\n",
      "Validation Accuracy: k = 17; cut_freq = 5 ---> 0.963576229621\n",
      "Validation Accuracy: k = 17; cut_freq = 6 ---> 0.950961452495\n",
      "Validation Accuracy: k = 17; cut_freq = 7 ---> 0.938438714722\n",
      "Validation Accuracy: k = 17; cut_freq = 8 ---> 0.92018682798\n",
      "Validation Accuracy: k = 17; cut_freq = 9 ---> 0.917375972422\n",
      "Validation Accuracy: k = 17; cut_freq = 10 ---> 0.918098554449\n",
      "Validation Accuracy: k = 18; cut_freq = 2 ---> 0.962813911321\n",
      "Validation Accuracy: k = 18; cut_freq = 3 ---> 0.966383500833\n",
      "Validation Accuracy: k = 18; cut_freq = 4 ---> 0.962859798358\n",
      "Validation Accuracy: k = 18; cut_freq = 5 ---> 0.961472822869\n",
      "Validation Accuracy: k = 18; cut_freq = 6 ---> 0.951650449011\n",
      "Validation Accuracy: k = 18; cut_freq = 7 ---> 0.934917313385\n",
      "Validation Accuracy: k = 18; cut_freq = 8 ---> 0.913864571474\n",
      "Validation Accuracy: k = 18; cut_freq = 9 ---> 0.916732862944\n",
      "Validation Accuracy: k = 18; cut_freq = 10 ---> 0.90629096473\n",
      "Validation Accuracy: k = 19; cut_freq = 2 ---> 0.957915800162\n",
      "Validation Accuracy: k = 19; cut_freq = 3 ---> 0.96713095119\n",
      "Validation Accuracy: k = 19; cut_freq = 4 ---> 0.969141035382\n",
      "Validation Accuracy: k = 19; cut_freq = 5 ---> 0.962865949121\n",
      "Validation Accuracy: k = 19; cut_freq = 6 ---> 0.949641648027\n",
      "Validation Accuracy: k = 19; cut_freq = 7 ---> 0.942009587442\n",
      "Validation Accuracy: k = 19; cut_freq = 8 ---> 0.927185779475\n",
      "Validation Accuracy: k = 19; cut_freq = 9 ---> 0.923761550325\n",
      "Validation Accuracy: k = 19; cut_freq = 10 ---> 0.914577418391\n",
      "Validation Accuracy: k = 20; cut_freq = 2 ---> 0.96213849954\n",
      "Validation Accuracy: k = 20; cut_freq = 3 ---> 0.968483057961\n",
      "Validation Accuracy: k = 20; cut_freq = 4 ---> 0.958675552045\n",
      "Validation Accuracy: k = 20; cut_freq = 5 ---> 0.964226773071\n",
      "Validation Accuracy: k = 20; cut_freq = 6 ---> 0.943334259464\n",
      "Validation Accuracy: k = 20; cut_freq = 7 ---> 0.935681180173\n",
      "Validation Accuracy: k = 20; cut_freq = 8 ---> 0.927872474853\n",
      "Validation Accuracy: k = 20; cut_freq = 9 ---> 0.922235630516\n",
      "Validation Accuracy: k = 20; cut_freq = 10 ---> 0.920955562322\n",
      "Validation Accuracy: k = 21; cut_freq = 2 ---> 0.959332511537\n",
      "Validation Accuracy: k = 21; cut_freq = 3 ---> 0.969215640375\n",
      "Validation Accuracy: k = 21; cut_freq = 4 ---> 0.953752572555\n",
      "Validation Accuracy: k = 21; cut_freq = 5 ---> 0.96219925452\n",
      "Validation Accuracy: k = 21; cut_freq = 6 ---> 0.946140247467\n",
      "Validation Accuracy: k = 21; cut_freq = 7 ---> 0.948900348433\n",
      "Validation Accuracy: k = 21; cut_freq = 8 ---> 0.92569087876\n",
      "Validation Accuracy: k = 21; cut_freq = 9 ---> 0.932050570402\n",
      "Validation Accuracy: k = 21; cut_freq = 10 ---> 0.925059052878\n",
      "Validation Accuracy: k = 22; cut_freq = 2 ---> 0.95935609666\n",
      "Validation Accuracy: k = 22; cut_freq = 3 ---> 0.966389651596\n",
      "Validation Accuracy: k = 22; cut_freq = 4 ---> 0.956552409795\n",
      "Validation Accuracy: k = 22; cut_freq = 5 ---> 0.96635119853\n",
      "Validation Accuracy: k = 22; cut_freq = 6 ---> 0.951653015427\n",
      "Validation Accuracy: k = 22; cut_freq = 7 ---> 0.941146512609\n",
      "Validation Accuracy: k = 22; cut_freq = 8 ---> 0.929210996888\n",
      "Validation Accuracy: k = 22; cut_freq = 9 ---> 0.930658727358\n",
      "Validation Accuracy: k = 22; cut_freq = 10 ---> 0.939046955481\n",
      "Validation Accuracy: k = 23; cut_freq = 2 ---> 0.958648382576\n",
      "Validation Accuracy: k = 23; cut_freq = 3 ---> 0.968506643083\n",
      "Validation Accuracy: k = 23; cut_freq = 4 ---> 0.963558795262\n",
      "Validation Accuracy: k = 23; cut_freq = 5 ---> 0.963608531924\n",
      "Validation Accuracy: k = 23; cut_freq = 6 ---> 0.957260123878\n",
      "Validation Accuracy: k = 23; cut_freq = 7 ---> 0.946749771435\n",
      "Validation Accuracy: k = 23; cut_freq = 8 ---> 0.932065438345\n",
      "Validation Accuracy: k = 23; cut_freq = 9 ---> 0.933520602786\n",
      "Validation Accuracy: k = 23; cut_freq = 10 ---> 0.939131560862\n",
      "Validation Accuracy: k = 24; cut_freq = 2 ---> 0.960056376772\n",
      "Validation Accuracy: k = 24; cut_freq = 3 ---> 0.970556463549\n",
      "Validation Accuracy: k = 24; cut_freq = 4 ---> 0.965650918418\n",
      "Validation Accuracy: k = 24; cut_freq = 5 ---> 0.966398368776\n",
      "Validation Accuracy: k = 24; cut_freq = 6 ---> 0.953751289347\n",
      "Validation Accuracy: k = 24; cut_freq = 7 ---> 0.943978652151\n",
      "Validation Accuracy: k = 24; cut_freq = 8 ---> 0.936264552601\n",
      "Validation Accuracy: k = 24; cut_freq = 9 ---> 0.92081891914\n",
      "Validation Accuracy: k = 24; cut_freq = 10 ---> 0.939096692143\n",
      "Validation Accuracy: k = 25; cut_freq = 2 ---> 0.962847496832\n",
      "Validation Accuracy: k = 25; cut_freq = 3 ---> 0.967089931708\n",
      "Validation Accuracy: k = 25; cut_freq = 4 ---> 0.962175669397\n",
      "Validation Accuracy: k = 25; cut_freq = 5 ---> 0.963598531536\n",
      "Validation Accuracy: k = 25; cut_freq = 6 ---> 0.950977603646\n",
      "Validation Accuracy: k = 25; cut_freq = 7 ---> 0.939176164691\n"
     ]
    }
   ],
   "source": [
    "cv3_results = {}\n",
    "for k in range(10, 31):\n",
    "    for cutoff in [2, 3, 4, 5, 6, 7, 8, 9, 10]:  # desired cutoff frequency of the filter, Hz\n",
    "        xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)\n",
    "        val_acc = 0.0\n",
    "        tra_acc = 0.0\n",
    "        for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "            hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "            hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                       label_enc.transform(ytrain[train_index]),\n",
    "                       np.tile(k, 20))\n",
    "\n",
    "            y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))\n",
    "            val_acc += (y_val_pred == ytrain[test_index]).mean()\n",
    "            \n",
    "            y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))\n",
    "            \n",
    "            tra_acc += (y_train_pred == ytrain[train_index]).mean()\n",
    "            \n",
    "        val_acc /= kf.get_n_splits()\n",
    "        print('Validation Accuracy: k = ' + str(k) + '; cut_freq = ' + str(cutoff) + ' ---> ' + str(val_acc))\n",
    "        \n",
    "        cv3_results[(k, cutoff)] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "I was getting some results (70%) with these parameters when I was on version 0.2.0 but after updating to the latest\n",
    "version (0.2.1), GMMHMM hasn't been great and it's taking too long to run. There are some open issues on their Github which seem to suggest GMMHMM is a bit buggy atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0. ],\n",
       "       [ 0. ,  0.5,  0.5],\n",
       "       [ 0. ,  0. ,  1. ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_states = 3\n",
    "n_mix = 10\n",
    "# initial guess for EM\n",
    "pi0 = np.eye(1, n_states)[0] # start probability\n",
    "pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmmhmm = GMMHMM(n_components=n_states, \n",
    "                n_mix=n_mix,\n",
    "                covariance_type='diag',\n",
    "                init_params='mc',\n",
    "                n_iter=3,\n",
    "                random_state=rng)\n",
    "gmmhmm.startprob_ = pi0\n",
    "gmmhmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=None,\n",
       "    covars_weight=None, init_params='mc', means_prior=0.0,\n",
       "    means_weight=0.0, min_covar=0.001, n_components=3, n_iter=3, n_mix=10,\n",
       "    params='stmcw',\n",
       "    random_state=<mtrand.RandomState object at 0x000000000A48A3A8>,\n",
       "    startprob_prior=1.0, tol=0.01, transmat_prior=1.0, verbose=False,\n",
       "    weights_prior=1.0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(gmmhmm)\n",
    "hmm_classifier.fit(xtrain, label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20L, 429L)\n",
      "(20L,)\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.38694638694638694)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', (y_val_pred == yval).mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian Mixture Classifier (Zero Padded Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding sequances with zero so they all have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_seq(seq):\n",
    "    seq_len = seq.shape[0]\n",
    "    x = np.pad(seq[:, 0], (0, max_length - seq_len%max_length), 'constant')\n",
    "    y = np.pad(seq[:, 1], (0, max_length - seq_len%max_length), 'constant')\n",
    "    z = np.pad(seq[:, 2], (0, max_length - seq_len%max_length), 'constant')\n",
    "    return np.stack((x, y, z)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_zp = np.asarray([pad_seq(seq) for seq in xtrain])\n",
    "xtest_zp = np.asarray([pad_seq(seq) for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 250, 3)\n",
      "(1429, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_zp.shape)\n",
    "print(xtest_zp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GaussianMixtureClassifier():\n",
    "    '''\n",
    "    GaussianMixtureClassifier is classifier where a seperate GMM is trained on\n",
    "    different classes and it has a similar API to ski-learn classifiers\n",
    "    Parameters\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        K = int(np.max(y)+1)\n",
    "        self.models = []\n",
    "        for k in range(K):\n",
    "            model = GaussianMixture(**self.kwargs)\n",
    "            model.fit(X[y==k])\n",
    "            self.models.append(model)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        loglikelihood = [ model.score_samples(X) for model in self.models ]\n",
    "        return np.vstack(loglikelihood).argmax(axis=0)\n",
    "    \n",
    "    def score(self, X):\n",
    "        return self.predict(X)\n",
    "\n",
    "    def score_samples(self, X):\n",
    "        loglikelihood = [ model.score_samples(X) for model in self.models ]\n",
    "        return np.vstack(loglikelihood).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshaping the data into a two dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_zp = xtrain_zp.reshape(xtrain_zp.shape[0], xtrain_zp.shape[1]* xtrain_zp.shape[2])\n",
    "ytrain_zp = ytrain - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 750)\n",
      "set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_zp.shape)\n",
    "print(set(ytrain_zp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Diagonal Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.96680497925311204)\n",
      "('Accuracy: ', 0.97268907563025209)\n",
      "('Accuracy: ', 0.97027600849256901)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "    gmm_classifier = GaussianMixtureClassifier(n_components=10, covariance_type='diag', verbose=False, max_iter=1000)\n",
    "\n",
    "    gmm_classifier.fit(xtrain_zp[train_index], ytrain[train_index]-1)\n",
    "    accuracy = (gmm_classifier.predict(xtrain_zp[test_index]) == (ytrain[test_index] - 1)).mean()\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 1.0)\n",
      "('Accuracy: ', 0.99159663865546221)\n",
      "('Accuracy: ', 0.99150743099787686)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "    gmm_classifier = GaussianMixtureClassifier(n_components=10, covariance_type='full', verbose=False, max_iter=1000)\n",
    "    gmm_classifier.fit(xtrain_zp[train_index], ytrain[train_index]-1)\n",
    "    accuracy = (gmm_classifier.predict(xtrain_zp[test_index]) == (ytrain[test_index] - 1)).mean()\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-pass Filtering of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    filtered = np.empty_like(data)\n",
    "    \n",
    "    for i in range(filtered.shape[0]):\n",
    "        ll = np.zeros(data[i].shape)\n",
    "        \n",
    "        for j in range(3):\n",
    "            ll[:,j] = lfilter(b, a, data[i][:,j])\n",
    "        \n",
    "        filtered[i] = ll\n",
    "    return filtered\n",
    "\n",
    "# Filter requirements.\n",
    "order = 4\n",
    "fs = 200.0       # sample rate, Hz\n",
    "cutoff = 3  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=1, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = GaussianHMM(n_iter=10, random_state=seed)\n",
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.98340248962655596)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.98416050686378032)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_probs = hmm_classifier.predict_proba(xtrain_filtered[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.69445443249061156"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_probs[(ytrain[test_index] - 1), range(len(test_index))].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pandas.DataFrame(val_probs)\n",
    "result.to_csv('./predictions.txt', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation on number of states, cutoff frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "order = 4\n",
    "fs = 200.0  \n",
    "\n",
    "hmm = GaussianHMM(n_iter=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: k = 10; cut_freq = 2 ---> 0.941175230565\n",
      "Validation Accuracy: k = 10; cut_freq = 3 ---> 0.974032995778\n"
     ]
    }
   ],
   "source": [
    "cv3_results = {}\n",
    "for k in range(10, 31):\n",
    "    for cutoff in [2, 3, 4, 5, 6, 7, 8, 9, 10]:  # desired cutoff frequency of the filter, Hz\n",
    "        xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)\n",
    "        val_acc = 0.0\n",
    "        tra_acc = 0.0\n",
    "        for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "            hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "            hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                       label_enc.transform(ytrain[train_index]),\n",
    "                       np.tile(k, 20))\n",
    "\n",
    "            y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))\n",
    "            val_acc += (y_val_pred == ytrain[test_index]).mean()\n",
    "            \n",
    "            y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))\n",
    "            \n",
    "            tra_acc += (y_train_pred == ytrain[train_index]).mean()\n",
    "            \n",
    "        val_acc /= kf.get_n_splits()\n",
    "        print('Validation Accuracy: k = ' + str(k) + '; cut_freq = ' + str(cutoff) + ' ---> ' + str(val_acc))\n",
    "        \n",
    "        cv3_results[(k, cutoff)] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix Material\n",
    "* scaling and guassian filter (although guassian filter didn't work) https://www.researchgate.net/publication/4090432_Principal_Component_Analysis_for_Online_Handwritten_Character_Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
