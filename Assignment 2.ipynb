{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 Assignment 2\n",
    "\n",
    "## *Tasks TODO*\n",
    "- parameter initialization\n",
    "- mean negative log probability\n",
    "- sample predictions.txt generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hmmlearn\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it's version 0.2.1 (install from github, not pip)\n",
    "# pip install git+https://github.com/hmmlearn/hmmlearn.git\n",
    "hmmlearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "trainData = sio.loadmat('./trajectories_train.mat')\n",
    "testData = sio.loadmat('./trajectories_xtest.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the data\n",
    "xtrain = trainData['xtrain'].reshape((1429))\n",
    "ytrain = trainData['ytrain'].reshape((1429))\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size=0.3, random_state=rng)\n",
    "xtest = testData['xtest'].reshape((1429))\n",
    "key = trainData['key']\n",
    "key = [item[0] for item in key.reshape((20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n",
      "(429,)\n",
      "(429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xval.shape)\n",
    "print(yval.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = xtrain[idx]\n",
    "y = ytrain[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_char(data):\n",
    "    start_x = 0\n",
    "    start_y = 0\n",
    "    plt.plot(start_x, start_y, 'ro')\n",
    "    for vel_h, vel_v, alpha in zip(data[0,], data[1, ], 1/(1 + np.exp(-x[2, ]/np.sum(x[1, ])))):\n",
    "        start_x = start_x + vel_h\n",
    "        start_y = start_y + vel_v\n",
    "        plt.plot(start_x, start_y,'bo', alpha = alpha)\n",
    "    plt.title('Character ' + key[y-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhP/D9a2td1pctsTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb8b24d208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_char(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([seq.T for seq in xtrain])\n",
    "xval = np.asarray([seq.T for seq in xval])\n",
    "xtest = np.asarray([seq.T for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xval.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths_train = list(map(lambda x: x.shape[0], xtrain))\n",
    "lengths_test = list(map(lambda x: x.shape[0], xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder().fit(ytrain)\n",
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(hmm, sequence):\n",
    "\n",
    "    logprob_frame = hmm._compute_log_likelihood(sequence)\n",
    "    logprob_sequence, _ =  hmm._do_forward_pass(logprob_frame)\n",
    "\n",
    "    return logprob_sequence\n",
    "\n",
    "def log_likelihoods(hmm, sequences):\n",
    "\n",
    "    ll = lambda seq: log_likelihood(hmm, seq)\n",
    "\n",
    "    return np.fromiter(map(ll, sequences), dtype='float64')\n",
    "\n",
    "def log_likelihoods_cond(cond_hmms, sequences):\n",
    "\n",
    "    ll = lambda hmm: log_likelihoods(hmm, sequences)\n",
    "\n",
    "    return np.vstack(map(ll, cond_hmms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, hmm=GaussianHMM()):\n",
    "\n",
    "        self.hmm = hmm\n",
    "        self.class_cond_hmms_ = []\n",
    "\n",
    "    def fit(self, sequences, labels):\n",
    "\n",
    "        class_counts = np.bincount(labels)\n",
    "        self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "\n",
    "        for c in range(np.max(labels)+1):\n",
    "\n",
    "            sequences_c = sequences[labels == c]\n",
    "\n",
    "            X_c = np.vstack(sequences_c)\n",
    "            lengths_c = list(map(len, sequences_c))\n",
    "            \n",
    "            class_cond_hmm = clone(self.hmm, safe=True)\n",
    "            class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "\n",
    "            self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, sequences):\n",
    "\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "        return np.argmax(log_post_unnorm, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0.5,  0.5,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0.5,  0.5,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0.5,  0.5],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  1. ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_states = 5\n",
    "\n",
    "# initial guess for EM\n",
    "pi0 = np.eye(1, n_states)[0] # start probability\n",
    "pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=n_states, \n",
    "                  init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "hmm.startprob_ = pi0\n",
    "hmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT fo warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='mc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=5, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "hmm_classifier.fit(xtrain, \n",
    "                   label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy 0.801864801865\n"
     ]
    }
   ],
   "source": [
    "print('Accuarcy', (y_val_pred == yval).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Corss Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy 5 0.801864801865\n",
      "Accuarcy 6 0.785547785548\n",
      "Accuarcy 7 0.862470862471\n",
      "Accuarcy 8 0.86013986014\n",
      "Accuarcy 9 0.890442890443\n",
      "Accuarcy 10 0.897435897436\n",
      "Accuarcy 11 0.892773892774\n",
      "Accuarcy 12 0.878787878788\n",
      "Accuarcy 13 0.888111888112\n",
      "Accuarcy 14 0.899766899767\n",
      "Accuarcy 15 0.916083916084\n",
      "Accuarcy 16 0.904428904429\n",
      "Accuarcy 17 0.911421911422\n",
      "Accuarcy 18 0.904428904429\n",
      "Accuarcy 19 0.932400932401\n",
      "Accuarcy 20 0.925407925408\n",
      "Accuarcy 21 0.913752913753\n",
      "Accuarcy 22 0.918414918415\n",
      "Accuarcy 23 0.920745920746\n",
      "Accuarcy 24 0.913752913753\n",
      "Accuarcy 25 0.909090909091\n",
      "Accuarcy 26 0.911421911422\n",
      "Accuarcy 27 0.918414918415\n",
      "Accuarcy 28 0.920745920746\n",
      "Accuarcy 29 0.916083916084\n",
      "Accuarcy 30 0.911421911422\n"
     ]
    }
   ],
   "source": [
    "cv1_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "                      init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    hmm.startprob_ = pi0\n",
    "    hmm.transmat_  = trans0\n",
    "    hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "    hmm_classifier.fit(xtrain, \n",
    "                       label_enc.transform(ytrain))\n",
    "    y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xval))\n",
    "    accuarcy = (y_val_pred == yval).mean()\n",
    "    cv1_results[k] = accuarcy\n",
    "    print('Accuarcy', k, accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "I was getting some results (70%) with these parameters when I was on version 0.2.0 but after updating to the latest\n",
    "version (0.2.1), GMMHMM hasn't been great and it's taking too long to run. There are some open issues on their Github which seem to suggest GMMHMM is a bit buggy atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0.5,  0.5,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0.5,  0.5,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0.5,  0.5],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  1. ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_states = 5\n",
    "n_mix = 1\n",
    "# initial guess for EM\n",
    "pi0 = np.eye(1, n_states)[0] # start probability\n",
    "pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmmhmm = GMMHMM(n_components=n_states, \n",
    "                n_mix=n_mix,\n",
    "                covariance_type='diag',\n",
    "                init_params='mc',\n",
    "                n_iter=500,\n",
    "                random_state=rng)\n",
    "gmmhmm.startprob_ = pi0\n",
    "gmmhmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-2a7ed5b891fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhmm_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerativeClassifierHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmmhmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhmm_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-ddf7646296a4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, sequences, labels)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mclass_cond_hmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mclass_cond_hmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_cond_hmms_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_cond_hmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwdlattice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframelogprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0mcurr_logprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0mbwdlattice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_backward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframelogprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0mposteriors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_posteriors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfwdlattice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwdlattice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 self._accumulate_sufficient_statistics(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36m_do_backward_pass\u001b[0;34m(self, framelogprob)\u001b[0m\n\u001b[1;32m    471\u001b[0m                         \u001b[0mlog_mask_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartprob_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                         \u001b[0mlog_mask_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransmat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                         framelogprob, bwdlattice)\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbwdlattice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(gmmhmm)\n",
    "hmm_classifier.fit(xtrain, label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuarcy', (y_val_pred == yval).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Corss Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
