{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 Assignment 2\n",
    "\n",
    "## *Tasks TODO*\n",
    "- parameter initialization\n",
    "- baseline (GMM model)\n",
    "- mean negative log probability\n",
    "- sample predictions.txt generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hmmlearn\n",
    "import sklearn\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it's version 0.2.1 (install from github, not pip)\n",
    "# pip install git+https://github.com/hmmlearn/hmmlearn.git\n",
    "hmmlearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.0'"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "trainData = sio.loadmat('./trajectories_train.mat')\n",
    "testData = sio.loadmat('./trajectories_xtest.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the data\n",
    "xtrain = trainData['xtrain'].reshape((-1, ))\n",
    "ytrain = trainData['ytrain'].reshape((-1, ))\n",
    "kf = StratifiedKFold(n_splits = 3, random_state=rng)\n",
    "xtest = testData['xtest'].reshape((-1, ))\n",
    "key = trainData['key']\n",
    "key = [item[0] for item in key.reshape((-1, ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429,)\n",
      "(1429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "# print([sum(yval == i) for i in np.unique(ytrain)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = xtrain[idx]\n",
    "y = ytrain[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_char(data, label):\n",
    "    start_x = 0\n",
    "    start_y = 0\n",
    "    plt.plot(start_x, start_y, 'ro')\n",
    "    for vel_h, vel_v, alpha in zip(data[0,], data[1, ], 1/(1 + np.exp(-data[2, ]/np.sum(data[1, ])))):\n",
    "        start_x = start_x + vel_h\n",
    "        start_y = start_y + vel_v\n",
    "        plt.plot(start_x, start_y,'bo', alpha = alpha)\n",
    "    plt.title('Character ' + key[label-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc86ae041d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_char(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([seq.T for seq in xtrain])\n",
    "xtest = np.asarray([seq.T for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_max = np.max(np.vstack(xtrain), axis=0)\n",
    "train_min = np.min(np.vstack(xtrain), axis=0)\n",
    "def rescale(seq):\n",
    "    return (seq - train_min) / (train_max - train_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([rescale(seq) for seq in xtrain])\n",
    "xtest = np.asarray([rescale(seq) for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths_train = list(map(lambda x: x.shape[0], xtrain))\n",
    "lengths_test = list(map(lambda x: x.shape[0], xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20], dtype=uint8)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder().fit(ytrain)\n",
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(hmm, sequence):\n",
    "\n",
    "    logprob_frame = hmm._compute_log_likelihood(sequence)\n",
    "    logprob_sequence, _ =  hmm._do_forward_pass(logprob_frame)\n",
    "\n",
    "    return logprob_sequence\n",
    "\n",
    "def log_likelihoods(hmm, sequences):\n",
    "\n",
    "    ll = lambda seq: log_likelihood(hmm, seq)\n",
    "\n",
    "    return np.fromiter(map(ll, sequences), dtype='float64')\n",
    "\n",
    "def log_likelihoods_cond(cond_hmms, sequences):\n",
    "\n",
    "    ll = lambda hmm: log_likelihoods(hmm, sequences)\n",
    "\n",
    "    return np.vstack(map(ll, cond_hmms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original Class we had that could only take in 1 n_state for all the HMMs\n",
    "\n",
    "# class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "#     def __init__(self, hmm=GaussianHMM()):\n",
    "\n",
    "#         self.hmm = hmm\n",
    "#         self.class_cond_hmms_ = []\n",
    "\n",
    "#     def fit(self, sequences, labels):\n",
    "\n",
    "#         class_counts = np.bincount(labels).astype(np.float)\n",
    "#         self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "\n",
    "#         for c in range(np.max(labels)+1):\n",
    "\n",
    "#             sequences_c = sequences[labels == c]\n",
    "\n",
    "#             X_c = np.vstack(sequences_c)\n",
    "#             lengths_c = list(map(len, sequences_c))\n",
    "            \n",
    "#             class_cond_hmm = clone(self.hmm, safe=True)\n",
    "#             class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "\n",
    "#             self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, sequences):\n",
    "#         # 20 x N matrix\n",
    "#         log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "#         log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "#         return np.argmax(log_post_unnorm, axis=0)\n",
    "    \n",
    "#     def generateSample(self, mClass, length):\n",
    "#         sel_hmm = self.class_cond_hmms_[mClass]\n",
    "#         x, _ = sel_hmm.sample(length)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure to keep the init_params commented otherwise it doesn't work properly for some reason\n",
    "\n",
    "class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hmm=GaussianHMM()):\n",
    "        self.hmm = hmm\n",
    "        self.class_cond_hmms_ = []\n",
    "\n",
    "    def fit(self, sequences, labels, k):        \n",
    "        class_counts = np.bincount(labels).astype(np.float)\n",
    "        self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "        \n",
    "        for c in range(np.max(labels)+1):\n",
    "            sequences_c = sequences[labels == c]\n",
    "            X_c = np.vstack(sequences_c)\n",
    "            lengths_c = list(map(len, sequences_c))\n",
    "            class_cond_hmm = clone(self.hmm, safe=True)\n",
    "            n_states_k = k[c]\n",
    "            pi0 = np.eye(1, n_states_k)[0]\n",
    "            trans0 = np.diag(np.ones(n_states_k)) + np.diag(np.ones(n_states_k-1), 1)\n",
    "            trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "            class_cond_hmm.n_components = n_states_k\n",
    "            class_cond_hmm.startprob_ = pi0\n",
    "            class_cond_hmm.transmat_  = trans0\n",
    "            class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "            self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        # 20 x N matrix\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "        return np.argmax(log_post_unnorm, axis=0)\n",
    "    \n",
    "    def generateSample(self, mClass, length):\n",
    "        sel_hmm = self.class_cond_hmms_[mClass]\n",
    "        x, _ = sel_hmm.sample(length)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_states = 10\n",
    "\n",
    "# initial guess for EM\n",
    "# pi0 = np.eye(1, n_states)[0] # start probability\n",
    "# pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "# trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "# trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "# trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=n_states, \n",
    "#                   init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "# hmm.startprob_ = pi0\n",
    "# hmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT of warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(25, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.93360995850622408)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96092925026399156)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g   h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  26   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   \n",
       "c   0   0  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  10   0   1   4   0   0   0   0   0   0   0   4   0   \n",
       "l   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   2   0   \n",
       "m   0   0   0   0   0   0   0   0  18   3   0   0   0   0   0   0   0   2   0   \n",
       "n   0   0   0   0   0   0   0   0   4  16   0   0   0   0   0   0   0   1   0   \n",
       "o   0   0   0   0   0   0   0   0   0   0  22   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0   0   0   0   0   0  24   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0   0   0   0   1   0   0  18   0   0   0   0   0   0   \n",
       "r   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22   0   0   0   0   \n",
       "u   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   4   0   \n",
       "v   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  30   0   0   \n",
       "w   0   0   0   0   0   0   0   0   2   1   0   0   0   0   0   1   0  16   0   \n",
       "y   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   \n",
       "z   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  31  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[test_index], y_val_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g   h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  55   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   \n",
       "c   0   0  44   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  47   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  64   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  50   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  24   0   1   7   0   0   0   0   0   0   0   6   0   \n",
       "l   0   0   0   0   0   0   3  48   0   0   0   0   0   0   0   0   0   1   0   \n",
       "m   0   0   0   0   0   0   2   0  37   2   0   0   0   0   0   0   0   3   0   \n",
       "n   0   0   0   0   0   0   0   0   3  35   0   0   0   0   0   0   0   3   0   \n",
       "o   0   0   0   0   0   0   0   0   0   0  44   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0   0   0   0   0   0  46   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   \n",
       "r   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0   0   0   0   0   0   0   0   0  43   0   0   0   0   \n",
       "u   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  39   0   3   0   \n",
       "v   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60   0   0   \n",
       "w   0   0   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0  36   0   \n",
       "y   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45   \n",
       "z   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  62  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[train_index], y_train_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations of validations confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with m, u, w\n",
    "* n gets mixed up with m, w\n",
    "* u gets mixed up with w\n",
    "\n",
    "### Observations of training confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with u, w\n",
    "* n gets mixed up with n, w, m\n",
    "* p gets mixed up with n\n",
    "* u gets mixed up with a, w\n",
    "* w gets mixed up with a, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random sample from the gmm for a certain class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc86911f750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myClass = [20]\n",
    "# ? Mattia, you had the following line but didn't run on mine until I added the [0]. Can you confirm?\n",
    "# x = hmm_classifier.generateSample(label_enc.transform(myClass), 200)\n",
    "x = hmm_classifier.generateSample(label_enc.transform(myClass)[0], 200)\n",
    "x = x * (train_max - train_min) + train_min\n",
    "plot_char(x.T, myClass[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 5, 0.7998600419874038)\n",
      "('Accuracy', 6, 0.8621413575927221)\n",
      "('Accuracy', 7, 0.8530440867739678)\n",
      "('Accuracy', 8, 0.8761371588523443)\n",
      "('Accuracy', 9, 0.8803358992302309)\n",
      "('Accuracy', 10, 0.8999300209937019)\n",
      "('Accuracy', 11, 0.900629811056683)\n",
      "('Accuracy', 12, 0.9062281315605318)\n",
      "('Accuracy', 13, 0.9097270818754374)\n",
      "('Accuracy', 14, 0.9111266620013996)\n",
      "('Accuracy', 15, 0.9188243526941917)\n",
      "('Accuracy', 16, 0.9118264520643807)\n",
      "('Accuracy', 17, 0.9132260321903429)\n",
      "('Accuracy', 18, 0.9111266620013996)\n",
      "('Accuracy', 19, 0.9104268719384184)\n",
      "('Accuracy', 20, 0.9146256123163051)\n",
      "('Accuracy', 21, 0.9125262421273618)\n",
      "('Accuracy', 22, 0.9181245626312107)\n",
      "('Accuracy', 23, 0.9230230930720784)\n",
      "('Accuracy', 24, 0.9258222533240028)\n",
      "('Accuracy', 25, 0.9258222533240028)\n",
      "('Accuracy', 26, 0.9153254023792862)\n",
      "('Accuracy', 27, 0.9230230930720784)\n",
      "('Accuracy', 28, 0.9286214135759272)\n",
      "('Accuracy', 29, 0.9209237228831351)\n",
      "('Accuracy', 30, 0.9258222533240028)\n"
     ]
    }
   ],
   "source": [
    "cv1_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "#                       init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    correct = 0.0\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "#         hmm.startprob_ = pi0\n",
    "#         hmm.transmat_  = trans0\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]), np.tile(k, 20))\n",
    "        y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))\n",
    "        correct += np.sum(y_val_pred == ytrain[test_index])\n",
    "    accuracy = correct/xtrain.shape[0]\n",
    "    cv1_results[k] = accuracy\n",
    "    print('Accuracy', k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "#                       init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    class_cond_accuracies = {}\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "#         hmm.startprob_ = pi0\n",
    "#         hmm.transmat_  = trans0\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]), np.tile(k, 20))\n",
    "        for label in label_enc.classes_:\n",
    "            class_cond_xtest = xtrain[test_index][ytrain[test_index] == label]\n",
    "            y_class_cond_pred = label_enc.inverse_transform(hmm_classifier.predict(class_cond_xtest))\n",
    "            class_cond_accuracy = (y_class_cond_pred == label).mean()\n",
    "            if (not class_cond_accuracies.has_key(label)):\n",
    "                class_cond_accuracies[label] = []\n",
    "            class_cond_accuracies[label] = class_cond_accuracies[label] + [class_cond_accuracy]\n",
    "\n",
    "    k_states_results = {}\n",
    "    for label in label_enc.classes_:\n",
    "        k_states_results[label] = np.mean(class_cond_accuracies[label])\n",
    "    cv2_results[k] = k_states_results\n",
    "    print('Average for k = ', k, np.mean(cv2_results[k].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.7977</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.4849</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.4683</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.7746</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8605</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.6278</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.6302</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a       b       c       d       e       g       h       l       m  \\\n",
       "5   0.9519  0.9524  0.9091  0.2240  0.9896  0.9733  0.1930  0.7977  0.5507   \n",
       "6   0.9638  0.9167  0.9545  1.0000  0.9896  1.0000  0.4386  0.8234  0.7161   \n",
       "7   0.9757  0.9048  0.9848  0.9855  0.9896  1.0000  0.3158  0.7972  0.5527   \n",
       "8   0.9877  0.9524  0.9848  1.0000  0.9896  1.0000  0.2281  0.8613  0.5672   \n",
       "9   0.9757  0.9643  1.0000  1.0000  0.9896  1.0000  0.2456  0.8979  0.6555   \n",
       "10  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.4561  0.9103  0.6403   \n",
       "11  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4737  0.8599  0.6416   \n",
       "12  1.0000  0.9405  1.0000  1.0000  0.9896  1.0000  0.4912  0.8727  0.6713   \n",
       "13  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.3860  0.8865  0.6713   \n",
       "14  0.9877  0.9405  1.0000  1.0000  0.9896  1.0000  0.4386  0.8481  0.6858   \n",
       "15  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.5263  0.8984  0.6548   \n",
       "16  1.0000  0.9405  1.0000  1.0000  0.9896  1.0000  0.5088  0.8471  0.6555   \n",
       "17  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.5088  0.8727  0.6410   \n",
       "18  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.3684  0.8471  0.6561   \n",
       "19  0.9877  0.9643  0.9848  1.0000  0.9896  1.0000  0.3684  0.8723  0.6700   \n",
       "20  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.4035  0.8732  0.6133   \n",
       "21  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.3860  0.9107  0.6561   \n",
       "22  0.9877  0.9762  1.0000  1.0000  0.9896  1.0000  0.4386  0.8979  0.6397   \n",
       "23  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4561  0.9107  0.6555   \n",
       "24  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4561  0.8979  0.6568   \n",
       "25  0.9877  0.9405  1.0000  1.0000  0.9896  1.0000  0.4561  0.8856  0.7003   \n",
       "26  0.9877  0.9286  1.0000  1.0000  0.9896  1.0000  0.4386  0.8727  0.6423   \n",
       "27  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4386  0.9112  0.6864   \n",
       "28  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.5439  0.9236  0.6258   \n",
       "29  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.3860  0.8979  0.6555   \n",
       "30  0.9877  0.9286  1.0000  1.0000  0.9896  1.0000  0.4737  0.9107  0.7161   \n",
       "\n",
       "         n       o       p       q       r       s       u       v       w  \\\n",
       "5   0.4349  0.9848  0.8720  0.8246  0.7044  1.0000  0.4848  0.9889  0.7254   \n",
       "6   0.4849  0.9545  0.9281  0.8947  0.7404  1.0000  0.4394  0.9889  0.6719   \n",
       "7   0.4683  0.9697  0.9281  0.9474  0.7746  0.9848  0.2973  0.9889  0.8614   \n",
       "8   0.5167  0.9697  0.9275  0.9649  0.8096  1.0000  0.5635  1.0000  0.8789   \n",
       "9   0.5016  0.9848  0.9143  0.9298  0.8263  0.9848  0.5332  1.0000  0.8956   \n",
       "10  0.5643  0.9848  0.9710  0.9474  0.8605  1.0000  0.6263  1.0000  0.8439   \n",
       "11  0.5635  0.9848  0.9432  0.9649  0.9307  0.9690  0.6732  1.0000  0.8623   \n",
       "12  0.5976  0.9848  0.9432  0.9474  0.8965  0.9848  0.6861  1.0000  0.8789   \n",
       "13  0.6786  0.9848  0.9432  0.9474  0.9307  1.0000  0.7338  1.0000  0.8614   \n",
       "14  0.6452  1.0000  0.9287  0.9474  0.9298  0.9683  0.7965  1.0000  0.8965   \n",
       "15  0.6286  1.0000  0.9565  0.9474  0.9649  0.9841  0.8124  0.9889  0.8798   \n",
       "16  0.6421  0.9848  0.9710  0.9474  0.9649  0.9841  0.7489  0.9889  0.8456   \n",
       "17  0.6929  0.9848  0.9710  0.9474  0.9474  0.9841  0.7338  0.9889  0.8439   \n",
       "18  0.6444  0.9848  0.9855  0.9474  0.9482  0.9841  0.7799  1.0000  0.8974   \n",
       "19  0.6278  1.0000  1.0000  0.9649  0.9474  0.9841  0.7345  0.9889  0.8807   \n",
       "20  0.6921  1.0000  0.9855  0.9649  0.9649  0.9841  0.8139  0.9889  0.8465   \n",
       "21  0.5952  1.0000  0.9710  0.9474  0.9649  1.0000  0.7626  1.0000  0.8623   \n",
       "22  0.5794  1.0000  1.0000  0.9649  0.9649  0.9841  0.8579  0.9889  0.8640   \n",
       "23  0.6778  1.0000  1.0000  0.9649  0.9474  0.9841  0.8276  1.0000  0.8982   \n",
       "24  0.7270  1.0000  0.9855  0.9825  0.9649  0.9841  0.8427  1.0000  0.8982   \n",
       "25  0.7103  1.0000  1.0000  0.9825  0.9649  0.9841  0.8283  1.0000  0.8982   \n",
       "26  0.6302  1.0000  0.9710  0.9825  0.9307  0.9841  0.8117  1.0000  0.9316   \n",
       "27  0.5976  1.0000  1.0000  0.9825  0.9482  0.9841  0.8593  1.0000  0.9149   \n",
       "28  0.6944  1.0000  0.9855  1.0000  0.9825  0.9841  0.7980  1.0000  0.9149   \n",
       "29  0.6468  1.0000  1.0000  0.9649  0.9482  0.9841  0.8593  1.0000  0.9316   \n",
       "30  0.6294  1.0000  1.0000  0.9825  0.9825  0.9841  0.8283  1.0000  0.9149   \n",
       "\n",
       "         y    z  \n",
       "5   1.0000  1.0  \n",
       "6   0.9855  1.0  \n",
       "7   0.9855  1.0  \n",
       "8   0.9855  1.0  \n",
       "9   0.9710  1.0  \n",
       "10  0.9710  1.0  \n",
       "11  0.9710  1.0  \n",
       "12  1.0000  1.0  \n",
       "13  1.0000  1.0  \n",
       "14  1.0000  1.0  \n",
       "15  1.0000  1.0  \n",
       "16  1.0000  1.0  \n",
       "17  1.0000  1.0  \n",
       "18  1.0000  1.0  \n",
       "19  1.0000  1.0  \n",
       "20  1.0000  1.0  \n",
       "21  1.0000  1.0  \n",
       "22  1.0000  1.0  \n",
       "23  1.0000  1.0  \n",
       "24  1.0000  1.0  \n",
       "25  1.0000  1.0  \n",
       "26  1.0000  1.0  \n",
       "27  1.0000  1.0  \n",
       "28  1.0000  1.0  \n",
       "29  1.0000  1.0  \n",
       "30  1.0000  1.0  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pandas.DataFrame(cv2_results).T\n",
    "result.columns = key\n",
    "result.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 22,  9,  6,  5,  6, 28, 28,  6, 24, 14, 19, 28, 28,  5, 27,  8,\n",
       "       26,  5,  5])"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highest n_states for each character\n",
    "np.asarray(range(5, 31))[np.argmax(np.asarray(result), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handpicked highest\n",
    "# [12, 22, 10, 10, 10, 10, 28, 28, 10, 24, 14, 19, 28, 28, 10, 27, 10, 26, 10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining the classifier using the \"Optimized\" number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.array([12, 22, 10, 10, 10, 10, 28, 28, 10, 24, 14, 19, 28, 28, 10, 27, 10, 26, 10, 10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.90663900414937759)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.92713833157338965)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian HMM with different states per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenerativeClassifierHMMCV(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, k=range(3,9)):\n",
    "        self.class_cond_hmms_ = []\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, sequences, labels):\n",
    "        kf = KFold(n_splits = 3)\n",
    "        class_counts = np.bincount(labels).astype(np.float)\n",
    "        self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "\n",
    "        for c in range(np.max(labels)+1):\n",
    "            sequences_c = sequences[labels == c]\n",
    "            sequences_not_c = sequences[labels != c]\n",
    "\n",
    "            lengths_c = np.array(list(map(len, sequences_c)))\n",
    "            log_likels = {}\n",
    "            for n_states in self.k: \n",
    "                pi0 = np.eye(1, n_states)[0] # start probability\n",
    "\n",
    "                trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "                trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "                \n",
    "                hmm = GaussianHMM(n_components=n_states, \n",
    "                  init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "                \n",
    "                log_likel = 0\n",
    "                for train_index, test_index in kf.split(sequences_c):\n",
    "                    hmm.startprob_ = pi0\n",
    "                    hmm.transmat_  = trans0\n",
    "                    \n",
    "                    X_c = np.vstack(sequences_c[train_index])\n",
    "                    \n",
    "                    hmm.fit(X_c, lengths=lengths_c[train_index])\n",
    "                    log_likel += np.sum(log_likelihoods(hmm, sequences_c[test_index]))\n",
    "                    \n",
    "                log_likels[n_states] = log_likel\n",
    "                print('Label ' + str(c) + ' for states ' + str(n_states) + ': Log in class ' + \n",
    "                      str(log_likel) + \n",
    "                      '\\nmax log off class ' + str(np.max(log_likelihoods(hmm, sequences_not_c)))\n",
    "                     + '\\n min log in class ' + str(np.min(log_likelihoods(hmm, sequences_c))))\n",
    "                \n",
    "#             self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        # 20 x N matrix\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "        return np.argmax(log_post_unnorm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm_classifier_CV = GenerativeClassifierHMMCV(k = range(15, 31))\n",
    "hmm_classifier_CV.fit(xtrain, \n",
    "                   label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "I was getting some results (70%) with these parameters when I was on version 0.2.0 but after updating to the latest\n",
    "version (0.2.1), GMMHMM hasn't been great and it's taking too long to run. There are some open issues on their Github which seem to suggest GMMHMM is a bit buggy atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0. ],\n",
       "       [ 0. ,  0.5,  0.5],\n",
       "       [ 0. ,  0. ,  1. ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_states = 3\n",
    "n_mix = 10\n",
    "# initial guess for EM\n",
    "pi0 = np.eye(1, n_states)[0] # start probability\n",
    "pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmmhmm = GMMHMM(n_components=n_states, \n",
    "                n_mix=n_mix,\n",
    "                covariance_type='diag',\n",
    "                init_params='mc',\n",
    "                n_iter=3,\n",
    "                random_state=rng)\n",
    "gmmhmm.startprob_ = pi0\n",
    "gmmhmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=None,\n",
       "    covars_weight=None, init_params='mc', means_prior=0.0,\n",
       "    means_weight=0.0, min_covar=0.001, n_components=3, n_iter=3, n_mix=10,\n",
       "    params='stmcw',\n",
       "    random_state=<mtrand.RandomState object at 0x000000000A48A3A8>,\n",
       "    startprob_prior=1.0, tol=0.01, transmat_prior=1.0, verbose=False,\n",
       "    weights_prior=1.0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(gmmhmm)\n",
    "hmm_classifier.fit(xtrain, label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20L, 429L)\n",
      "(20L,)\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.38694638694638694)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', (y_val_pred == yval).mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix Material\n",
    "* scaling and guassian filter (although guassian filter didn't work) https://www.researchgate.net/publication/4090432_Principal_Component_Analysis_for_Online_Handwritten_Character_Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
