{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 Assignment 2\n",
    "\n",
    "## *Tasks TODO*\n",
    "- parameter initialization\n",
    "- mean negative log probability\n",
    "- sample predictions.txt generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hmmlearn\n",
    "import sklearn\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it's version 0.2.1 (install from github, not pip)\n",
    "# pip install git+https://github.com/hmmlearn/hmmlearn.git\n",
    "hmmlearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.0'"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "trainData = sio.loadmat('./trajectories_train.mat')\n",
    "testData = sio.loadmat('./trajectories_xtest.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the data\n",
    "xtrain = trainData['xtrain'].reshape((-1, ))\n",
    "ytrain = trainData['ytrain'].reshape((-1, ))\n",
    "kf = StratifiedKFold(n_splits = 3, random_state=rng)\n",
    "xtest = testData['xtest'].reshape((-1, ))\n",
    "key = trainData['key']\n",
    "key = [item[0] for item in key.reshape((-1, ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429,)\n",
      "(1429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "# print([sum(yval == i) for i in np.unique(ytrain)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = xtrain[idx]\n",
    "y = ytrain[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_char(data, label):\n",
    "    start_x = 0\n",
    "    start_y = 0\n",
    "    plt.plot(start_x, start_y, 'ro')\n",
    "    for vel_h, vel_v, alpha in zip(data[0,], data[1, ], 1/(1 + np.exp(-data[2, ]/np.sum(data[1, ])))):\n",
    "        start_x = start_x + vel_h\n",
    "        start_y = start_y + vel_v\n",
    "        plt.plot(start_x, start_y,'bo', alpha = alpha)\n",
    "    plt.title('Character ' + key[label-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc868c09a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_char(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([seq.T for seq in xtrain])\n",
    "xtest = np.asarray([seq.T for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_max = np.max(np.vstack(xtrain), axis=0)\n",
    "train_min = np.min(np.vstack(xtrain), axis=0)\n",
    "def rescale(seq):\n",
    "    return (seq - train_min) / (train_max - train_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([rescale(seq) for seq in xtrain])\n",
    "xtest = np.asarray([rescale(seq) for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429,)\n",
      "(1429,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths_train = list(map(lambda x: x.shape[0], xtrain))\n",
    "lengths_test = list(map(lambda x: x.shape[0], xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20], dtype=uint8)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder().fit(ytrain)\n",
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(hmm, sequence):\n",
    "\n",
    "    logprob_frame = hmm._compute_log_likelihood(sequence)\n",
    "    logprob_sequence, _ =  hmm._do_forward_pass(logprob_frame)\n",
    "\n",
    "    return logprob_sequence\n",
    "\n",
    "def log_likelihoods(hmm, sequences):\n",
    "\n",
    "    ll = lambda seq: log_likelihood(hmm, seq)\n",
    "\n",
    "    return np.fromiter(map(ll, sequences), dtype='float64')\n",
    "\n",
    "def log_likelihoods_cond(cond_hmms, sequences):\n",
    "\n",
    "    ll = lambda hmm: log_likelihoods(hmm, sequences)\n",
    "\n",
    "    return np.vstack(map(ll, cond_hmms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original Class we had that could only take in 1 n_state for all the HMMs\n",
    "\n",
    "# class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "#     def __init__(self, hmm=GaussianHMM()):\n",
    "\n",
    "#         self.hmm = hmm\n",
    "#         self.class_cond_hmms_ = []\n",
    "\n",
    "#     def fit(self, sequences, labels):\n",
    "\n",
    "#         class_counts = np.bincount(labels).astype(np.float)\n",
    "#         self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "\n",
    "#         for c in range(np.max(labels)+1):\n",
    "\n",
    "#             sequences_c = sequences[labels == c]\n",
    "\n",
    "#             X_c = np.vstack(sequences_c)\n",
    "#             lengths_c = list(map(len, sequences_c))\n",
    "            \n",
    "#             class_cond_hmm = clone(self.hmm, safe=True)\n",
    "#             class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "\n",
    "#             self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, sequences):\n",
    "#         # 20 x N matrix\n",
    "#         log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "#         log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "#         return np.argmax(log_post_unnorm, axis=0)\n",
    "    \n",
    "#     def generateSample(self, mClass, length):\n",
    "#         sel_hmm = self.class_cond_hmms_[mClass]\n",
    "#         x, _ = sel_hmm.sample(length)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure to keep the init_params commented otherwise it doesn't work properly for some reason\n",
    "\n",
    "class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hmm=GaussianHMM()):\n",
    "        self.hmm = hmm\n",
    "        self.class_cond_hmms_ = []\n",
    "\n",
    "    def fit(self, sequences, labels, k):        \n",
    "        class_counts = np.bincount(labels).astype(np.float)\n",
    "        self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "        \n",
    "        for c in range(np.max(labels)+1):\n",
    "            sequences_c = sequences[labels == c]\n",
    "            X_c = np.vstack(sequences_c)\n",
    "            lengths_c = list(map(len, sequences_c))\n",
    "            class_cond_hmm = clone(self.hmm, safe=True)\n",
    "            n_states_k = k[c]\n",
    "            pi0 = np.eye(1, n_states_k)[0]\n",
    "            trans0 = np.diag(np.ones(n_states_k)) + np.diag(np.ones(n_states_k-1), 1)\n",
    "            trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "            class_cond_hmm.n_components = n_states_k\n",
    "            class_cond_hmm.startprob_ = pi0\n",
    "            class_cond_hmm.transmat_  = trans0\n",
    "            class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "            self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        # 20 x N matrix\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "        return np.argmax(log_post_unnorm, axis=0)\n",
    "    \n",
    "    def generateSample(self, mClass, length):\n",
    "        sel_hmm = self.class_cond_hmms_[mClass]\n",
    "        x, _ = sel_hmm.sample(length)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# n_states = 10\n",
    "\n",
    "# # initial guess for EM\n",
    "# pi0 = np.eye(1, n_states)[0] # start probability\n",
    "# pi0\n",
    "\n",
    "# # initial guess for EM\n",
    "# # transition matrix\n",
    "# trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "# trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "# trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=n_states, \n",
    "#                   init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "# hmm.startprob_ = pi0\n",
    "# hmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT of warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.91286307053941906)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.92291446673706445)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g  h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  28   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  26   0   0   0   0  0   0   0   0   0   1   0   0   0   0   0   1   0   \n",
       "c   0   0  22   0   0   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  24   0   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  32   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  25  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  8   0   1   5   0   0   0   0   0   0   0   5   0   \n",
       "l   0   0   0   0   0   0  0  27   0   0   0   0   0   0   0   0   0   0   0   \n",
       "m   0   0   0   0   0   0  0   0  17   2   0   0   0   0   0   0   0   4   0   \n",
       "n   0   0   0   0   0   0  0   0   5  14   0   0   0   0   0   0   0   2   0   \n",
       "o   0   0   0   0   0   0  0   0   0   0  22   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0  0   0   0   0   0  24   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0  0   0   0   1   0   0  18   0   0   0   0   0   0   \n",
       "r   0   1   0   0   0   0  0   0   0   0   0   0   0  19   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0  0   0   0   0   0   0   0   0  22   0   0   0   0   \n",
       "u   2   0   0   0   0   0  0   0   1   1   0   0   0   0   0  12   0   6   0   \n",
       "v   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0  30   0   0   \n",
       "w   0   0   0   0   0   0  0   0   1   1   0   0   0   0   0   0   0  18   0   \n",
       "y   0   0   0   0   0   2  0   0   0   0   0   0   0   0   0   0   0   0  21   \n",
       "z   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  31  "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[test_index], y_val_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g   h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "c   0   0  44   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  47   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  64   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  50   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  22   0   1   7   0   0   0   1   0   0   0   7   0   \n",
       "l   0   0   0   0   0   0   0  49   0   1   0   0   0   1   0   0   0   1   0   \n",
       "m   0   0   0   0   0   0   0   0  29   8   0   0   0   0   0   0   0   7   0   \n",
       "n   0   0   0   0   0   0   1   0  10  27   0   0   0   0   0   0   0   3   0   \n",
       "o   0   0   0   0   0   0   0   0   0   0  44   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0   0   0   0   2   0  44   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   \n",
       "r   0   1   0   0   0   0   2   0   0   1   0   0   0  34   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0   0   0   0   0   0   0   0   0  43   0   0   0   0   \n",
       "u   3   0   0   0   0   0   0   0   3   0   0   0   0   0   0  28   0   8   0   \n",
       "v   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60   0   0   \n",
       "w   0   0   0   0   0   0   0   0   3   2   0   0   0   0   0   0   0  33   0   \n",
       "y   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45   \n",
       "z   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  62  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[train_index], y_train_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations of validations confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with m, u, w\n",
    "* n gets mixed up with m, w\n",
    "* u gets mixed up with w\n",
    "\n",
    "### Observations of training confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with u, w\n",
    "* n gets mixed up with n, w, m\n",
    "* p gets mixed up with n\n",
    "* u gets mixed up with a, w\n",
    "* w gets mixed up with a, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random sample from the gmm for a certain class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuU1NWV6PHvDk+VR7eIoDQNGNEBuluSdFAniZOHiZoJ\nAk1m4szkKgKLm1kmJgFN4tVENDEzSwGNxkzCJHidpblmxm5eOnnIJNGZiYio0NUNMUGQ7vaBjdAN\nRHmf+8eu39Svm+pnPX6v/VmrV1X9qrrqVD92nd8++5wjzjmMMcbE33uCboAxxpjisIBvjDEJYQHf\nGGMSwgK+McYkhAV8Y4xJCAv4xhiTEBbwTSSJyFIReSTodhgTJRbwTWiJyN+KyGYROSQib4jIz0Xk\nw0G3y09E5onIfwXdDmN6wwK+CSURWQzcB3wXGAOUAw8CVxfgtQbm+zmj8NomeSzgm9ARkZHAncAN\nzrk659yfnHPHnHNPOOe+5nvoYBH5FxE5KCKNIlLte45viMgr6fu2icgc333zROS/ReReEXkbWCoi\n7xWRX4vI2yKyV0QeFZES3/eMF5E6EWlNP+b7IjIF+CFwafospC392CEiskxEmkRkj4j8UEROS9/3\nURFpEZGvi8ibwENZ3r+/fW0islNE/jx9vFlE3hKR6/L8YzcJYAHfhNGlwFBgdQ+Puxp4DCgB1gHf\n9933CvARYCRwB/CIiJzju/9iYCd69nAXIMA/AOcCU4DxwFIAERkAPAHsBiYC44DHnHPbgS8Azzrn\nhjnnvA+IfwQuAKYD56cf/y3fa48FzgQmAIu6eG8XA/XAKOCn6ff5wfTzfR74vogM6+HnY0xHzjn7\nsq9QfQF/B7zZw2OWAht8t6cC73bz+C3ArPT1eUBTD88/G3gpff1SoBUYmOVx84D/8t0W4E/Ae33H\nLgV2pa9/FDgKDO3mtecBf/TdrgQcMMZ37G1getC/K/uK1pflD00YvQ2cJSIDnXPHu3ncm77r7wBD\nve8RkWuBxWiPHGAYcJbv8c3+JxKRMcD30LOC4ejZ7/703eOB3T20xTMaOB14QUT+5+mBAb7HtDrn\nDvfwPHt8198FcM51PmY9fNMnltIxYfQscATtZfeZiEwA/hn4IjDKaaqlAQ28ns7LxH43fazSOTcC\nTZt4j28GyrsYYO38PHvRYDzNOVeS/hrpnBvWzfcYUxQW8E3oOOfa0Zz3gyIyW0ROF5FBInKViNzd\ni6c4Aw2qrQAicj1Q0cP3DAcOAe0iMg642XffJuAN4B9F5AwRGSoiH0rftwcoE5HB6bafRD9s7hWR\ns9OvP05EruhFu40pKAv4JpScc8vRlMxtaOBuRnvsa3rxvduA5eiZwh40B/7fPXzbHcD7gXbgSaDO\n93wngJnogGkT0AJ8Ln33r4FG4E0R2Zs+9nVgB7BRRA4AG4ALe2q3MYUmztnZpTHGJIH18I0xJiEs\n4BtjTEJYwDfGmISwgG+MMQkRqolXZ511lps4cWLQzTDGmEh54YUX9jrnRvf0uFAF/IkTJ7J58+ag\nm2GMMZEiIrt78zhL6RhjTEJYwDfGmISwgG+MMQlhAd8YYxLCAr4xxiREqKp0jDHJ8dxz8NBDsGsX\nTJoE118PF18cdKvizXr4xpiie+45uO022LsXxo3Ty9tu0+OmcKyHb4wpio0bYdUq7dG3tMDYsVCS\n3gXYu3zoIevlF5IFfGNMwW3cCLfeCiNHao9+82Z49VVIpWDUKLjgAhg9Wj8MTOFYwDfGFNyqVRrs\nS0pgzx44cgScg6NH4fBh/QA45xx45x34xCdg4kRYuBAuvTTolseLBXxjTMHt2qU9e4A//hGGD4cD\nBzTgDxoEhw5BYyNccgmce67m9G+4QQP/u+/q5bx5lu7JlQ3aGmPyauNGWLQILr9cLzdu1CqcAwf0\n/oMHYdgwGDEChgzRXv2xY3DaaRrY3/Mevd3SAi+9BIMHw4YNMHMmfO5zejZg+scCvjEmb7xcfWur\n9uhbW/X2jBnQ3g5tbRrs33lHA/uf/7l+MAwZAmedlXmeV17RD4BDhzTov/uung08+ST89V/Dv/xL\ncO8xyizgG2PyZtUq7bmXlGhALynR25s2wV13aVAvKQEROP98HbBtb4eBAzWH7zl0SC+PH4eTJ/Ux\nfkuXWk+/PyzgG2PyZudODfB+I0bo8UsugZUr4fnn4fHHtTLn9df1Q2DpUg36bW0a4AcN0l790KF6\nNjBggD7XkCF6hnDsGDz6aNHfXuSJcy7oNvyP6upqZ+vhGxMdzz4LP/6xllhOnKiDrV7P3tPWpiWX\nK1f2/rlOPx3eegv27dMPhYED9YPA6/n7LVsGS5bk8U1FkIi84Jyr7ulxVqVjjOmXZ5+F//N/tAfv\nVdY0N2vABz1+4IB+ff3rPT/fpZd2LMN87jm4+24dvO0q2APcdJNeJj3o94aldIwx/fLjH5+arx8/\nXnPxo0fDa6/p5V13aTqnry6+GGpr4Uc/0ufpzje/2b/3kDTWwzfG9Murr2rP3m/ECE3B9JS+6Ytr\nr4WpU+GDH+z6Me++m7/XizPr4Rtj+mXixExtvefAAT2eb9U9ZqdNbxQ84IvIqyKSEpEtImIjssbE\nxMKFGuC9ypq2Nr29cGHQLTNdKVYP/2POuem9GUU2xkTDpZfCd7+rZZVeeeV3v1u49W8uu6zr+/7u\n7wrzmnFjOXxjTLeefx4efjhTennddZl8eufKmkJ68EGdlbtnT8fjn/40PPJIcdoQdcUI+A7YICIn\ngB855zoM54jIImARQHl5eRGaY4zpreefh9tv1wqcsjKti7/9drjjju4HUQthzRr4/OehtDRzbP/+\njjX/pnvFCPgfds69JiJnA0+JyO+dc894d6Y/AFaCTrwqQnuMMb308MMaUDtvVPLww8UP+Fu36hIL\nBw/qUssXXqhppObm4rYjygqew3fOvZa+fAtYDcwo9GsaY/Lj1VezL5Wwe3dx27F9u75me7sG+8OH\ndaG2nTu19t/0TkEDvoicISLDvevAp4CGQr6mMabvNm3S9ec/8xm93LRJj3dVejlhQnHbt349TJ+u\nm6a8+66uqQPQ0ACzZxe3LVFW6B7+GOC/RGQrsAl40jn3iwK/pjGmDzZt0sXL9u3TJY337dPbmzbp\nAG1bW8fSy7Y2PV5MLS26uuZll+myye3tml664AKoqChuW6KsoDl859xO4KJCvoYxJjcPP5zZfhA6\n5ukffFAHaB9+WFMqEybAV79a/Px9WZkG+bFj9Qt0wHbkyOK2I+qsLNOYhNu9O7P9oMefp//gB4sf\n4DubORMeeECvjxypwX//fq3aMb1nSysYkwDetoOf/GRm20HPhAnhyNN3Z8oU+NKXNNi3tOjll76k\nx03vWQ/fmJjzth0cOVJ78nv36m1vFcvrrtOcPWSWNG5v19RNmEyZYgE+V9bDNybmVq3K5Oi9ZYxH\njtTjoPvNLl0KZ56pSxqfeabenmEF1LFjPXxjYm7Xruw5+ldfzdyeMSO8Ab6hAdau1QlW48fDrFlW\nmdNf1sM3JuYmTSreMsb51tAA992npaBlZXp533163PSdBXxjYm7+fM3J+2vp29v1eNitXatr55SW\najrKu752bdAtiyYL+MbEjFeRc/nlegk6QOtfxri/2w4WW3PzqbX2I0fa+jn9ZTl8Y2LEq8gZMULz\n9q2tmYqcfG47WCzjx+sZiX+FzPZ2Wz+nv6yHb0yMrFp16sbiI0ZkKnKiZtYsnWC1f7+mo7zrs2YF\n3bJosoBvTIzs3Jl9dcudO4NpT64qKuArX9EPrpYWvfzKV6xKp78spWNMjJx3nqZx/JuCHDigx6Oq\nosICfL5YD9+YGJk/P/vG4lGoyDGFZwHfmIjyqnE+9anM+jiXXKIDtKNH66zZ0aOjU5FjCs9SOsZE\n0MaNcNttmfVx3n5bb3/nOxrcLcCbbCzgGxNB/vVxIHO5alX0g31DA6xenVlKYc4cy+Hni6V0jImg\nrvaa9a+PE0UNDbBiRcelFFassKUU8sUCvjER1NVes1FYH6c7q1dnX0ph9eqgWxYPFvCNCamuNhaH\naK+P0x1bSqGwLOCHVH093H47zJunl/X1QbfIFFN3G4uD5um/8x0YNUqrcUaNygzYRtn48frB5WdL\nKeSPDdqGUH093HOPnsr+4hewZw/ceWfHxzgXTNtMcXS3sbi3bn0cq3HmzNGcPXTcu/b664NtV1wU\nvIcvIleKyMsiskNEvlHo14uD2loN9v/2bxrswXX6OolIkC00hbZ7d/ZBWW9j8biqqIDFizsupbB4\nsVXp5EtBe/giMgB4EPgk0AI8LyLrnHPbCvm6Ubdliw7AvfkmaIDvTICTWEYuviZM0DRO5yUSwrSx\neKHYUgqFU+iUzgxgh3NuJ4CIPAbMAizgd6GxUXs2JtmisrF4LmzrwuIrdBdxHOAfX29JH/sfIrJI\nRDaLyObW1tYCNyf81q6FqiqtvDDJFfeNxW3rwmAEPmjrnFsJrASorq5O/FBkSwtMnqy9uh074NCh\nbI9ywAkspRNvYd5YPFf+rQshc7l2rfXyC6nQEeM1wF9QVZY+ZrpQVqan7uecozsVDR9ylFMHbU+w\n7G+2BtpOY3Jh9fbBKHTAfx6YLCKTRGQwcA2wrsCvGWmdd/j5+y8P4eL37uUc9jCcA0x4z2ss+5ut\nLPlpddBNNabfrN4+GAVN6TjnjovIF4FfAgOAVc65xkK+ZtSJwLBh8MwzenvGDPjJ2rOZNs17RAkd\nT5pMFNTXQ10dNDVBeTnU1OhYTVLNmqU5e+hYb3/ddcG2K+4KnsN3zv078O+Ffp0o27YNnngCnn4a\ntm6F4cM1KJSXw9GjWM19xNXXw7JlmqcuK9PAtmwZ3HRTsoJ+56qcv/xL/dv3bl93neXvCy3wQduk\n27YNHngAjh/XYH/ypA7U7tunlQtVVfphMHVq0C01/VVXl32Asq4uOQHfq8rxPvTa2uDJJ21/2mKz\nMo+APfGE/hNs3qx7kb79tn61tMBpp2kKwAayoq2pKfsAZVNTMO0Jgr8qx78K5tq1QbcsWSzgB2zr\nVl0vJ5WCEyd0jZyTJ2HvXs1rtrbaQFbUlZdnH6AsLw+mPUGwqpxwsIAfoO3bYedO+MMf9LZzmto5\ncQIGDIBdu2DgQF0e10RXTU3Hyivvek1N0C0rHqvKCQcL+AFav16Xvn33XT3N9Rw/roO1hw7pQJbl\n76OtqkoHaEtLNVVXWpq8AdvO5cbe9Vmzgm5ZstigbYBaWuDgQS3DPHJEjx0/rpeDB8Po0Tqou307\nTJkSXDtN7qqqkhXgPamUDk43N8OQIXD4sP7NW1VOMKyHH6CyMnjrLTjvPE3dDBiggX7wYC3F/OQn\ndQ2VJ54IuqXG9F0qBcuXZ9bLGTxYg/0NN+gscgv2xWcBP0AzZ+o/wZAhun7OyZOavx86VHv006bp\nmjq2eqaJIn85qr8yp64u6JYll6V0AjRlivZ0vv1t7dFPmKClmEOHwkc+oo85cEB7RyZc6ut1o5rd\nu/X3NnduMlM23WluPvVv1ypzgmU9/IBdfTU89JBWbEyfrsF++nQYM0ZPhfftsyqdsPG2oNy/X3PR\n+/frbdt3uCOrzAkf6+EHoLFRJ5y0tGgPaNYsuO02vW/7ds3Ze/f97d/agG3YeFtQdp45W1trvXy/\nmhrN4UPH9XLmzw+2XUlmAb/IGhvhe9/LTDFvb9fbX/6y5uynTLEAH3a7d5/aS03azNneqKyEJUsy\nVTrjx2uwr6wMumXJZQG/yLrb+CGzIqYJswkTtKfq/e4geTNne6uy0gJ8mFgOv8haWrJPMbdKnOiY\nOzf7JKK5c4NumTHds4BfZF4ax6+93SpxoqSqCm6+uePM2Ztvtvy9CT9L6RTZrFmas4eOA1nXXhts\nu0zfJHXmrIk26+EX2bRpOkDrpXFGjswM2BpjTCFZDz8A06ZZgDfx1tAAa9ZktnScPduWUggDC/jG\nmLxqaIB779WxjfHjdQLhvffCV79qQT+bVErncHgfjnPnFq6yyVI6xpi8WrMm+xo6a9YE3bLwSaV0\nf+O2tsyH47JlerwQrIdfBHZ6G03F7HnFSVNT9olptobOqbqbtV2Iv7WC9fBFZKmIvCYiW9Jfny7U\na4WZd3rr/wS/9149bsKr2D2vOOlqS0dbQ+dUXe13XKgPx0KndO51zk1Pf/17gV8rlOz0Npr8PS//\n7622NuiWhd/s2dknps2eHXTLwqfYH46Wwy+wYn+Cm/yw31v/VVToAG1JiZYel5TYgG1Xij1ru9A5\n/C+JyLXAZmCJc25/5weIyCJgEUB5DBcjKS/XdEDndVfs9Dbc7PfWN6kUrF6dGe+YMyezAqxR2X5G\nlZW6v3FtbWaBuQULCjdWJM65/n+zyAZgbJa7bgU2AnsBB3wbOMc51+3CqNXV1W7z5s39bk8Y+UvU\n/DNrrccTbl4Ov/Pv7aabbOC2s1QKVqw49We1eLH9rDyF/hmJyAvOueqeHpdTSsc5d7lzriLL11rn\n3B7n3Ann3Engn4EZubxWVNnpbTR5PS//782CfXarV2cf71i9OuiWhUdYfkYFS+mIyDnOuTfSN+cA\nia1LqaiwAB9FtrRv71gZZkf19boHgJe6qakJz8+okDn8u0VkOprSeRX43wV8LWNMQGy8I6O+PpMK\nLCvTtM2yZTB8uP5Mgv4ZFSzgO+f+V6GeO+xswo5JkjlzND8NHfPT118fbLuCUFeXfSLV0aP6M4Fg\nf0ZWlplnNmHHJE1lpQ4++sc74j5gm0rBHXfAwoV66f1/d1XOe+RIOH5GtrRCnhV7qrQxYZCk8Y5U\nSjdn99I2bW16e8kSPaPvavvLMPyMrIefZzZhx5h486dt/BU3dXU6QJttIlVNTdCtVtbDzzMbwAqn\nbJUTtmNVbrZtg/XrMxOGZs6EqVODblXhNTefuiWp16mrqtLyXf/f2oIF4flbsx5+ntkG1+HjVU7s\n39+xcqK+PuiWRde2bXD//dq58dIa99+vx+Nu/Pju17+pqoKlS2HVKr0MS7AHC/h509AA3/42PPCA\nlmAdOWITdsKiu1Nw0z/r12f/ma5fH3TLCi/saZvuWEonDxoaMtOmy8o6Tpu2CVfBa2rKfgre1BRM\ne+Kgu7RG3FVW6gBtXV0mnTV/fjQ6dRbw88A/bRoyl6tXW8APg+4qJ0z/eCXHSR2rCkPFTX9YSicP\nmputMifMonwKHlYzZ2b/mc6cGXTLTHcs4OdBT4M4Jlhe5URpqY6rlJbq7TANpkXN1Klw440dJxLd\neGMyqnSizFI6eWBTy8OvqsoCfK6yref+9a8H3ar8qq/XSZK7d8OECVpdF6e/G+vh50FFRfZp05a/\nN3HhrefuXzJkxYp4LRlSXw/33KOdtfHj9fKee+JVvms9/DyxJZBNnHVXmBDFwctsulsWJS69fAv4\n/dDYqJuQeyVZs2fDtGlBt8qYwgnLeu6FtHt39vcYp/JdS+n0UWMj3HdfZlC2vV1vNzYG3TJjCqe8\nPP6FCRMmZH+PcSrftYDfR2vWZJ9huGZN0C1Lrvp6uP12mDdPL+OUcw2LOXOyl2HOmRN0y/InCcui\nWMDvo65q7ltagmlP0iVhoC0MkrDmfVUV3Hxzx/Ldm2+OT/4eLIffZ14ap/MMw87TzE1xJGGgLSyi\nOru0L+JevmsBv49mz9acPXSsub/uumDblVRJGGgzucs2hyDuH17ZWMDvhc6TMa66CrZv19O+sjIN\n9lalE4wJE2ydHNM9bw5BaWnHOQRxS0n1hgX8Hng5Yu+PZf9+7SnELbcXVXPn6u8HOp5xLVwYbLtM\neCRhDkFv5TRoKyJ/JSKNInJSRKo73XeLiOwQkZdF5Ircmhkcf47YX5VTWxt0ywwkY6AtCKkU3Hmn\nfnDeeWe0Z9TatqMZufbwG4Aa4Ef+gyIyFbgGmAacC2wQkQuccydyfL2isxxx+MV9oK3Y4pYCsW1H\nM3Lq4TvntjvnXs5y1yzgMefcEefcLmAHMCOX1wpKEiZjGOPnT4H4z2pXrw66Zd3r6qwkCXMIeqtQ\ndfjjAP8JU0v62ClEZJGIbBaRza2trQVqTv8lYTKGMX5RTIF0t7hbEuYQ9FaPKR0R2QCMzXLXrc65\ntbk2wDm3ElgJUF1d7XJ9vnzzcsS1tZmSroULLYVg4iuKKZCeBmaTMIegN3oM+M65y/vxvK8B/j+P\nsvSxUNu2TTdh9hZFmzlTN3SwHLFJkqjt77B1qwb2kyc10E+bBmPHhv+sJAiFSumsA64RkSEiMgmY\nDGwq0GvlxbZtcP/92rMpK9PL++/X48YkSZRSII8/Dp//vLZz7154+234z/+EN98M/1lJEHKq0hGR\nOcADwGjgSRHZ4py7wjnXKCL/CmwDjgM3hL1CZ/367KeE69fbtm1Bqa+HurpMKq2mxs60iiUKKRBv\nkHbAAA3szc3wxhvau3/hBZgyJbxnJUHJtUpntXOuzDk3xDk3xjl3he++u5xz73XOXeic+3nuTS0s\n24g8XOrrYdkyTSWUlenlsmW2KJrJqK2FY8dgxAgYPlw7BUOHak//8OHwnpUEyVbLTLONyMOlri57\naWBdXdAtM2GxdSu8844uc7J7N4jAeefp38nMmRbss7GAnzZzZvbyy5kzg25ZMnVVGmgT3gxoOmfX\nLu3Rv+c92qNvaoI9e2DgQPjsZ4NuYThZwE+bOhVuvLHjQNWNN1r+Pihd7bBkE94M6JleRQWcdhqc\nfTYMGQLHj2uxxe23w0UXBd3CcLLF03ymTrUAHxY1NZqzh46lgQsWBNuuOGpshHXrMqu/Xn11+Fd/\nbW6G88/X/P327TBoEEyaBGeeab377ljAN6FUVQU33dSxSmfBAqvSybfGRvje92DUKA32Bw7o7S9/\nOdxB35tNO3asfoF2CEpKgm1X2CU+4NvGCOFlE94Kb906DfZeoPQu160LPuA3NOhe0d7/5uzZmsYB\nPQNcvlyv+88A588Prr1RkOgcfnfrbxiTBC0tmhbxGzGib3s0p1Jwxx265Mgdd+Tn/6ehAe69t+P/\n5r336nHQTtmSJR3H3JYssc5aTxLdw7eNEYKRSmmqxlvCoqbGft5BKSuDHTu0rLGtTQPnhAmaH++N\nVEp72qWlmRnqy5fnHnzXrMn+v7lmTaaXH4XJYWGT6B5+FFcFjDovQPiXsFi+3M6qgpBKwW9/C488\nAr/7nS5H8MYbujTBn/1Z756jUPMl7H+zMBLdw4/iqoBR5w8QkLmsq7PeWjGlUnDrrfDcc7o0wbFj\nGuwPHdJxk+99D5588tQzMP+Y1+DB8JvfaC18SYkuZZCvRcvsf7MwEt3Dt40Ris+WsAiHujqduPTu\nuzpR6fTTNYAfPKgfAo2Nev2Xv9S9H774Rf2eFSvgj3+ELVvgpz/VwH/woD6Pd5aQj8A8e3b2/83Z\ns/Pz/pMq0T18b1XA1asz+eTrr7eeZiF5A3DWcwtWczO0tuqEJYATJ/TLOb0Ugaee0p72qFG6GNnv\nfgfjxukgaWsrnHEGHDkCr72mE6BOPx1efFHTQb2tlmlo6Pj/N2eO5ugrKuCrX9WcvXffvHmZ/L3p\nn0QHfLCBn2KzcrpwGD9eA/vQoboezbFjHe8fPFh7/gcO6GSm9nZ9TEODpm1OnNAPi0GDtAd+8KA+\nHno/YNvQkNk71xvP8fbO9YK+Bfj8SnRKxxSfldOFQ02NBtrjx7WnfvJkpmc/cqTeHjxY16g5fFiP\njR6tK1F6uf59+zSVM2KEfihcdhnMmtX732VU986NssT18K0kMD9ymbBmZ1XBq6yEf/gHuOUWPcMa\nMkR7+2ecoemZP/1J0zUDB2pQ/8AHNOd//LjeN2yYft/Ro7o08eDBfV/6orlZe/Z+Np5TWInq4VtJ\nYH7YhLV4mDtXd4z6+7+Hj39c/ycuu0yvl5ZqYB81Cj70IQ3oLS1QXa1VPSdOaK9+2DDdZep979Ol\nMHo7MzqV0vr/n/0Mfv1rXeUSbDyn0BLVw7eSwPywCWvx4V++wjtra27WBcgqKrRap7kZxoyBiRP1\nsRUVumDZgQPauy8thX/6p96/ZiqlC+Ode66mhdratPb/oov0w8R2qSqcRAV8O4XsP381xQsvwCWX\ndLzffo7Rly3VVlOTub50qaZtxozRL9Db/oqr3qitzXQYRoyA3/8e3npL/37uv98GagspUQHfSgL7\np3M1RUODztD82Mcy//j2c4y/ykrdQ/b4cTjrLP1bGDCg70tWNzVl/la8D4+TJzVlZMG+sBKVw6+o\n0JmBXt7wD3/QHoq/F2NO1bma4v3v1+MvvmgT1pIilYL16zXoe9U6jY1aldPXFU272tzGOgyFl5iA\nn0rpkq8VFfoH29qqx2zvy551nh07diz8xV9oFYdXWmkbRsebN/51wQU6qPu5z+kZnrd6ZV/MnZt9\nFu3cuflvt+kop5SOiPwVsBSYAsxwzm1OH58IbAdeTj90o3PuC7m8Vq78ecPJk/XY/v0a9O0PrXvZ\nUmGnnabT3L/5zeDaZYqnt+NfvSnXrazUip7a2kx59IIF1mEohlxz+A1ADfCjLPe94pybnuPz540/\nb+ixgcbemTNHc/jQcXasVVMkR2/Gv7xy3dLSjuW62c7+bC5GMHJK6TjntjvnXu75kcHrnDfcswd+\n9St46SUdiEpqDXl9vW76PG+eXtbXn/qYigr9p/XPjvWmv5tkqKnJnobxj3/ZzNnwK2SVziQR2QK0\nA7c55/4z24NEZBGwCKC8vLxgjZk7N7Mp9uHD8Mwzev1jH+u+JxJn9fVwzz2ZHtn+/Xr75ptPHYiz\ndU3M6afD00/r9cmT4eyz4YEHMtsP2ll0+PXYwxeRDSLSkOVrVjff9gZQnk7pLAZ+KiIjsj3QObfS\nOVftnKsePXp0/95FL3h5w5IS2LRJ638//nEdgExqT8Q/ruHvkdXWBt0yEybeDPUhQ+Dqq3Wv2xdf\n1IlX/u0Hhw616puw67GH75y7vK9P6pw7AhxJX39BRF4BLgA297mFeeKtoePt1fmBD2RqyCGZPZHd\nu7P3yJqagmmPCafOM9Rffz2z7+0FF2SOHz6sZ4lgYz1hVZCyTBEZLSID0tfPAyYDOwvxWr3hX0Nn\n0CCd1fdMIegzAAAN60lEQVToo1pX/Oab+pgk9kQmTMjeIytgZs1EUOey3PZ2Dfj+v52RI3X55Gxj\nPUlKk4ZdrmWZc4AHgNHAkyKyxTl3BXAZcKeIHANOAl9wzu3LubX95PVQjhyBZ5/VRZ8OH9Y/5CNH\nNF89cGDyeiJz52rOHjr2yBYuDLZdJlw6V+iMHJnZ8NzjdZis+ibccgr4zrnVwCmZb+dcLRCaTLBX\nQ/z005pnPO00zUe+9pqu+tfSomt4xP0PNdvS0DffrDl7r2564cK+z5w08dZ505pzz9W/l4oKrdjx\nOgrz5gXaTNMLiVhLx+uheKeioD36Cy/U5WBbWpIR7Jcv77i70PLluvnIHXcE3ToTZt6mNV5n4fzz\ndW7Gtm22/WDUJCLgez0UbwcfEd3U4X3vS07u3paGNrnoaSVNEw2JWEvH66G8//26WYNzcOmlmV16\n4rK0QiqlvfWFC/XSP5ms88AbJLMyyZgkS0TABw36P/iB9mivvFK3Zisp0dr8OPRwe9rNa/x4q5E2\nJukSkdLxi2sVQU8pm84Db95A2/z5wbTXGFN8ienhx11PKRsvreWvkV6yJJ4ffsaY7BLVw89WlhiX\ngNeb1QzjenZjjOmdxPTwe8pxR0l9ve4vOn++XtbX9241Q2NMsiUm4Ptz3P6Fwurqgm5Z39TX66qf\n+/frB9f+/XrbOUvZGGO6l5iUTm937Am77gZnly61AG+M6VpievhxKUtsaso+OGsrXBpjepKYHn5F\nBXz723D8OJx1lvb2Bw6MXlliebmmcToPztoKl8aYniSih59K6VLIlZUa7PfuhYYGmDkzeikQG5w1\nxvRXInr4/rz35Ml6bP9+DfpRW1ahqkpnB9fVZVa4XLDAVrg0xvQsEQE/qgO2DQ267aI3b2DOHE1N\nVVVZgDfG9F0iUjpRHLBtaNCN1f3zBlas0OPGGNMfiejhewO2x47B6NHRGLBdvTp7+eXq1bbuuDGm\nf2Lfw0+lYN06DZKjR0Nrqx4L+4CtLWdsjMm32Pfwa2uzD9imUuEZsE2lOm4zOHdu79bGMcaYvoh9\nD7+riUph6SmnUro0QltbJsgvWwbTpmUvv5wzJ+gWG2OiKvYBv7w83AO2/jMQ/xo/9fWweHHHtXEW\nL7b8vTGm/3JK6YjIPcBM4CjwCnC9c64tfd8twALgBHCjc+6XOba1X+bO1R4zdNz4Y8GCIFpzqqam\nUz98vDOQigoL8MaY/Mm1h/8UUOGcqwL+ANwCICJTgWuAacCVwA9EZECOr9UvlZU6UcnfUw7TtoZh\nPwMxxsRHTj1859yvfDc3Ap9NX58FPOacOwLsEpEdwAzg2Vxer7/CsPFHtoHZysrwn4EYY+Ijnzn8\n+cDP09fHAf5h0Zb0sVOIyCIR2Swim1tbW/PYnPDoamA2lQr/GYgxJj567OGLyAZgbJa7bnXOrU0/\n5lbgOPBoXxvgnFsJrASorq52ff3+KPAPzELmsrY2c/ZhAd4YU2g9Bnzn3OXd3S8i84DPAJ9wznkB\n+zXAn4UuSx8rqq1b4fHHYfdumDABPvtZuOiiYrei+4FZY4wplpxSOiJyJfA14Grn3Du+u9YB14jI\nEBGZBEwGNuXyWn21dSvcfbfmw8eP18u779bjxWYDs8aYMMg1h/99YDjwlIhsEZEfAjjnGoF/BbYB\nvwBucM6dyPG1+uTxx7PXtz/+eDFboebOzT6JKiwzfY0xyZBrlc753dx3F3BXLs+fiy1bdHD04EFN\nn1x4oa6lE8RWgN7AbG1tZqnjBQssb2+MKa5YrqWTSmneXkSD/eHDsHEjTJ2aWU+nUK9bV5cJ6jU1\nmaBuA7PGmKDFcmkFr/rFOQ32Q4Zo8G9s1IHbQkilYPnyjuvXL1+ux40xJgxi2cNvaoLzz4cRI2Db\nNh0gHTkSRo0qXJWOfxtFyFzW1VnP3hgTDrEM+OXl2sMeO1a/QAdJS0oK95pR3UbRGJMcsUzpBFEV\nE8VtFI0xyRLLgJ9tuYJZs2DNGli0SLc7zPfesDU12T9kamry+zrGGNNfkpkcG7zq6mq3efPmnJ7D\nv0iZN1j75puwaxdUVcF735tZoKy/68vX12tu3lsIraZGn7u7Kh1jjCkUEXnBOVfd0+NilcP3Fikr\nLYXBg+Hpp/X4sGEa+OvrdSB3zBg93p8NwevrM69RVqYfHMuW6RlFVZUFeGNMeMUqpeNfpOzllzW4\newOnJSVw2mlamgn9H1D1V+P4Z/DW1eX3vRhjTL7FqofvX6SsvV0DPmjv/vBhGDo0M7Da3YBqV2vX\ne6+RrRoniBm8xhjTF7Hq4fsXKfNm2B45AuPG6fW2Nv0Q6G5D8O7Wru/8Gp72dj1ujDFhFquA7y/H\nvPBCOHBAg/EHPwjTpunM2zPP7H5D8K42Fa+t1futGscYE1WxrdJpbtaBWxE4erTrqplUSgdvvfTN\nSy/p4Ot7fB+FJ09qeedPfqK3u6rSMcaYICSySgcyi5T1pkQylYIVK7QH76Vvdu2CM87ouMha53x/\nVZUFeGNM9MQqpePp7UJmq1efmr6prNRJWbZ2vTEmbmIZ8HtbOtnUpIO7fuefD+edZ5uKG2PiJ3Yp\nHej9QmbeImveypag6Zvp0+Fb3yp8O40xpphi2cPv7UJmc+Zkr7jJVq5pjDFRF8sefmWlLpB2/Lhu\nazhuHAwYAB/+MCxd2nFC1eLFmsv3Bnevv97SN8aYeIpdWWZDg1benDihgb21FQYNgmuv1X1uS0s1\nveMtoGb5eWNM1CW2LNNfeeOVVu7fD+vW6W5XnXek8rZDNMaYuMsp4IvIPcBM4CjwCnC9c65NRCYC\n24GX0w/d6Jz7Qi6v1R3/RKitW+HiizsOxI4cCa+/Dpdd1vH7bEcqY0yS5Dpo+xRQ4ZyrAv4A3OK7\n7xXn3PT0V0GD/bJl2osvK9P0zW9/q2vge9rb4dxzbUcqY0yy5RTwnXO/cs4dT9/cCJR19/hC8Nfc\nt7Zqtc3rr8PatXrpVd586UvF3/bQGGPCJJ9lmfOBn/tuTxKRLSLytIh8pKtvEpFFIrJZRDa3trb2\n+UWbmnQlzCeegJ/9TIP8uefqKpkbNuh9ixfr0gqdtz20AVtjTJL0mMMXkQ3A2Cx33eqcW5t+zK3A\nceDR9H1vAOXOubdF5APAGhGZ5pw70PlJnHMrgZWgVTp9fQNDhmgK5+BBOP10XSyttRUmTdIyzJKS\nzKqY3jo7xhiTRD0GfOfc5d3dLyLzgM8An3DpGk/n3BHgSPr6CyLyCnABkFvNZTeOHtUdrU6ezByz\nQVljjMnIKaUjIlcCXwOuds694zs+WkQGpK+fB0wGdubyWl05cgQ++lFd4fKdd2DgQO3dnzhhg7LG\nGOOXaw7/+8Bw4Kl0vv6H6eOXAfUisgV4HPiCc25fjq+VVXm5pnWuukqrdMaO1QXTBg2yZRKMMcYv\npzp859z5XRyvBWpzee7emjtXyzJLS7X+futWePtt+NSn4AtfsJy9McZ4Ij/TtrJSq228Xa6uuKLj\npuPGGGNU5AM+WPWNMcb0RiyXRzbGGHMqC/jGGJMQFvCNMSYhLOAbY0xCWMA3xpiECNWOVyLSCuzO\n09OdBezN03OFhb2n8Ivb+wF7T1EwwTk3uqcHhSrg55OIbO7Nll9RYu8p/OL2fsDeU5xYSscYYxLC\nAr4xxiREnAP+yqAbUAD2nsIvbu8H7D3FRmxz+MYYYzqKcw/fGGOMjwV8Y4xJiFgFfBH5KxFpFJGT\nIlLd6b5bRGSHiLwsIlcE1cb+EJEr0+3eISLfCLo9/SEiq0TkLRFp8B07U0SeEpE/pi9Lg2xjX4nI\neBH5jYhsS//dfTl9PLLvS0SGisgmEdmafk93pI9H9j0BiMgAEXlJRJ5I3470++mvWAV8oAGoAZ7x\nHxSRqcA1wDTgSuAH3haMYZdu54PAVcBU4G/S7ydq/i/6s/f7BvAfzrnJwH+kb0fJcWCJc24qcAlw\nQ/p3E+X3dQT4uHPuImA6cKWIXEK03xPAl4HtvttRfz/9EquA75zb7px7Octds4DHnHNHnHO7gB3A\njOK2rt9mADucczudc0eBx9D3EynOuWeAzttczgIeTl9/GJhd1EblyDn3hnPuxfT1g2hAGUeE35dT\nh9I3B6W/HBF+TyJSBvwl8GPf4ci+n1zEKuB3YxzQ7Lvdkj4WBVFue0/GOOfeSF9/ExgTZGNyISIT\ngfcBzxHx95VOf2wB3gKecs5F/T3dB3wNOOk7FuX302+RC/giskFEGrJ8Ra7XazKc1gdHskZYRIah\nezh/xTl3wH9fFN+Xc+6Ec246UAbMEJGKTvdH5j2JyGeAt5xzL3T1mCi9n1xFbotD59zl/fi214Dx\nvttl6WNREOW292SPiJzjnHtDRM5Be5SRIiKD0GD/qHOuLn048u8LwDnXJiK/QcdeovqePgRcLSKf\nBoYCI0TkEaL7fnISuR5+P60DrhGRISIyCZgMbAq4Tb31PDBZRCaJyGB08HldwG3Kl3XAdenr1wFr\nA2xLn4mIAD8BtjvnVvjuiuz7EpHRIlKSvn4a8Eng90T0PTnnbnHOlTnnJqL/O792zn2eiL6fnDnn\nYvMFzEFz3EeAPcAvfffdCrwCvAxcFXRb+/i+Pg38Id3+W4NuTz/fw/8D3gCOpX9HC4BRaIXEH4EN\nwJlBt7OP7+nDaCqgHtiS/vp0lN8XUAW8lH5PDcC30scj+5587+2jwBNxeT/9+bKlFYwxJiGSktIx\nxpjEs4BvjDEJYQHfGGMSwgK+McYkhAV8Y4xJCAv4xhiTEBbwjTEmIf4/qmYTBWl0A2MAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc868c09350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myClass = [9]\n",
    "# ? Mattia, you had the following line but didn't run on mine until I added the [0]. Can you confirm?\n",
    "# x = hmm_classifier.generateSample(label_enc.transform(myClass), 200)\n",
    "x = hmm_classifier.generateSample(label_enc.transform(myClass)[0], 200)\n",
    "x = x * (train_max - train_min) + train_min\n",
    "plot_char(x.T, myClass[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "                      init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    correct = 0.0\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "        hmm.startprob_ = pi0\n",
    "        hmm.transmat_  = trans0\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]))\n",
    "        y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))\n",
    "        correct += np.sum(y_val_pred == ytrain[test_index])\n",
    "    accuracy = correct/xtrain.shape[0]\n",
    "    cv1_results[k] = accuracy\n",
    "    print('Accuracy', k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average for k = ', 5, 0.73516404310209515)\n",
      "('Average for k = ', 6, 0.77170053423319063)\n",
      "('Average for k = ', 7, 0.82463536372694468)\n",
      "('Average for k = ', 8, 0.85141150450003433)\n",
      "('Average for k = ', 9, 0.87754455065691717)\n",
      "('Average for k = ', 10, 0.88568322248456699)\n",
      "('Average for k = ', 11, 0.88951240595047787)\n",
      "('Average for k = ', 12, 0.88555516362080999)\n",
      "('Average for k = ', 13, 0.88400382273213118)\n",
      "('Average for k = ', 14, 0.89725385648655087)\n",
      "('Average for k = ', 15, 0.89924318450181351)\n",
      "('Average for k = ', 16, 0.90491572420467359)\n",
      "('Average for k = ', 17, 0.8954297766409226)\n",
      "('Average for k = ', 18, 0.89871134555368926)\n",
      "('Average for k = ', 19, 0.90568653234390273)\n",
      "('Average for k = ', 20, 0.90366541188456717)\n",
      "('Average for k = ', 21, 0.90985052144686962)\n",
      "('Average for k = ', 22, 0.90888175845293495)\n",
      "('Average for k = ', 23, 0.90647960238373082)\n",
      "('Average for k = ', 24, 0.89597965709354921)\n",
      "('Average for k = ', 25, 0.90346232076995803)\n"
     ]
    }
   ],
   "source": [
    "cv2_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "                      init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    class_cond_accuracies = {}\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "        hmm.startprob_ = pi0\n",
    "        hmm.transmat_  = trans0\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]))\n",
    "        for label in label_enc.classes_:\n",
    "            class_cond_xtest = xtrain[test_index][ytrain[test_index] == label]\n",
    "            y_class_cond_pred = label_enc.inverse_transform(hmm_classifier.predict(class_cond_xtest))\n",
    "            class_cond_accuracy = (y_class_cond_pred == label).mean()\n",
    "            if (not class_cond_accuracies.has_key(label)):\n",
    "                class_cond_accuracies[label] = []\n",
    "            class_cond_accuracies[label] = class_cond_accuracies[label] + [class_cond_accuracy]\n",
    "\n",
    "    k_states_results = {}\n",
    "    for label in label_enc.classes_:\n",
    "        k_states_results[label] = np.mean(class_cond_accuracies[label])\n",
    "    cv2_results[k] = k_states_results\n",
    "    print('Average for k = ', k, np.mean(cv2_results[k].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.8224</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.8070</td>\n",
       "      <td>0.6877</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4211</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.4697</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.2982</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6035</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>0.5651</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5628</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7912</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9571</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7921</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8605</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8781</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4211</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9571</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9571</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7596</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8352</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.9221</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6107</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9221</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.5786</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.6706</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.5955</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a       b       c       d       e     g       h       l       m  \\\n",
       "5   0.9757  0.9405  0.8939  0.0000  0.9792  0.88  0.1930  0.8224  0.5507   \n",
       "6   1.0000  0.9167  0.9394  0.0139  0.9896  1.00  0.4211  0.8481  0.4901   \n",
       "7   0.9757  0.8929  0.9545  1.0000  0.9896  1.00  0.2982  0.7721  0.5942   \n",
       "8   0.9877  0.9167  0.9394  1.0000  0.9896  1.00  0.2807  0.8471  0.5817   \n",
       "9   0.9877  0.9524  0.9697  1.0000  0.9896  1.00  0.4912  0.8851  0.5975   \n",
       "10  0.9881  0.9643  0.9848  1.0000  0.9896  1.00  0.4737  0.8476  0.6719   \n",
       "11  0.9877  0.9286  1.0000  1.0000  0.9896  1.00  0.3333  0.8599  0.6561   \n",
       "12  0.9877  0.9405  0.9545  1.0000  0.9896  1.00  0.3509  0.8485  0.6700   \n",
       "13  0.9881  0.9405  0.9848  1.0000  0.9896  1.00  0.3158  0.8737  0.6403   \n",
       "14  0.9877  0.9524  0.9697  1.0000  0.9896  1.00  0.4211  0.8613  0.6555   \n",
       "15  1.0000  0.9405  0.9697  1.0000  0.9896  1.00  0.4737  0.8481  0.6561   \n",
       "16  1.0000  0.9405  0.9545  1.0000  0.9896  1.00  0.5439  0.8609  0.6265   \n",
       "17  0.9877  0.9167  0.9545  1.0000  0.9896  1.00  0.4035  0.8604  0.6851   \n",
       "18  0.9757  0.9286  0.9848  1.0000  0.9896  1.00  0.4386  0.8481  0.6555   \n",
       "19  1.0000  0.9643  0.9848  1.0000  0.9896  1.00  0.3860  0.8352  0.6416   \n",
       "20  1.0000  0.9643  0.9848  1.0000  0.9896  1.00  0.4035  0.8979  0.6107   \n",
       "21  0.9877  0.9524  0.9848  1.0000  0.9896  1.00  0.4561  0.8851  0.6423   \n",
       "22  1.0000  0.9405  0.9697  1.0000  0.9896  1.00  0.4386  0.8856  0.6403   \n",
       "23  0.9877  0.9405  0.9545  1.0000  0.9896  1.00  0.4035  0.8851  0.6700   \n",
       "24  0.9877  0.9286  0.9848  1.0000  0.9896  1.00  0.3684  0.8732  0.6265   \n",
       "25  0.9877  0.9405  0.9848  1.0000  0.9896  1.00  0.4912  0.8471  0.6403   \n",
       "26  0.9877  0.9643  1.0000  1.0000  0.9896  1.00  0.3860  0.8604  0.6265   \n",
       "27  0.9877  0.9405  0.9848  1.0000  0.9896  1.00  0.3509  0.8481  0.6555   \n",
       "28  0.9877  0.9524  1.0000  1.0000  0.9896  1.00  0.4386  0.8737  0.6258   \n",
       "29  0.9881  0.9405  0.9848  1.0000  0.9896  1.00  0.4561  0.8865  0.6706   \n",
       "30  0.9877  0.9524  1.0000  1.0000  0.9896  1.00  0.4561  0.9107  0.5955   \n",
       "\n",
       "         n       o       p       q       r       s       u       v       w  \\\n",
       "5   0.3238  0.9545  0.9143  0.8070  0.6877  1.0000  0.0476  1.0000  0.7588   \n",
       "6   0.4056  0.9545  0.9281  0.8947  0.6886  0.9841  0.4697  1.0000  0.5333   \n",
       "7   0.4865  0.9697  0.9281  0.9474  0.8263  0.9690  0.2994  1.0000  0.6035   \n",
       "8   0.5651  0.9697  0.9426  0.9298  0.8096  1.0000  0.5628  1.0000  0.8079   \n",
       "9   0.5151  0.9848  0.9287  0.9123  0.8096  0.9848  0.7511  1.0000  0.7912   \n",
       "10  0.5167  0.9848  0.9571  0.9474  0.8439  1.0000  0.7807  1.0000  0.7921   \n",
       "11  0.5968  0.9848  0.9710  0.9474  0.8614  0.9848  0.8427  1.0000  0.8605   \n",
       "12  0.5325  0.9848  0.9149  0.9649  0.8956  0.9848  0.8283  1.0000  0.8781   \n",
       "13  0.6286  0.9848  0.9432  0.9474  0.8956  0.9690  0.7330  1.0000  0.8456   \n",
       "14  0.6786  0.9848  0.9571  0.9474  0.9474  0.9690  0.8593  0.9889  0.7754   \n",
       "15  0.6468  1.0000  0.9571  0.9474  0.9298  0.9690  0.8586  0.9889  0.8096   \n",
       "16  0.6619  1.0000  0.9710  0.9474  0.9307  0.9690  0.8745  1.0000  0.8281   \n",
       "17  0.5468  1.0000  0.9710  0.9474  0.9649  0.9690  0.9524  1.0000  0.7596   \n",
       "18  0.5317  1.0000  0.9710  0.9474  0.9649  0.9690  0.9524  0.9889  0.8281   \n",
       "19  0.6595  1.0000  0.9710  0.9474  0.9649  0.9841  0.9221  1.0000  0.8632   \n",
       "20  0.6294  1.0000  0.9710  0.9649  0.9307  0.9690  0.9055  0.9889  0.8632   \n",
       "21  0.6444  1.0000  1.0000  0.9649  0.9474  0.9690  0.9055  0.9889  0.8789   \n",
       "22  0.6127  1.0000  1.0000  0.9825  0.9649  0.9690  0.9221  1.0000  0.8623   \n",
       "23  0.6611  1.0000  0.9710  0.9825  0.9316  0.9690  0.9214  1.0000  0.8623   \n",
       "24  0.5643  1.0000  0.9855  0.9825  0.9474  0.9841  0.8117  0.9889  0.8965   \n",
       "25  0.5635  1.0000  0.9855  1.0000  0.9482  0.9841  0.8268  1.0000  0.8798   \n",
       "26  0.5952  1.0000  1.0000  0.9649  0.9307  0.9841  0.8427  1.0000  0.8807   \n",
       "27  0.5786  1.0000  0.9855  0.9825  0.9298  0.9841  0.8586  1.0000  0.9316   \n",
       "28  0.5794  1.0000  1.0000  0.9649  0.9298  0.9690  0.8268  1.0000  0.8798   \n",
       "29  0.6444  1.0000  1.0000  0.9825  0.9307  0.9841  0.8283  1.0000  0.9307   \n",
       "30  0.6294  1.0000  1.0000  0.9825  0.9307  0.9841  0.8283  1.0000  0.9482   \n",
       "\n",
       "         y       z  \n",
       "5   0.9848  0.9892  \n",
       "6   0.9565  1.0000  \n",
       "7   0.9855  1.0000  \n",
       "8   0.8979  1.0000  \n",
       "9   1.0000  1.0000  \n",
       "10  0.9710  1.0000  \n",
       "11  0.9855  1.0000  \n",
       "12  0.9855  1.0000  \n",
       "13  1.0000  1.0000  \n",
       "14  1.0000  1.0000  \n",
       "15  1.0000  1.0000  \n",
       "16  1.0000  1.0000  \n",
       "17  1.0000  1.0000  \n",
       "18  1.0000  1.0000  \n",
       "19  1.0000  1.0000  \n",
       "20  1.0000  1.0000  \n",
       "21  1.0000  1.0000  \n",
       "22  1.0000  1.0000  \n",
       "23  1.0000  1.0000  \n",
       "24  1.0000  1.0000  \n",
       "25  1.0000  1.0000  \n",
       "26  1.0000  1.0000  \n",
       "27  1.0000  1.0000  \n",
       "28  1.0000  1.0000  \n",
       "29  1.0000  1.0000  \n",
       "30  1.0000  1.0000  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pandas.DataFrame(cv2_results).T\n",
    "result.columns = key\n",
    "result.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 10, 11,  7,  6,  6, 16, 30, 17, 14, 15, 21, 25, 17,  5, 17,  5,\n",
       "       30,  9,  6])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highest n_states for each character\n",
    "np.asarray(range(5, 31))[np.argmax(np.asarray(result), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handpicked highest\n",
    "# [15, 10, 11, 10, 10, 10, 16, 30, 17, 14, 15, 21, 25, 17, 10, 17, 10, 30, 15, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining the classifier using the \"Optimized\" number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.array([15, 10, 11, 10, 10, 10, 16, 30, 17, 14, 15, 21, 25, 17, 10, 17, 10, 30, 15, 15]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.82572614107883813)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.86166842661034848)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian HMM with different states per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenerativeClassifierHMMCV(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, k=range(3,9)):\n",
    "        self.class_cond_hmms_ = []\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, sequences, labels):\n",
    "        kf = KFold(n_splits = 3)\n",
    "        class_counts = np.bincount(labels).astype(np.float)\n",
    "        self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "\n",
    "        for c in range(np.max(labels)+1):\n",
    "            sequences_c = sequences[labels == c]\n",
    "            sequences_not_c = sequences[labels != c]\n",
    "\n",
    "            lengths_c = np.array(list(map(len, sequences_c)))\n",
    "            log_likels = {}\n",
    "            for n_states in self.k: \n",
    "                pi0 = np.eye(1, n_states)[0] # start probability\n",
    "\n",
    "                trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "                trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "                \n",
    "                hmm = GaussianHMM(n_components=n_states, \n",
    "                  init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "                \n",
    "                log_likel = 0\n",
    "                for train_index, test_index in kf.split(sequences_c):\n",
    "                    hmm.startprob_ = pi0\n",
    "                    hmm.transmat_  = trans0\n",
    "                    \n",
    "                    X_c = np.vstack(sequences_c[train_index])\n",
    "                    \n",
    "                    hmm.fit(X_c, lengths=lengths_c[train_index])\n",
    "                    log_likel += np.sum(log_likelihoods(hmm, sequences_c[test_index]))\n",
    "                    \n",
    "                log_likels[n_states] = log_likel\n",
    "                print('Label ' + str(c) + ' for states ' + str(n_states) + ': Log in class ' + \n",
    "                      str(log_likel) + \n",
    "                      '\\nmax log off class ' + str(np.max(log_likelihoods(hmm, sequences_not_c)))\n",
    "                     + '\\n min log in class ' + str(np.min(log_likelihoods(hmm, sequences_c))))\n",
    "                \n",
    "#             self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        # 20 x N matrix\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "        return np.argmax(log_post_unnorm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm_classifier_CV = GenerativeClassifierHMMCV(k = range(15, 31))\n",
    "hmm_classifier_CV.fit(xtrain, \n",
    "                   label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "I was getting some results (70%) with these parameters when I was on version 0.2.0 but after updating to the latest\n",
    "version (0.2.1), GMMHMM hasn't been great and it's taking too long to run. There are some open issues on their Github which seem to suggest GMMHMM is a bit buggy atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0. ],\n",
       "       [ 0. ,  0.5,  0.5],\n",
       "       [ 0. ,  0. ,  1. ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_states = 3\n",
    "n_mix = 10\n",
    "# initial guess for EM\n",
    "pi0 = np.eye(1, n_states)[0] # start probability\n",
    "pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmmhmm = GMMHMM(n_components=n_states, \n",
    "                n_mix=n_mix,\n",
    "                covariance_type='diag',\n",
    "                init_params='mc',\n",
    "                n_iter=3,\n",
    "                random_state=rng)\n",
    "gmmhmm.startprob_ = pi0\n",
    "gmmhmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=None,\n",
       "    covars_weight=None, init_params='mc', means_prior=0.0,\n",
       "    means_weight=0.0, min_covar=0.001, n_components=3, n_iter=3, n_mix=10,\n",
       "    params='stmcw',\n",
       "    random_state=<mtrand.RandomState object at 0x000000000A48A3A8>,\n",
       "    startprob_prior=1.0, tol=0.01, transmat_prior=1.0, verbose=False,\n",
       "    weights_prior=1.0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(gmmhmm)\n",
    "hmm_classifier.fit(xtrain, label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20L, 429L)\n",
      "(20L,)\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.38694638694638694)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', (y_val_pred == yval).mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
