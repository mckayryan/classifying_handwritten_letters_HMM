{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# COMP9418 Assignment 2\n",
    "\n",
    "## *Tasks TODO*\n",
    "- parameter initialization\n",
    "- baseline (GMM model)\n",
    "- mean negative log probability\n",
    "- sample predictions.txt generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hmmlearn\n",
    "import sklearn\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it's version 0.2.1 (install from github, not pip)\n",
    "# pip install git+https://github.com/hmmlearn/hmmlearn.git\n",
    "hmmlearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "trainData = sio.loadmat('./trajectories_train.mat')\n",
    "testData = sio.loadmat('./trajectories_xtest.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean up the data\n",
    "xtrain = trainData['xtrain'].reshape((-1, ))\n",
    "ytrain = trainData['ytrain'].reshape((-1, ))\n",
    "kf = StratifiedKFold(n_splits = 3, random_state=rng)\n",
    "xtest = testData['xtest'].reshape((-1, ))\n",
    "key = trainData['key']\n",
    "key = [item[0] for item in key.reshape((-1, ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429L,)\n",
      "(1429L,)\n",
      "(1429L,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "# print([sum(yval == i) for i in np.unique(ytrain)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = xtrain[idx]\n",
    "y = ytrain[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_char(data, label):\n",
    "    start_x = 0\n",
    "    start_y = 0\n",
    "    plt.plot(start_x, start_y, 'ro')\n",
    "    for vel_h, vel_v, alpha in zip(data[0,], data[1, ], 1/(1 + np.exp(-data[2, ]/np.sum(data[1, ])))):\n",
    "        start_x = start_x + vel_h\n",
    "        start_y = start_y + vel_v\n",
    "        plt.plot(start_x, start_y,'bo', alpha = alpha)\n",
    "    plt.title('Character ' + key[label-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nje8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70e32e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_char(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([seq.T for seq in xtrain])\n",
    "xtest = np.asarray([seq.T for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_max = np.max(np.vstack(xtrain), axis=0)\n",
    "train_min = np.min(np.vstack(xtrain), axis=0)\n",
    "def rescale(seq):\n",
    "    return (seq - train_min) / (train_max - train_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.asarray([rescale(seq) for seq in xtrain])\n",
    "xtest = np.asarray([rescale(seq) for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429L,)\n",
      "(1429L,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lengths_train = list(map(lambda x: x.shape[0], xtrain))\n",
    "lengths_test = list(map(lambda x: x.shape[0], xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc = LabelEncoder().fit(ytrain)\n",
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Padding sequances with zero so they all have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_length = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pad_seq(seq):\n",
    "    seq_len = seq.shape[0]\n",
    "    x = np.pad(seq[:, 0], (0, max_length - seq_len%max_length), 'constant')\n",
    "    y = np.pad(seq[:, 1], (0, max_length - seq_len%max_length), 'constant')\n",
    "    z = np.pad(seq[:, 2], (0, max_length - seq_len%max_length), 'constant')\n",
    "    return np.stack((x, y, z)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xtrain_zp = np.asarray([pad_seq(seq) for seq in xtrain])\n",
    "xtest_zp = np.asarray([pad_seq(seq) for seq in xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429L, 250L, 3L)\n",
      "(1429L, 250L, 3L)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_zp.shape)\n",
    "print(xtest_zp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generative Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(hmm, sequence):\n",
    "\n",
    "    logprob_frame = hmm._compute_log_likelihood(sequence)\n",
    "    logprob_sequence, _ =  hmm._do_forward_pass(logprob_frame)\n",
    "\n",
    "    return logprob_sequence\n",
    "\n",
    "def log_likelihoods(hmm, sequences):\n",
    "\n",
    "    ll = lambda seq: log_likelihood(hmm, seq)\n",
    "\n",
    "    return np.fromiter(map(ll, sequences), dtype='float64')\n",
    "\n",
    "def log_likelihoods_cond(cond_hmms, sequences):\n",
    "\n",
    "    ll = lambda hmm: log_likelihoods(hmm, sequences)\n",
    "\n",
    "    return np.vstack(map(ll, cond_hmms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Original Class we had that could only take in 1 n_state for all the HMMs\n",
    "\n",
    "# class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "#     def __init__(self, hmm=GaussianHMM()):\n",
    "\n",
    "#         self.hmm = hmm\n",
    "#         self.class_cond_hmms_ = []\n",
    "\n",
    "#     def fit(self, sequences, labels):\n",
    "\n",
    "#         class_counts = np.bincount(labels).astype(np.float)\n",
    "#         self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "\n",
    "#         for c in range(np.max(labels)+1):\n",
    "\n",
    "#             sequences_c = sequences[labels == c]\n",
    "\n",
    "#             X_c = np.vstack(sequences_c)\n",
    "#             lengths_c = list(map(len, sequences_c))\n",
    "            \n",
    "#             class_cond_hmm = clone(self.hmm, safe=True)\n",
    "#             class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "\n",
    "#             self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, sequences):\n",
    "#         # 20 x N matrix\n",
    "#         log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "#         log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "#         return np.argmax(log_post_unnorm, axis=0)\n",
    "    \n",
    "#     def generateSample(self, mClass, length):\n",
    "#         sel_hmm = self.class_cond_hmms_[mClass]\n",
    "#         x, _ = sel_hmm.sample(length)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make sure to keep the init_params commented otherwise it doesn't work properly for some reason\n",
    "\n",
    "class GenerativeClassifierHMM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hmm=GaussianHMM()):\n",
    "        self.hmm = hmm\n",
    "        self.class_cond_hmms_ = []\n",
    "\n",
    "    def fit(self, sequences, labels, k):        \n",
    "        class_counts = np.bincount(labels).astype(np.float)\n",
    "        self.logprior = np.log(class_counts / np.sum(class_counts))\n",
    "        \n",
    "        for c in range(np.max(labels)+1):\n",
    "            sequences_c = sequences[labels == c]\n",
    "            X_c = np.vstack(sequences_c)\n",
    "            lengths_c = list(map(len, sequences_c))\n",
    "            class_cond_hmm = clone(self.hmm, safe=True)\n",
    "            n_states_k = k[c]\n",
    "            pi0 = np.eye(1, n_states_k)[0]\n",
    "            trans0 = np.diag(np.ones(n_states_k)) + np.diag(np.ones(n_states_k-1), 1)\n",
    "            trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "            class_cond_hmm.n_components = n_states_k\n",
    "            class_cond_hmm.startprob_ = pi0\n",
    "            class_cond_hmm.transmat_  = trans0\n",
    "            class_cond_hmm.fit(X_c, lengths=lengths_c)\n",
    "            self.class_cond_hmms_.append(class_cond_hmm)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        # 20 x N matrix\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "\n",
    "        return np.argmax(log_post_unnorm, axis=0)\n",
    "    \n",
    "    def predict_proba(self, sequences):\n",
    "        log_likelihood_ = log_likelihoods_cond(self.class_cond_hmms_, sequences)\n",
    "\n",
    "        log_post_unnorm = log_likelihood_ + self.logprior.reshape(-1, 1)\n",
    "        \n",
    "        prob_post_norm = np.empty_like(log_post_unnorm)\n",
    "        \n",
    "        for i in range(log_post_unnorm.shape[1]):\n",
    "            c = np.max(log_post_unnorm[:,i])\n",
    "            prob_post_unnorm = np.exp(log_post_unnorm[:,i].astype(np.float64) - c)\n",
    "            prob_post_norm[:,i] = prob_post_unnorm / np.sum(prob_post_unnorm)\n",
    "            \n",
    "        return prob_post_norm\n",
    "    \n",
    "    def generateSample(self, mClass, length):\n",
    "        sel_hmm = self.class_cond_hmms_[mClass]\n",
    "        x, _ = sel_hmm.sample(length)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Guassian HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_states = 10\n",
    "\n",
    "# initial guess for EM\n",
    "# pi0 = np.eye(1, n_states)[0] # start probability\n",
    "# pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "# trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "# trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "# trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=n_states, \n",
    "#                   init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "# hmm.startprob_ = pi0\n",
    "# hmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT of warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(15, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.96887966804979253)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96409714889123543)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   1.70869843e-197   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   1.00000000e+000   0.00000000e+000   0.00000000e+000]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "probs = hmm_classifier.predict_proba(xtrain[train_index])\n",
    "print(probs[:,2])\n",
    "print(ytrain[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g   h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  26   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   \n",
       "c   0   0  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  10   0   1   4   0   0   0   0   0   0   0   4   0   \n",
       "l   0   0   0   0   0   0   0  25   0   0   0   0   0   0   0   0   0   2   0   \n",
       "m   0   0   0   0   0   0   0   0  18   3   0   0   0   0   0   0   0   2   0   \n",
       "n   0   0   0   0   0   0   0   0   4  16   0   0   0   0   0   0   0   1   0   \n",
       "o   0   0   0   0   0   0   0   0   0   0  22   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0   0   0   0   0   0  24   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0   0   0   0   1   0   0  18   0   0   0   0   0   0   \n",
       "r   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22   0   0   0   0   \n",
       "u   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   4   0   \n",
       "v   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  30   0   0   \n",
       "w   0   0   0   0   0   0   0   0   2   1   0   0   0   0   0   1   0  16   0   \n",
       "y   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   \n",
       "z   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  31  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[test_index], y_val_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   g   h   l   m   n   o   p   q   r   s   u   v   w   y  \\\n",
       "a  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "b   0  55   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   \n",
       "c   0   0  44   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "d   0   0   0  47   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "e   0   0   0   0  64   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "g   0   0   0   0   0  50   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "h   0   0   0   0   0   0  24   0   1   7   0   0   0   0   0   0   0   6   0   \n",
       "l   0   0   0   0   0   0   3  48   0   0   0   0   0   0   0   0   0   1   0   \n",
       "m   0   0   0   0   0   0   2   0  37   2   0   0   0   0   0   0   0   3   0   \n",
       "n   0   0   0   0   0   0   0   0   3  35   0   0   0   0   0   0   0   3   0   \n",
       "o   0   0   0   0   0   0   0   0   0   0  44   0   0   0   0   0   0   0   0   \n",
       "p   0   0   0   0   0   0   0   0   0   0   0  46   0   0   0   0   0   0   0   \n",
       "q   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   0   \n",
       "r   0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   0   0   0   0   \n",
       "s   0   0   0   0   0   0   0   0   0   0   0   0   0   0  43   0   0   0   0   \n",
       "u   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  39   0   3   0   \n",
       "v   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60   0   0   \n",
       "w   0   0   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0  36   0   \n",
       "y   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45   \n",
       "z   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "    z  \n",
       "a   0  \n",
       "b   0  \n",
       "c   0  \n",
       "d   0  \n",
       "e   0  \n",
       "g   0  \n",
       "h   0  \n",
       "l   0  \n",
       "m   0  \n",
       "n   0  \n",
       "o   0  \n",
       "p   0  \n",
       "q   0  \n",
       "r   0  \n",
       "s   0  \n",
       "u   0  \n",
       "v   0  \n",
       "w   0  \n",
       "y   0  \n",
       "z  62  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "conf_mat = pandas.DataFrame(confusion_matrix(ytrain[train_index], y_train_pred))\n",
    "conf_mat.columns = key\n",
    "conf_mat.index = key\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Observations of validations confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with m, u, w\n",
    "* n gets mixed up with m, w\n",
    "* u gets mixed up with w\n",
    "\n",
    "### Observations of training confusion matrix\n",
    "* h gets mixed up with n, w\n",
    "* m gets mixed up with u, w\n",
    "* n gets mixed up with n, w, m\n",
    "* p gets mixed up with n\n",
    "* u gets mixed up with a, w\n",
    "* w gets mixed up with a, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Generate a random sample from the gmm for a certain class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc86911f750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myClass = [20]\n",
    "# ? Mattia, you had the following line but didn't run on mine until I added the [0]. Can you confirm?\n",
    "# x = hmm_classifier.generateSample(label_enc.transform(myClass), 200)\n",
    "x = hmm_classifier.generateSample(label_enc.transform(myClass)[0], 200)\n",
    "x = x * (train_max - train_min) + train_min\n",
    "plot_char(x.T, myClass[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 5, 0.7998600419874038)\n",
      "('Accuracy', 6, 0.8621413575927221)\n",
      "('Accuracy', 7, 0.8530440867739678)\n",
      "('Accuracy', 8, 0.8761371588523443)\n",
      "('Accuracy', 9, 0.8803358992302309)\n",
      "('Accuracy', 10, 0.8999300209937019)\n",
      "('Accuracy', 11, 0.900629811056683)\n",
      "('Accuracy', 12, 0.9062281315605318)\n",
      "('Accuracy', 13, 0.9097270818754374)\n",
      "('Accuracy', 14, 0.9111266620013996)\n",
      "('Accuracy', 15, 0.9188243526941917)\n",
      "('Accuracy', 16, 0.9118264520643807)\n",
      "('Accuracy', 17, 0.9132260321903429)\n",
      "('Accuracy', 18, 0.9111266620013996)\n",
      "('Accuracy', 19, 0.9104268719384184)\n",
      "('Accuracy', 20, 0.9146256123163051)\n",
      "('Accuracy', 21, 0.9125262421273618)\n",
      "('Accuracy', 22, 0.9181245626312107)\n",
      "('Accuracy', 23, 0.9230230930720784)\n",
      "('Accuracy', 24, 0.9258222533240028)\n",
      "('Accuracy', 25, 0.9258222533240028)\n",
      "('Accuracy', 26, 0.9153254023792862)\n",
      "('Accuracy', 27, 0.9230230930720784)\n",
      "('Accuracy', 28, 0.9286214135759272)\n",
      "('Accuracy', 29, 0.9209237228831351)\n",
      "('Accuracy', 30, 0.9258222533240028)\n"
     ]
    }
   ],
   "source": [
    "cv1_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "#                       init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    correct = 0.0\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "#         hmm.startprob_ = pi0\n",
    "#         hmm.transmat_  = trans0\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]), np.tile(k, 20))\n",
    "        y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))\n",
    "        correct += np.sum(y_val_pred == ytrain[test_index])\n",
    "    accuracy = correct/xtrain.shape[0]\n",
    "    cv1_results[k] = accuracy\n",
    "    print('Accuracy', k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv2_results = {}\n",
    "for k in range(5, 31):\n",
    "    pi0 = np.eye(1, k)[0]\n",
    "    trans0 = np.diag(np.ones(k)) + np.diag(np.ones(k-1), 1)\n",
    "    trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "    hmm = GaussianHMM(n_components=k, \n",
    "#                       init_params='mc',\n",
    "                      n_iter=10,\n",
    "                      random_state=seed)\n",
    "    class_cond_accuracies = {}\n",
    "    for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "#         hmm.startprob_ = pi0\n",
    "#         hmm.transmat_  = trans0\n",
    "        hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "        hmm_classifier.fit(xtrain[train_index], label_enc.transform(ytrain[train_index]), np.tile(k, 20))\n",
    "        for label in label_enc.classes_:\n",
    "            class_cond_xtest = xtrain[test_index][ytrain[test_index] == label]\n",
    "            y_class_cond_pred = label_enc.inverse_transform(hmm_classifier.predict(class_cond_xtest))\n",
    "            class_cond_accuracy = (y_class_cond_pred == label).mean()\n",
    "            if (not class_cond_accuracies.has_key(label)):\n",
    "                class_cond_accuracies[label] = []\n",
    "            class_cond_accuracies[label] = class_cond_accuracies[label] + [class_cond_accuracy]\n",
    "\n",
    "    k_states_results = {}\n",
    "    for label in label_enc.classes_:\n",
    "        k_states_results[label] = np.mean(class_cond_accuracies[label])\n",
    "    cv2_results[k] = k_states_results\n",
    "    print('Average for k = ', k, np.mean(cv2_results[k].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.7977</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.4849</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.4683</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.7746</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8605</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.6278</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.6302</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a       b       c       d       e       g       h       l       m  \\\n",
       "5   0.9519  0.9524  0.9091  0.2240  0.9896  0.9733  0.1930  0.7977  0.5507   \n",
       "6   0.9638  0.9167  0.9545  1.0000  0.9896  1.0000  0.4386  0.8234  0.7161   \n",
       "7   0.9757  0.9048  0.9848  0.9855  0.9896  1.0000  0.3158  0.7972  0.5527   \n",
       "8   0.9877  0.9524  0.9848  1.0000  0.9896  1.0000  0.2281  0.8613  0.5672   \n",
       "9   0.9757  0.9643  1.0000  1.0000  0.9896  1.0000  0.2456  0.8979  0.6555   \n",
       "10  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.4561  0.9103  0.6403   \n",
       "11  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4737  0.8599  0.6416   \n",
       "12  1.0000  0.9405  1.0000  1.0000  0.9896  1.0000  0.4912  0.8727  0.6713   \n",
       "13  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.3860  0.8865  0.6713   \n",
       "14  0.9877  0.9405  1.0000  1.0000  0.9896  1.0000  0.4386  0.8481  0.6858   \n",
       "15  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.5263  0.8984  0.6548   \n",
       "16  1.0000  0.9405  1.0000  1.0000  0.9896  1.0000  0.5088  0.8471  0.6555   \n",
       "17  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.5088  0.8727  0.6410   \n",
       "18  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.3684  0.8471  0.6561   \n",
       "19  0.9877  0.9643  0.9848  1.0000  0.9896  1.0000  0.3684  0.8723  0.6700   \n",
       "20  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.4035  0.8732  0.6133   \n",
       "21  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.3860  0.9107  0.6561   \n",
       "22  0.9877  0.9762  1.0000  1.0000  0.9896  1.0000  0.4386  0.8979  0.6397   \n",
       "23  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4561  0.9107  0.6555   \n",
       "24  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4561  0.8979  0.6568   \n",
       "25  0.9877  0.9405  1.0000  1.0000  0.9896  1.0000  0.4561  0.8856  0.7003   \n",
       "26  0.9877  0.9286  1.0000  1.0000  0.9896  1.0000  0.4386  0.8727  0.6423   \n",
       "27  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.4386  0.9112  0.6864   \n",
       "28  0.9877  0.9643  1.0000  1.0000  0.9896  1.0000  0.5439  0.9236  0.6258   \n",
       "29  0.9877  0.9524  1.0000  1.0000  0.9896  1.0000  0.3860  0.8979  0.6555   \n",
       "30  0.9877  0.9286  1.0000  1.0000  0.9896  1.0000  0.4737  0.9107  0.7161   \n",
       "\n",
       "         n       o       p       q       r       s       u       v       w  \\\n",
       "5   0.4349  0.9848  0.8720  0.8246  0.7044  1.0000  0.4848  0.9889  0.7254   \n",
       "6   0.4849  0.9545  0.9281  0.8947  0.7404  1.0000  0.4394  0.9889  0.6719   \n",
       "7   0.4683  0.9697  0.9281  0.9474  0.7746  0.9848  0.2973  0.9889  0.8614   \n",
       "8   0.5167  0.9697  0.9275  0.9649  0.8096  1.0000  0.5635  1.0000  0.8789   \n",
       "9   0.5016  0.9848  0.9143  0.9298  0.8263  0.9848  0.5332  1.0000  0.8956   \n",
       "10  0.5643  0.9848  0.9710  0.9474  0.8605  1.0000  0.6263  1.0000  0.8439   \n",
       "11  0.5635  0.9848  0.9432  0.9649  0.9307  0.9690  0.6732  1.0000  0.8623   \n",
       "12  0.5976  0.9848  0.9432  0.9474  0.8965  0.9848  0.6861  1.0000  0.8789   \n",
       "13  0.6786  0.9848  0.9432  0.9474  0.9307  1.0000  0.7338  1.0000  0.8614   \n",
       "14  0.6452  1.0000  0.9287  0.9474  0.9298  0.9683  0.7965  1.0000  0.8965   \n",
       "15  0.6286  1.0000  0.9565  0.9474  0.9649  0.9841  0.8124  0.9889  0.8798   \n",
       "16  0.6421  0.9848  0.9710  0.9474  0.9649  0.9841  0.7489  0.9889  0.8456   \n",
       "17  0.6929  0.9848  0.9710  0.9474  0.9474  0.9841  0.7338  0.9889  0.8439   \n",
       "18  0.6444  0.9848  0.9855  0.9474  0.9482  0.9841  0.7799  1.0000  0.8974   \n",
       "19  0.6278  1.0000  1.0000  0.9649  0.9474  0.9841  0.7345  0.9889  0.8807   \n",
       "20  0.6921  1.0000  0.9855  0.9649  0.9649  0.9841  0.8139  0.9889  0.8465   \n",
       "21  0.5952  1.0000  0.9710  0.9474  0.9649  1.0000  0.7626  1.0000  0.8623   \n",
       "22  0.5794  1.0000  1.0000  0.9649  0.9649  0.9841  0.8579  0.9889  0.8640   \n",
       "23  0.6778  1.0000  1.0000  0.9649  0.9474  0.9841  0.8276  1.0000  0.8982   \n",
       "24  0.7270  1.0000  0.9855  0.9825  0.9649  0.9841  0.8427  1.0000  0.8982   \n",
       "25  0.7103  1.0000  1.0000  0.9825  0.9649  0.9841  0.8283  1.0000  0.8982   \n",
       "26  0.6302  1.0000  0.9710  0.9825  0.9307  0.9841  0.8117  1.0000  0.9316   \n",
       "27  0.5976  1.0000  1.0000  0.9825  0.9482  0.9841  0.8593  1.0000  0.9149   \n",
       "28  0.6944  1.0000  0.9855  1.0000  0.9825  0.9841  0.7980  1.0000  0.9149   \n",
       "29  0.6468  1.0000  1.0000  0.9649  0.9482  0.9841  0.8593  1.0000  0.9316   \n",
       "30  0.6294  1.0000  1.0000  0.9825  0.9825  0.9841  0.8283  1.0000  0.9149   \n",
       "\n",
       "         y    z  \n",
       "5   1.0000  1.0  \n",
       "6   0.9855  1.0  \n",
       "7   0.9855  1.0  \n",
       "8   0.9855  1.0  \n",
       "9   0.9710  1.0  \n",
       "10  0.9710  1.0  \n",
       "11  0.9710  1.0  \n",
       "12  1.0000  1.0  \n",
       "13  1.0000  1.0  \n",
       "14  1.0000  1.0  \n",
       "15  1.0000  1.0  \n",
       "16  1.0000  1.0  \n",
       "17  1.0000  1.0  \n",
       "18  1.0000  1.0  \n",
       "19  1.0000  1.0  \n",
       "20  1.0000  1.0  \n",
       "21  1.0000  1.0  \n",
       "22  1.0000  1.0  \n",
       "23  1.0000  1.0  \n",
       "24  1.0000  1.0  \n",
       "25  1.0000  1.0  \n",
       "26  1.0000  1.0  \n",
       "27  1.0000  1.0  \n",
       "28  1.0000  1.0  \n",
       "29  1.0000  1.0  \n",
       "30  1.0000  1.0  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pandas.DataFrame(cv2_results).T\n",
    "result.columns = key\n",
    "result.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 22,  9,  6,  5,  6, 28, 28,  6, 24, 14, 19, 28, 28,  5, 27,  8,\n",
       "       26,  5,  5])"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highest n_states for each character\n",
    "np.asarray(range(5, 31))[np.argmax(np.asarray(result), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tested states\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 30, 20, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.939xx\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 20, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.93983402489626555\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.94190871369294604\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 15, 28, 26, 28, 28] 0.91701244813278004\n",
    "# [28, 28, 28, 28, 28, 28, 28, 10, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.91xx\n",
    "# [28, 28, 28, 28, 28, 28, 28, 21, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.94190871369294604\n",
    "# [28, 28, 28, 28, 28, 28, 15, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28] 0.92323651452282163\n",
    "\n",
    "# Winner\n",
    "# [28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Retraining the classifier using the \"Optimized\" number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.array([28, 28, 28, 28, 28, 28, 28, 28, 25, 25, 28, 28, 28, 28, 28, 27, 28, 26, 28, 28])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.94190871369294604)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96620908130939809)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Low-pass filtering of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    filtered = np.empty_like(data)\n",
    "    \n",
    "    for i in range(filtered.shape[0]):\n",
    "        ll = np.zeros(data[i].shape)\n",
    "        \n",
    "        for j in range(3):\n",
    "            ll[:,j] = lfilter(b, a, data[i][:,j])\n",
    "        \n",
    "        filtered[i] = ll\n",
    "    return filtered\n",
    "\n",
    "# Filter requirements.\n",
    "order = 4\n",
    "fs = 200.0       # sample rate, Hz\n",
    "cutoff = 2  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_states = 10\n",
    "\n",
    "# initial guess for EM\n",
    "# pi0 = np.eye(1, n_states)[0] # start probability\n",
    "# pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "# trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "# trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "# trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=n_states, \n",
    "#                   init_params='mc',\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)\n",
    "# hmm.startprob_ = pi0\n",
    "# hmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# due to https://github.com/hmmlearn/hmmlearn/issues/158 and \n",
    "# https://github.com/hmmlearn/hmmlearn/issues/175\n",
    "# the fitting process is going to give a LOT of warnings\n",
    "# so we hide them in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=10, n_iter=10, params='stmc',\n",
       "      random_state=1234, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "train_index, test_index = list(kf.split(xtrain, ytrain))[0]\n",
    "\n",
    "hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                   label_enc.transform(ytrain[train_index]),\n",
    "                   np.tile(15, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy', 0.96887966804979253)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy', (y_val_pred == ytrain[test_index]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96409714889123543)\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy', (y_train_pred == ytrain[train_index]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cross validation on number of states, cutoff frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "order = 4\n",
    "fs = 200.0  \n",
    "\n",
    "hmm = GaussianHMM(n_components=n_states,\n",
    "                  n_iter=10,\n",
    "                  random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: k = 10; cut_freq = 2 ---> 0.941175230565\n",
      "Validation Accuracy: k = 10; cut_freq = 3 ---> 0.974032995778\n",
      "Validation Accuracy: k = 10; cut_freq = 4 ---> 0.951644298248\n",
      "Validation Accuracy: k = 10; cut_freq = 5 ---> 0.951651732219\n",
      "Validation Accuracy: k = 10; cut_freq = 6 ---> 0.943244786528\n",
      "Validation Accuracy: k = 10; cut_freq = 7 ---> 0.929225864831\n",
      "Validation Accuracy: k = 10; cut_freq = 8 ---> 0.915280264919\n",
      "Validation Accuracy: k = 10; cut_freq = 9 ---> 0.906148170785\n",
      "Validation Accuracy: k = 10; cut_freq = 10 ---> 0.906148170785\n",
      "Validation Accuracy: k = 11; cut_freq = 2 ---> 0.947467751185\n",
      "Validation Accuracy: k = 11; cut_freq = 3 ---> 0.965722956995\n",
      "Validation Accuracy: k = 11; cut_freq = 4 ---> 0.956534975435\n",
      "Validation Accuracy: k = 11; cut_freq = 5 ---> 0.954533608424\n",
      "Validation Accuracy: k = 11; cut_freq = 6 ---> 0.947453901172\n",
      "Validation Accuracy: k = 11; cut_freq = 7 ---> 0.934897577887\n",
      "Validation Accuracy: k = 11; cut_freq = 8 ---> 0.925800352473\n",
      "Validation Accuracy: k = 11; cut_freq = 9 ---> 0.908948008025\n",
      "Validation Accuracy: k = 11; cut_freq = 10 ---> 0.914540248533\n",
      "Validation Accuracy: k = 12; cut_freq = 2 ---> 0.950240153677\n",
      "Validation Accuracy: k = 12; cut_freq = 3 ---> 0.965691937901\n",
      "Validation Accuracy: k = 12; cut_freq = 4 ---> 0.951664299024\n",
      "Validation Accuracy: k = 12; cut_freq = 5 ---> 0.959375832158\n",
      "Validation Accuracy: k = 12; cut_freq = 6 ---> 0.95101733992\n",
      "Validation Accuracy: k = 12; cut_freq = 7 ---> 0.93974108483\n",
      "Validation Accuracy: k = 12; cut_freq = 8 ---> 0.916679541935\n",
      "Validation Accuracy: k = 12; cut_freq = 9 ---> 0.908313615727\n",
      "Validation Accuracy: k = 12; cut_freq = 10 ---> 0.900598232968\n",
      "Validation Accuracy: k = 13; cut_freq = 2 ---> 0.950207851374\n",
      "Validation Accuracy: k = 13; cut_freq = 3 ---> 0.964266509345\n",
      "Validation Accuracy: k = 13; cut_freq = 4 ---> 0.953093311925\n",
      "Validation Accuracy: k = 13; cut_freq = 5 ---> 0.958015008207\n",
      "Validation Accuracy: k = 13; cut_freq = 6 ---> 0.946819508873\n",
      "Validation Accuracy: k = 13; cut_freq = 7 ---> 0.946053340948\n",
      "Validation Accuracy: k = 13; cut_freq = 8 ---> 0.925056486462\n",
      "Validation Accuracy: k = 13; cut_freq = 9 ---> 0.913143272656\n",
      "Validation Accuracy: k = 13; cut_freq = 10 ---> 0.909690590828\n",
      "Validation Accuracy: k = 14; cut_freq = 2 ---> 0.952339710805\n",
      "Validation Accuracy: k = 14; cut_freq = 3 ---> 0.963542644111\n",
      "Validation Accuracy: k = 14; cut_freq = 4 ---> 0.96007611227\n",
      "Validation Accuracy: k = 14; cut_freq = 5 ---> 0.95376615729\n",
      "Validation Accuracy: k = 14; cut_freq = 6 ---> 0.934873992765\n",
      "Validation Accuracy: k = 14; cut_freq = 7 ---> 0.936988417835\n",
      "Validation Accuracy: k = 14; cut_freq = 8 ---> 0.929233298803\n",
      "Validation Accuracy: k = 14; cut_freq = 9 ---> 0.914592286334\n",
      "Validation Accuracy: k = 14; cut_freq = 10 ---> 0.906136887189\n",
      "Validation Accuracy: k = 15; cut_freq = 2 ---> 0.958613513857\n",
      "Validation Accuracy: k = 15; cut_freq = 3 ---> 0.962877232718\n",
      "Validation Accuracy: k = 15; cut_freq = 4 ---> 0.961498974408\n",
      "Validation Accuracy: k = 15; cut_freq = 5 ---> 0.958665551657\n",
      "Validation Accuracy: k = 15; cut_freq = 6 ---> 0.948134180507\n",
      "Validation Accuracy: k = 15; cut_freq = 7 ---> 0.939724933678\n",
      "Validation Accuracy: k = 15; cut_freq = 8 ---> 0.923649775474\n",
      "Validation Accuracy: k = 15; cut_freq = 9 ---> 0.915982846169\n",
      "Validation Accuracy: k = 15; cut_freq = 10 ---> 0.908246444705\n",
      "Validation Accuracy: k = 16; cut_freq = 2 ---> 0.952340994013\n",
      "Validation Accuracy: k = 16; cut_freq = 3 ---> 0.96779021182\n",
      "Validation Accuracy: k = 16; cut_freq = 4 ---> 0.959440436763\n",
      "Validation Accuracy: k = 16; cut_freq = 5 ---> 0.959365831769\n",
      "Validation Accuracy: k = 16; cut_freq = 6 ---> 0.950268606355\n",
      "Validation Accuracy: k = 16; cut_freq = 7 ---> 0.934887577499\n",
      "Validation Accuracy: k = 16; cut_freq = 8 ---> 0.924373640709\n",
      "Validation Accuracy: k = 16; cut_freq = 9 ---> 0.911061149887\n",
      "Validation Accuracy: k = 16; cut_freq = 10 ---> 0.9061704727\n",
      "Validation Accuracy: k = 17; cut_freq = 2 ---> 0.957263973504\n",
      "Validation Accuracy: k = 17; cut_freq = 3 ---> 0.967066346585\n",
      "Validation Accuracy: k = 17; cut_freq = 4 ---> 0.962868515538\n",
      "Validation Accuracy: k = 17; cut_freq = 5 ---> 0.963576229621\n",
      "Validation Accuracy: k = 17; cut_freq = 6 ---> 0.950961452495\n",
      "Validation Accuracy: k = 17; cut_freq = 7 ---> 0.938438714722\n",
      "Validation Accuracy: k = 17; cut_freq = 8 ---> 0.92018682798\n",
      "Validation Accuracy: k = 17; cut_freq = 9 ---> 0.917375972422\n",
      "Validation Accuracy: k = 17; cut_freq = 10 ---> 0.918098554449\n",
      "Validation Accuracy: k = 18; cut_freq = 2 ---> 0.962813911321\n",
      "Validation Accuracy: k = 18; cut_freq = 3 ---> 0.966383500833\n",
      "Validation Accuracy: k = 18; cut_freq = 4 ---> 0.962859798358\n",
      "Validation Accuracy: k = 18; cut_freq = 5 ---> 0.961472822869\n",
      "Validation Accuracy: k = 18; cut_freq = 6 ---> 0.951650449011\n",
      "Validation Accuracy: k = 18; cut_freq = 7 ---> 0.934917313385\n",
      "Validation Accuracy: k = 18; cut_freq = 8 ---> 0.913864571474\n",
      "Validation Accuracy: k = 18; cut_freq = 9 ---> 0.916732862944\n",
      "Validation Accuracy: k = 18; cut_freq = 10 ---> 0.90629096473\n",
      "Validation Accuracy: k = 19; cut_freq = 2 ---> 0.957915800162\n",
      "Validation Accuracy: k = 19; cut_freq = 3 ---> 0.96713095119\n",
      "Validation Accuracy: k = 19; cut_freq = 4 ---> 0.969141035382\n",
      "Validation Accuracy: k = 19; cut_freq = 5 ---> 0.962865949121\n",
      "Validation Accuracy: k = 19; cut_freq = 6 ---> 0.949641648027\n",
      "Validation Accuracy: k = 19; cut_freq = 7 ---> 0.942009587442\n",
      "Validation Accuracy: k = 19; cut_freq = 8 ---> 0.927185779475\n",
      "Validation Accuracy: k = 19; cut_freq = 9 ---> 0.923761550325\n",
      "Validation Accuracy: k = 19; cut_freq = 10 ---> 0.914577418391\n",
      "Validation Accuracy: k = 20; cut_freq = 2 ---> 0.96213849954\n",
      "Validation Accuracy: k = 20; cut_freq = 3 ---> 0.968483057961\n",
      "Validation Accuracy: k = 20; cut_freq = 4 ---> 0.958675552045\n",
      "Validation Accuracy: k = 20; cut_freq = 5 ---> 0.964226773071\n",
      "Validation Accuracy: k = 20; cut_freq = 6 ---> 0.943334259464\n",
      "Validation Accuracy: k = 20; cut_freq = 7 ---> 0.935681180173\n",
      "Validation Accuracy: k = 20; cut_freq = 8 ---> 0.927872474853\n",
      "Validation Accuracy: k = 20; cut_freq = 9 ---> 0.922235630516\n",
      "Validation Accuracy: k = 20; cut_freq = 10 ---> 0.920955562322\n",
      "Validation Accuracy: k = 21; cut_freq = 2 ---> 0.959332511537\n",
      "Validation Accuracy: k = 21; cut_freq = 3 ---> 0.969215640375\n",
      "Validation Accuracy: k = 21; cut_freq = 4 ---> 0.953752572555\n",
      "Validation Accuracy: k = 21; cut_freq = 5 ---> 0.96219925452\n",
      "Validation Accuracy: k = 21; cut_freq = 6 ---> 0.946140247467\n",
      "Validation Accuracy: k = 21; cut_freq = 7 ---> 0.948900348433\n",
      "Validation Accuracy: k = 21; cut_freq = 8 ---> 0.92569087876\n",
      "Validation Accuracy: k = 21; cut_freq = 9 ---> 0.932050570402\n",
      "Validation Accuracy: k = 21; cut_freq = 10 ---> 0.925059052878\n",
      "Validation Accuracy: k = 22; cut_freq = 2 ---> 0.95935609666\n",
      "Validation Accuracy: k = 22; cut_freq = 3 ---> 0.966389651596\n",
      "Validation Accuracy: k = 22; cut_freq = 4 ---> 0.956552409795\n",
      "Validation Accuracy: k = 22; cut_freq = 5 ---> 0.96635119853\n",
      "Validation Accuracy: k = 22; cut_freq = 6 ---> 0.951653015427\n",
      "Validation Accuracy: k = 22; cut_freq = 7 ---> 0.941146512609\n",
      "Validation Accuracy: k = 22; cut_freq = 8 ---> 0.929210996888\n",
      "Validation Accuracy: k = 22; cut_freq = 9 ---> 0.930658727358\n",
      "Validation Accuracy: k = 22; cut_freq = 10 ---> 0.939046955481\n",
      "Validation Accuracy: k = 23; cut_freq = 2 ---> 0.958648382576\n",
      "Validation Accuracy: k = 23; cut_freq = 3 ---> 0.968506643083\n",
      "Validation Accuracy: k = 23; cut_freq = 4 ---> 0.963558795262\n",
      "Validation Accuracy: k = 23; cut_freq = 5 ---> 0.963608531924\n",
      "Validation Accuracy: k = 23; cut_freq = 6 ---> 0.957260123878\n",
      "Validation Accuracy: k = 23; cut_freq = 7 ---> 0.946749771435\n",
      "Validation Accuracy: k = 23; cut_freq = 8 ---> 0.932065438345\n",
      "Validation Accuracy: k = 23; cut_freq = 9 ---> 0.933520602786\n",
      "Validation Accuracy: k = 23; cut_freq = 10 ---> 0.939131560862\n",
      "Validation Accuracy: k = 24; cut_freq = 2 ---> 0.960056376772\n",
      "Validation Accuracy: k = 24; cut_freq = 3 ---> 0.970556463549\n",
      "Validation Accuracy: k = 24; cut_freq = 4 ---> 0.965650918418\n",
      "Validation Accuracy: k = 24; cut_freq = 5 ---> 0.966398368776\n",
      "Validation Accuracy: k = 24; cut_freq = 6 ---> 0.953751289347\n",
      "Validation Accuracy: k = 24; cut_freq = 7 ---> 0.943978652151\n",
      "Validation Accuracy: k = 24; cut_freq = 8 ---> 0.936264552601\n",
      "Validation Accuracy: k = 24; cut_freq = 9 ---> 0.92081891914\n",
      "Validation Accuracy: k = 24; cut_freq = 10 ---> 0.939096692143\n",
      "Validation Accuracy: k = 25; cut_freq = 2 ---> 0.962847496832\n",
      "Validation Accuracy: k = 25; cut_freq = 3 ---> 0.967089931708\n",
      "Validation Accuracy: k = 25; cut_freq = 4 ---> 0.962175669397\n",
      "Validation Accuracy: k = 25; cut_freq = 5 ---> 0.963598531536\n",
      "Validation Accuracy: k = 25; cut_freq = 6 ---> 0.950977603646\n",
      "Validation Accuracy: k = 25; cut_freq = 7 ---> 0.939176164691\n"
     ]
    }
   ],
   "source": [
    "cv3_results = {}\n",
    "for k in range(10, 31):\n",
    "    for cutoff in [2, 3, 4, 5, 6, 7, 8, 9, 10]:  # desired cutoff frequency of the filter, Hz\n",
    "        xtrain_filtered = butter_lowpass_filter(xtrain, cutoff, fs, order)\n",
    "        val_acc = 0.0\n",
    "        tra_acc = 0.0\n",
    "        for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "            hmm_classifier = GenerativeClassifierHMM(hmm)\n",
    "\n",
    "            hmm_classifier.fit(xtrain_filtered[train_index], \n",
    "                       label_enc.transform(ytrain[train_index]),\n",
    "                       np.tile(k, 20))\n",
    "\n",
    "            y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[test_index]))\n",
    "            val_acc += (y_val_pred == ytrain[test_index]).mean()\n",
    "            \n",
    "            y_train_pred = label_enc.inverse_transform(hmm_classifier.predict(xtrain_filtered[train_index]))\n",
    "            \n",
    "            tra_acc += (y_train_pred == ytrain[train_index]).mean()\n",
    "            \n",
    "        val_acc /= kf.get_n_splits()\n",
    "        print('Validation Accuracy: k = ' + str(k) + '; cut_freq = ' + str(cutoff) + ' ---> ' + str(val_acc))\n",
    "        \n",
    "        cv3_results[(k, cutoff)] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gaussian Mixture HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Note**:\n",
    "I was getting some results (70%) with these parameters when I was on version 0.2.0 but after updating to the latest\n",
    "version (0.2.1), GMMHMM hasn't been great and it's taking too long to run. There are some open issues on their Github which seem to suggest GMMHMM is a bit buggy atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0. ],\n",
       "       [ 0. ,  0.5,  0.5],\n",
       "       [ 0. ,  0. ,  1. ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_states = 3\n",
    "n_mix = 10\n",
    "# initial guess for EM\n",
    "pi0 = np.eye(1, n_states)[0] # start probability\n",
    "pi0\n",
    "\n",
    "# initial guess for EM\n",
    "# transition matrix\n",
    "trans0 = np.diag(np.ones(n_states)) + np.diag(np.ones(n_states-1), 1)\n",
    "trans0 /= trans0.sum(axis=1).reshape(-1, 1)\n",
    "trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gmmhmm = GMMHMM(n_components=n_states, \n",
    "                n_mix=n_mix,\n",
    "                covariance_type='diag',\n",
    "                init_params='mc',\n",
    "                n_iter=3,\n",
    "                random_state=rng)\n",
    "gmmhmm.startprob_ = pi0\n",
    "gmmhmm.transmat_  = trans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeClassifierHMM(hmm=GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=None,\n",
       "    covars_weight=None, init_params='mc', means_prior=0.0,\n",
       "    means_weight=0.0, min_covar=0.001, n_components=3, n_iter=3, n_mix=10,\n",
       "    params='stmcw',\n",
       "    random_state=<mtrand.RandomState object at 0x000000000A48A3A8>,\n",
       "    startprob_prior=1.0, tol=0.01, transmat_prior=1.0, verbose=False,\n",
       "    weights_prior=1.0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_classifier = GenerativeClassifierHMM(gmmhmm)\n",
    "hmm_classifier.fit(xtrain, label_enc.transform(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20L, 429L)\n",
      "(20L,)\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = label_enc.inverse_transform(hmm_classifier.predict(xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.38694638694638694)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', (y_val_pred == yval).mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Basic Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Guassian Mixture Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class GaussianMixtureClassifier():\n",
    "    '''\n",
    "    GaussianMixtureClassifier is classifier where a seperate GMM is trained on\n",
    "    different classes and it has a similar API to ski-learn classifiers\n",
    "    Parameters\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        K = int(np.max(y)+1)\n",
    "        self.models = []\n",
    "        for k in range(K):\n",
    "            model = GaussianMixture(**self.kwargs)\n",
    "            model.fit(X[y==k])\n",
    "            self.models.append(model)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        loglikelihood = [ model.score_samples(X) for model in self.models ]\n",
    "        return np.vstack(loglikelihood).argmax(axis=0)\n",
    "    \n",
    "    def score(self, X):\n",
    "        return self.predict(X)\n",
    "\n",
    "    def score_samples(self, X):\n",
    "        loglikelihood = [ model.score_samples(X) for model in self.models ]\n",
    "        return np.vstack(loglikelihood).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reshaping the data into a two dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xtrain_zp = xtrain_zp.reshape(xtrain_zp.shape[0], xtrain_zp.shape[1]* xtrain_zp.shape[2])\n",
    "ytrain_zp = ytrain - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 750)\n",
      "set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_zp.shape)\n",
    "print(set(ytrain_zp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Diagonal Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.97717842323651449)\n",
      "('Accuracy: ', 0.97689075630252098)\n",
      "('Accuracy: ', 0.97452229299363058)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "    gmm_classifier = GaussianMixtureClassifier(n_components=10, covariance_type='diag', verbose=False, max_iter=1000)\n",
    "\n",
    "    gmm_classifier.fit(xtrain_zp[train_index], ytrain[train_index]-1)\n",
    "    accuracy = (gmm_classifier.predict(xtrain_zp[test_index]) == (ytrain[test_index] - 1)).mean()\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.99792531120331951)\n",
      "('Accuracy: ', 0.99159663865546221)\n",
      "('Accuracy: ', 0.99787685774946921)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain, ytrain):\n",
    "    gmm_classifier = GaussianMixtureClassifier(n_components=10, covariance_type='full', verbose=False, max_iter=1000)\n",
    "\n",
    "    gmm_classifier.fit(xtrain_zp[train_index], ytrain[train_index]-1)\n",
    "    accuracy = (gmm_classifier.predict(xtrain_zp[test_index]) == (ytrain[test_index] - 1)).mean()\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Appendix Material\n",
    "* scaling and guassian filter (although guassian filter didn't work) https://www.researchgate.net/publication/4090432_Principal_Component_Analysis_for_Online_Handwritten_Character_Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
